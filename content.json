{"pages":[],"posts":[{"title":"ETDS的代码实现","text":"这部分紧跟上一篇关于Encrypted Traffic Detection System原理的文章，进行代码的实现，把细节和可以效率优化的部分做好。这一版本测试出来运行时间是7s，需要更快。 github链接： 代码整体结构 项目的文件结果大致如上所示，其中data专门一个文件夹，用以存放原始数据和中间生成的各种数据，主要是npy格式文件。关于算法部分的文件如上所示，在下载完nltk库后就可以直接使用了，运行main.py文件跑出结果，显示各个环节的运行时间。这里没有去考虑系统的数据交流环节，至少没有设计在网络环境下的交换时间，那个也不是重点考虑的部分。这里只涉及了几个中间部分处理数据的时间，其余的交互环节主要是保障安全性。 nltk库的使用这是一个语料库，用来做一些基础的文本处理。在我们的代码中，我们希望是用这个库来生成我们的token。但目前我有疑惑关于这里生成的是否都长度一致。 首先是下载nltk： pip install nltk 在运行的时候报错，提示我要依次执行： 12&gt;&gt;&gt; import nltk&gt;&gt;&gt; nltk.download('punkt') 之后就可以正常使用了，具体的nltk库的其他使用可以参考官方文档：给个链接 字典树核心思想是空间换时间，利用字符串的共同前缀作为存储依据，用来节省存储空间，加速搜索时间。Trie的字符串搜索时间复杂度为$O(m)$，$m$为最长的字符串长度，其查询性能与集合中的字符串的数量无关。其在搜索字符串时表现出的高效，使得特别适用于构建文本搜索和词频统计等应用。 参考链接 字典树的性质 根节点不包含字符，除根结点外的每一个节点都仅包含一个字符； 从根节点到某一结点路径上所经过的字符连接起来，即为该节点对应的字符串； 任意节点的所有子节点所包含的字符都不相同 Trie关键词查找过程 每次从根节点开始搜索 获取关键词的第一个字符，根据该字符选择对应的子节点，转到该子节点继续检索 在相应的子节点上，获取关键词的第二个字符，进一步选择对应的子节点进行检索 以此类推，进行迭代过程； 在某个节点处，关键词的所有字母已被取出，则读取附在该节点上的信息，查找完成 toolsHMAC伪随机序列的生成性能测试和可提高的部分 搜索算法是否可以更优 中间盒32行两个循环合并一下 问题 节省时间这里的代码没有包含多次使用同一模糊规则的环节 一些检验验证的时间也是忽略了么，是否能保证和前面那篇文章同样的变量控制 token的处理这里也是提前弄好的，但是实际中这里应该也会花一些时间吧 m-n那块我还没有论文对应起来 hash和fF都是用的相似的方法，它们有什么区别么？","link":"/2020/10/02/ETDS%E7%9A%84%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/"},{"title":"Encrypted Traffic Detection System","text":"这篇是我们正在做的，但是内容不够完善，包括整体的书写，主体思路和PrivDPI相似，但是细节和使用的算法都有不同，同时还对系统的安全性有证明。 Notation 安全性分析的理论公式System概述依旧分为C、S、RG、MB，但是和PrivDPI在功能分配上有细小不同。 验证C/S的传输内容一致性上，PrivDPI主要是通过比较$g^k$来判断，而这篇论文是依靠验证双方的token是否相同。当不相同时，交给RG来仲裁 攻击模型C或者S不诚信但是这里即使不诚信，我们也只考虑其中一方欺骗别人，要是合起伙来欺骗，那确实…….😔 一般C有恶意的话，基本出于想要躲过MB的侦擦去发一个敏感不和规矩的词汇；如果是S有恶意，主要是去陷害C（hhhhh） MB有问题MB就算有问题，那也不是大坏人，而是honest-but-curious（他会依照规矩办事，不欺瞒任何人，但是他好奇别人在传输什么内容） RG联合MB的攻击RG也想知道别人传输的内容，但是他自己无法直接接触到，就让MB当他的眼睛👀 安全目标保证rule和传输信息的保密性，保证RG能分辨出C/S中谁是好人，并且效率要高 详细流程A. Setup密钥的生成$k_{TLS}$：只有CS手上有的，用来加密交流信息的 $k_s$：只有CS手上有的，作为随机生成函数的input的seed🌱 $k_r$和$k_h$：生成token set和rule set使用 密钥的传输和验证这里的密钥传输和验证指得是将$k_s$和$k_h$从C传到RG（中途要经过MB），第一次传输使用RG的公钥加密传过去，即$E(k_h^{‘}, k_r^{‘}){ {PK}{RG} }$ ，RG收到后解析出$k_h^{‘}$和$k_r^{‘}$。第二次用来验证收到的和传送的是否一致，使用密钥对随机数$rand_c$计算哈希值，传送$E(H(rand_c){k_h^{‘} }, H(rand_c){k_r^{‘} }){ {PK}{RG} }$，RG收到后解密出来与第一次收到的对比完成验证过程。 对TLS密钥的数字验证这一部主要避免在判断CS谁是骗子的问题上时的无据可依。首先在最开始，MB分别传输给CS一个$rand_{MB}$，然后CS分别计算$E(rand_{MB}){k{TLS} }$并传给MB，MB比较一致性，通过后把$&lt;rand_{MB},E(rand_{MB})_{k_{TLS} }&gt;$记录下来 B. Obfuscated rule Generation下图的伪代码说明得很好了 C. Randomized Token Generation 伪代码说明得比较清楚，只需要注意在验证通过后还需要去验证CS是否都诚信，具体过程间前所述。同时这里可以参考PrivDPI整一个table来记录次数 D. Token Detection E. Trafﬁc Consistency Detection这里使用S来验证C发送的明文和token是否一致，即S也用明文来生成token，对比之后就可以确认 F. Disputes Resolution当出现攻击模型中的第一种，即CS中有一个有恶意的情况时，就需要RG做一个裁判了。S将$k_{TLS}$和$E(M){k{TLS} }$传给RG，当然为了防止被别人看到可以用RG的公钥加密。然后MG把之前setup存的数字收据发给RG，他经过一波验证后，可以判断出S的真实性。既然S真实了，那么C的验证RG直接把明文解析出来手动检测有没有敏感流量就👌 安全性分析","link":"/2020/09/25/Encrypted-Traffic-Detection-System/"},{"title":"PrivDPI","text":"论文原链接： keywords：Network privacy; Encrypted traffic inspection; Middlebox privacy 研究的主要问题在数据传输过程中，我们通常需要一个中间件来完成对传输内容的检测（不然，有人发敏感信息我们怎么拿住他❕），在传统模式里，赋予了中间件可解密信息的权力，他们通过对解密后的明文信息进行检测发现异常流量。However，现在人们十分注重个人隐私，我们不希望在传输过程中有中间者窥探我们的信息，但同时也不能让整个流量传输毫无监管。在这样的场景下，我们需要研究出一个能对密文关键词（敏感词）做检索的系统。可以想象，我们有一下安全需求： 传输的双方不可以通过手段获取我们的关键词检测规则，否则他们可以针对检测的关键词做绕过等小聪明处理 中间件不可以获取到任何有关明文的信息 已有研究成果已有的BlindBox可以完成大多数的功能，如密文关键词检索 本论文主要贡献点 时间上通过每次会话只建立一次缩短，且关键词信息可重复使用 加密规则生成得更有效果 重点算法设计 这个图是整个系统最关键的组成部分。他们的角色分工如下：RG：规则(rule)的制订者，他来告诉MB也就是做检测工作的工具人做事儿的规矩（MB：教我做事儿？？💢）。数学表达上，它传输过去的将是一个三元组。 MB：检测工具人，执行各种机械操作。他既不能知道C和S在交换什么小秘密，也不能去揣测上级RG大哥的具体规则要求，并且要为RG大哥的规则做掩护。因此简单来说，他主要是一个比对操作，用从RG处得到的规则来审查C。 C：👦 S：👩 Notation TLS传输协议： Obfuscated rule： 整体工作流程Setup完成基本准备工作，MB从RG那里获取规则集；C和S建立会话密钥key PreprocessingMB和C&amp;&amp;S交流得以获取一系列可重复使用的模糊规则（reusable obfuscated rule），所谓模糊就是这个过程要让双方都相互看不起，即MB无法得到C和S使用的key，同时C和S无法知晓MB从RG处得到的规则 Session Rule Preparation在preprocessing阶段生成的reusable obfuscated rule是一个C/S交流过程中比较固定的参数，在它的基础上我们生成每个会话的session rule（至于为什么session rule和obfuscated rule不可以是一个，是因为我们不希望每次会话建立，每次会话密钥改变就重新走一套preprocessing的过程，很废时间），在这里可以把obfuscated rule看作是“seed🌱”。 Token EncryptionC将它要传输的数据tokenizes，生成的token在加密传输给MB Token Detection这一步主要就是由MB控制完成，他收到来自C的加密后的token，同时他手里有之前从RG里得到的rule以及在session rule preparation中得到的session rule。第一步，他先用session rule来加密他的rule(📄这里的rule定义有点多，要注意区分)，然后就是比对的工作了 Token Validation这个工作仅当C/S中有一个是坏人的时候实施。方法是验证他们的token（这我还没理解清楚） Setup在setup过程中，我们规定了如下内容： 在RG中有很多rule，对于他的rule集合，我们取${r_i \\in R}$（这里$R$是rule domain），对于每一个$r_i$，RG选择一个随机的$\\alpha \\in Z_p$，以及随机的$s_i \\in Z_p$（这些随机的数字会方便之后来构造规则的保密性）。在前面选取的随机数基础上，我们计算出$A=g^a$，$R_i=g^{\\alpha \\cdot r_i+s_i}$，同时为了认证RG的身份，需要计算出$signs (R_i)$，最终RG把三元组$(s_i, R_i, signs(R_i))$发送给MB。 因为我们设计的是一个非对称密钥体系，所以需要设置公钥和私钥。公钥就是$A$，私钥则是CS握手建立TLS连接时产生的伪随机数，之后以这个伪随机数为源，生成以下三个keys： $k_{rand}$：作为生成之后的randomness的”seed🌱”，并且由于CS拥有的同样的$k_{rand}$，因此之后生成的随机序列也应当是一样的 $k$：用来生成reusable obfuscated rules，以及随后的session rules，且$k \\in Z_p$ $k_{TLS}$：用来加密TLS传输的流量 Preprocessing Protocol 这一步需要在第一次TLS session建立完成后立马执行，目的在于建立一系列快速、可重复使用的obfuscated rule。 这个可重复使用的rule就是： ​ $$I_i=g^{k \\cdot \\alpha \\cdot r_i +k^2}$$ 在最简单情况中，这个$I_i$是通过MB与C的交流形成的， MB计算$R_i=g^{\\alpha \\cdot r_i+s_i}$传给C，C计算出$I_i$后再传给MB 。但是我们需要基于此，做一些优化以增强安全性保护。 为了防止MB出了异心，比如自己去构造一个$R_i$，因为这里面有关键词匹配，它就可以用来解读密文信息，我们添加了一个$signs(R_i)$，利用签名防伪性（这里需要C去验证签名） 为了防止C出现异心，比如传MB一个$k_c$，自己却用别的，或者在之后的由$k_c$生成的$k_i$中出岔子，MB必须做一定的检查，在检查第一个$k_c$时，通过去比对C传的和S传的是否相等来做（要是CS都是骗子，那没办法噢）；在验证后续的$k_i$是否正确时，MB直接自己一个个算，再和C比对。上述是可用的方法之一，论文后面有提到效率更高的方式 为了防止C去窥探到rule的秘密，我们生成$R_i$的时候加入了随机数，就是这个作用 Session Rule Preparation Protocol 流程图已经很明确地表示出算法的过程，这里只需要强调一点，即为了防止暴力攻击，在一定session结束后会重新启动一次preprocessing Token Encryption Algorithm 这一步主要作用是C在操作，它需要将信息隐晦地传输给MB，而不能直接明文将关键词传输过去，因为之后MB要用session rule和它传输过来的内容做比对，因此C对文本的操作需要和MB保持一致性。 首先是一般文字$\\rightarrow$token：最直接的是把整个单词记录下来放在8byte大小的token里，改进后可以设置前缀后缀，或者语句的边界（我们可以思考更新的方式） token$\\rightarrow$加密后的token：加密方式和MB的rule的加密方式一致（之前相当于已经商量出一个共同密钥了），同样也要区分第一次还是后续的 token的可重复使用：这里使用一个记录三元组的counter table，每次遇到新的再添加，已有的话主要增加次数或者因为整体更新后（上面一块提到过重新启动的问题）去更新参数，这样可以提升效率 token防频率攻击：这里token最后会有一个hash(AES)，并且加入随机salt。salt是根据$k_{rand}$生成的，所以也不需要每次和MB同步 Token Detection Algorithm 就是最后比较的步骤，其中$ct_{r_i}$指这个rule出现的次数，初始置为0。 fast search tree 可拓展的点 在获取token时加入机器学习的算法 使用区块链分布式算法","link":"/2020/09/24/PrivDPI/"},{"title":"Spring boot的第一个简单应用","text":"​ 计网实验的时候需要自己写网页来抓包，我本来也想了解一下spring boot架构，之前用过beego，但时间有限，就直接抓起来弄，没有系统地去看，粗制滥造了一个，但是有些遇到的问题和感受还是想记录下来，之后去学这个框架的时候，也可回过头看看。 ​ 目前实现了几个页面，部署在服务器，没有用数据库，就是展示页面，然后设置了一些http缓存，安全验证的东西。 创建spring boot项目直接上官网或者idea里弄，需要支持spring web和spring security，官网上弄得话，下载解压，用idea打开即可。没有配置maven的记得提前弄好。（补充这东西的作用，目前看可以方便写代码时的智能补充+package） 打开后可以先添加为maven project，会有诸多好处。如下图所示，点击+号添加这个项目的pom.xml后，再点击package运行： （运行是点击Maven Projects框框里的小绿箭头噢） 这样一弄后有些东西用起来就舒服多啦，比如import不用去刻意写，可以直接点击错误的地方，看提示直接加进去就好，运行也不必输命令行：mvnw spring boot:run。之后肯定想测试一下，就打开上图的那个文件，这里有个main，是项目的入口，初始里面的内容和我们使用的spring security有关。 和这个含有main的文件同一路径下添加MainController.java文件（这个controller的含义可以具体去看看MVC模型是怎么回事儿的，这里不详细展开），然后将下面的内容复制进去。 123456789101112131415package com.zjn.network2;//这里根据你的名称改import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.ResponseBody;@Controllerpublic class MainController { @RequestMapping(&quot;/hello&quot;) @ResponseBody public String task1() { return &quot;Hello world!&quot;; }} 之后直接去main那里运行，没有错误的话，到浏览器localhost:端口号/hello上打开，它会跳转到login界面，用户名可以随便一点，密码在你的终端运行内容有，复制登陆进去，就可以看到打印的hello world字符。这个端口号一般默认是8080，但我部署设置后在application.properties中改动为了8800，这个不担心，看看终端输出即可。 返回html页面上面的hello例子，直接返回了字符串，但如果要返回html文档页面呢？我给出下面的例子： 12345678910111213141516171819202122232425262728293031323334package com.zjn.network2;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.ResponseBody;@Controllerpublic class MainController { @RequestMapping(&quot;/task1&quot;) @ResponseBody public String task1() { return &quot;Hello zjn 这是计网实验一的第一项&quot;; } @RequestMapping(&quot;/task2&quot;) public String task2() { return &quot;task 2&quot;; } @RequestMapping(&quot;/task3&quot;) public String task3() { return &quot;task 3&quot;; } @RequestMapping(&quot;/task4&quot;) public String task4() { return &quot;task 4&quot;; }} 还是刚刚创建的MainController文件，不过现在换成上面的内容。task1返回的是字符串，而后面几个是返回的对于名字的html文档。区别在哪里呢？看上面@的内容你就明白了，现在就要去创建这几个html文档，在下面目录中创建： 并且在application.properties中写下面内容： 1234# 定位模板的目录spring.mvc.view.prefix= /templates# 给返回的页面添加后缀名spring.mvc.view.suffix=.html 至于html的内容可以直接输入，想好看一点可以markdown直接转html，再自由一点自己去写html和css这些样式吧（作为后端的确实还弄不来…..）。弄好后，老样子去运行试试吧。 http304缓存机制https://www.jdon.com/50543这篇文章是我看到的最有用的一个，原文应该是搬运的英文的。但是在实现过程中还是做了一些修改。 文末提到的addUrlPatterns(&quot;/*&quot;)最好在我们的main中修改一下，这个很巧是在做security中自带的。 我的具体task 2代码如下： 12345678910111213141516@GetMapping(&quot;/task2&quot;) ResponseEntity&lt;String&gt; task2(WebRequest request) { ZonedDateTime expiresDate = ZonedDateTime.now().with(LocalTime.MAX); String expires = expiresDate.format(DateTimeFormatter.RFC_1123_DATE_TIME); String eTag = DigestUtils.md5DigestAsHex(expires.getBytes()); CacheControl cacheControl = CacheControl.maxAge(30, TimeUnit.MINUTES); if (request.checkNotModified(eTag)) { return null; } return ResponseEntity.ok() .eTag(eTag) .cacheControl(cacheControl) .body(&quot;task 2&quot;); } 注意到其实我舍弃了传我的html文档，因为ResponseEntity里面不是很好操作，一般需要和前端有一些交互才能做到。第二我要用LocalTime.MAX让我的时间是固定的，这样生成的etag才会一样，但其实这个值应该有真实含义，即最后一次修改时间，我这里只是达到一个出现304的需求，没有符合缓存设置的需求。其实这里看到了顺便去弄清ResponseBady和这个ResponseEntity用法区别，弄请http缓存设置是比较有益的。 部署到服务器这一篇内容真的很详实了https://blog.csdn.net/Mou_Yang/article/details/102137861我就总结一下步骤，和说一点小坑。 去阿里云等地方弄一个服务器，再找个趁手的远程连接软件，我用的xshell，用阿里云自己的倒也可以 服务器拿到手，当然得配置一些东西，其实部署上去就是让远程的另一台电脑帮你跑程序，用那个电脑的ip去访问页面，就不用在localhost了，并且日夜不息……所以你本地怎么让项目运行起来，那你就得让远程的怎么运行，不过这远程的是Linux，你不能照你本地的OS那么整，所以这个的话，其实就配个jdk就好，能跑java就行，现在还不用数据库。里面注意一点，在设置jdk环境变量的时候我总是弄不对，java -version找不到，它会提示一个命令，我后来没办法去试了一下，jdk给安好了，环境变量也没问题了……所以人家官方的错误提示还是很有用的！（可能不适用于所有人的情况） 把项目打包成jar，在服务器上运行，运行结果和本机没啥区别，再在浏览器上访问，完事儿。当然想日夜不息，添点东西就好咯，我这个简单的就没必要了 后记这个真的再简单不过，之前数据库要弄一个非常原始的java web项目都比这个要难一些，但也让我充分明白了框架真的好呀！（但全程自己写会加深对这个流程的理解），还有就是这个根本没有涉及到后端逻辑，最多熟悉一下spring boot使用哈哈哈。因为我是基本弄完以后才想着写这个，过程中的一些步骤错误可能会有点忘了，还有就是没有上几个对我帮助比较大的贴子（啊抱歉…他们还非常详细）下面的几点是我希望之后我来补充或者去学习的内容： spring boot的常用几个依赖的介绍（等我用的时候） 怎么去更好使用spring security，比如不要随机密码，不是每个页面都拦截，login页面的优化…. spring boot加入后端逻辑 有些网上图片的地址插入进来，抓包后只显示一次抓图片的过程（这大概是计网的问题… …………. github代码链接：https://github.com/Garlicisnotmyfavor/network1.git","link":"/2020/05/06/Spring-boot%E7%9A%84%E7%AC%AC%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E5%BA%94%E7%94%A8/"},{"title":"docker,k8s,虚拟机","text":"因为项目原因，使用过docker，tke（腾讯云）的k8s，平时用虚拟机也挺多，但是一直对容器，云服务这块的概念不是很深，这篇文章就是想要梳理一下这些概念，同时完成本地的一个k8s部署环境。 现在运行一个应用并不是最初课程中接触的那样：购买一个远程服务器，把远程服务器的环境配好，让服务器日夜不停地运行然后用户来访问。首先我们希望每次换一个机器跑应用时不需要重新配置哪些杂碎的东西。其次我们可能不能很好利用一整个服务器的资源，更节约的方式是按使用的资源来付费。最后，我们希望一个应用能较自动地在多个服务环境中运行，并且他们能相互协调，调整负载，调整运行状态。下面先从云计算。 云计算云计算是分布式计算、并行计算、网络存储、虚拟化、负载均衡、内容分发网络等融合的产物。 按需分配资源，如在以前的开发模式下，你需要用一整台服务器来运行调试你的应用程序，但是其实你用不了这个服务器的全部资源，这会物超所值，因此产生了云服务的模式，它是按照你使用的存储空间，耗费的计算资源来收费的，用多少给多少，而不是一台一台卖。 软硬件是分散在分布式计算机中的，而不是特定的本地计算机或者远程服务器。 公共云 Software-as-a-Service, SaaS（软件即服务）：如Gmail，以单一网络软件为主导。 Platform-as-a-Service, PaaS（平台即服务）：以平台形式提供应用开发、部署平台等系统功能。 Infrastructure-as-a-Service, IaaS（基础设施即服务）：提供顶尖的软硬件服务（感觉像拆开卖东西），如服务器、存储系统、网络硬件、虚拟化软件等。 私有云 大企业不希望将自己的信息放在公共平台上。 软件开发中，环境配置是很麻烦的，如操作系统的不统一、库的下载、组件的安装。“在我的机器可以跑了”并不意味在别人的电脑里能轻松跑一起。我们期待一个能复制打包相同环境的机制。在谈及docker之前，先简单介绍一些其他的环境解决方案。 虚拟机他可以完成在一个机器中创建你想要的运行环境，即便操作系统不同也可以，并且它不会影响你本机的各种运行。缺点在于，它模拟了底层环境，因此资源占用多；作为完整的操作系统，它需要你手动做用户登录等系统级操作；启动慢。 Linux容器（LXC）不模拟一个完整的操作系统，而是对进程进行隔离。对于容器里的进程来说，它接触到的各种资源都是虚拟的，从而实现与底层系统的隔离。相比于虚拟机，它启动快，是启动本机的一个进程；资源占用少，多个容器还可以共享资源；体积小，只包含使用到的组件。 docker属于LXC的一种封装，提供简单易用的容器使用接口。Docker将应用程序与该程序的依赖，打包在一个文件里面。运行这个文件，就会生成一个虚拟容器。 docker的用途 一次性环境：本地测试时用可以快速进入到测试的环境中。 提供弹性的云服务：Docker容器可以随开随关，适合动态扩容和缩容（还不是很懂这点）。 组建微服务架构：如果你的系统需要不同的环境的构建联合起来运行，那么使用几个不同的容器分别运行起来可以模拟微服务。 镜像(image)和容器镜像就像是面向对象中的对象，而容器像是实例。通常我们的应用程序都是基于一个现有的基础镜像，然后加入自己的特性化设置变为我们自己使用的容器环境，自己的这个新镜像也可以上传到docker hub，如果是公开的化，别人也就可以使用你的镜像啦。 docker的安全问题，命名空间 应用程序如何使用docker 写Dockerfile：用来配置image从而生成自己的image。 创建image文件：docker image build 生成容器：docker container run 与虚拟机的区别与通过Hypervisor把底层设备虚拟化的虚拟机不同，Docker直接移植于Linux内核之上，通过运行Linux进程将底层设备虚拟隔离，这样系统性能的损耗也要比虚拟机低的多，几乎可以忽略。同时，Docker应用容器的启停非常高效，可以支持大规模的分布系统的水平扩展，真正给企业开发带来福音。 docker-compose我们项目使用了这个命令，但是我现在还不是很清楚这个 docker容器的使用是很方便与集群部署的，下面主要介绍以一个集群部署工具 k8sKubernetes是一个可移植的，可扩展的开源平台，用于管理容器化的工作负载和服务。k8s集群由代表控制平面的组件和一组称为节点的机器组成。 节点k8s通过将容器放入在节点上运行的Pod中来执行你的工作负载。节点可以是一个虚拟机或者物理机器，每个节点都包含用于运行Pod所需要的服务，这些服务由控制平面管理。节点上的组件包括kubelet、容器运行时、kube-proxy。 云控制管理器之前项目在腾讯云使用k8s应当就是使用了这个概念的服务。 其中云控制器管理器中的控制器包括： 节点控制器：为服务器初始化一个Node对象；设置Node注解和标签；获取节点网络地址和主机名；检查节点状态 路由器控制器：方便集群中不同节点上的容器之间可以相互通信（可能也会为Pod网络分配IP地址） 服务控制器：基于云服务平台上，方便用户操作 Pod形象的比喻，如果说容器是豌豆的话，那pod就是豌豆荚，它包含了一个或多个容器，且这些处于一个pod中的容器共享存储，网络，以及怎样运行这些容器的声明。Pod的共享上下文包括一组Linux名字空间、控制组和可能一些其他的隔离方面，即用来隔离Docker容器的技术。 通常我们不需要自己来建Pod，而是使用如Deployment这种工作负载资源来创建Pod。 Deployment管理Pods，合理地调配工作负载，动态创建和销毁Pod。 服务将运行在一组Pods上的应用程序公开为网络服务的抽象方法。k8s为Pods提供自己的IP地址，并为一组Pod提供相同的DNS名，并且可以在它们之间进行负载均衡。 其他的一些概念sandboxHyper-Vk8s实践因为这次是本地实践，没有tke提供地控制环境，所以需要安装一些别的东西。 安装工具：https://kubernetes.io/zh/docs/tasks/tools/ 包括kubectl、minikube 其中，我没有看到具体minikube应该怎么下载，参考下面这个链接： https://developer.aliyun.com/article/221687 问题 k8s集群部署上的节点ip变化，那访问时的地址如何统一（见服务处的回答，会有相同的DNS域名） 参考链接：https://www.ruanyifeng.com/blog/2018/02/docker-tutorial.html https://kubernetes.io","link":"/2020/11/03/docker-k8s-%E8%99%9A%E6%8B%9F%E6%9C%BA/"},{"title":"fabric sdk","text":"之前确实有想要好好做这块，但是基础知识的学习有些跟不上，所以可能等有时间去关注的时候补充，目前的都很基础 关于fabric sdk的文中介绍网站：https://hyperledgercn.github.io/hyperledgerDocs/sdk-design_zh/ peer：锚节点是通道中能被所有对等节点探测、并能与之进行通信的一种对等节点。通道中的每个成员都有一个（或多个，以防单点故障）锚节点，允许属于不同成员身份的节点来发现通道中存在的其它节点。 block：在一个通道上，（区块是）一组有序交易的集合。区块往往通过密码学手段（Hash 值）连接到前导区块。 chain：chain就是block之间以hash连接为结构的交易日志。peer从order service接收交易block，并根据背书策略和并发冲突标记block上的交易是否有效，然后将该block追加到peer文件系统中的hash chain上。 chaincode：链码是一个运行在账本上的软件，它可以对资产进行编码，其中的交易指令（或者叫业务逻辑）也可以用来修改资产。 channel：通道是构建在“Fabric”网络上的私有区块链，实现了数据的隔离和保密。通道特定的账本在通道中是与所有对等节点共享的，并且交易方必须通过该通道的正确验证才能与账本进行交互。通道是由一个“配置块”来定义的。 commitment：一个通道中的每个对等节点都会验证交易的有序区块，然后将区块提交（写或追加）至该通道上账本的各个副本。对等节点也会标记每个区块中的每笔交易的状态是有效或者无效。 Concurrency Control Version Check： CCVC是保持通道中各对等节点间状态同步的一种方法。对等节点并行的执行交易，在交易提交至账本之前，对等节点会检查交易在执行期间读到的数据是否被修改。如果读取的数据在执行和提交之间被改变，就会引发CCVC冲突，该交易就会在账本中被标记为无效，而且值不会更新到状态数据库中。 configuration block：包含为系统链（排序服务）或通道定义成员和策略的配置数据。对某个通道或整个网络的配置修改（比如，成员离开或加入）都将导致生成一个新的配置区块并追加到适当的链上。这个配置区块会包含创始区块的内容加上增量。 consensus：共识是贯穿整个交易流程的广义术语，其用于产生一个对于排序的同意书和确认构成区块的交易集的正确性。 current state：ledger的current state表示其chain交易log中所有key的最新值。peer会将处理过的block中的每个交易对应的修改value提交到ledger的current state，由于current state表示channel所知的所有最新的k-v，所以current state也被称为World State。Chaincode执行交易proposal就是针对的current state。","link":"/2020/05/06/fabric-sdk/"},{"title":"git常用操作","text":"版本管理我基本都是用git，仓库github，原理部分这里不说，但给了一个廖雪峰的链接，那个很详细。这篇主要对付我这种有时候忘指令懒得查的这种人，哈哈哈，比较方便。 链接就是下面这个： https://www.liaoxuefeng.com/wiki/896043488029600/898732864121440 将本地项目挂到github去本地文件夹内依次运行: 123456git initgit add .git commit -m &quot;first commit&quot;git remote add orgin 你建立的github仓库的ssh链接(如果你仓库里已经有了文件，即便是readme.md，需要运行：git pull --rebase origin master)git push -u origin master 一般项目中会有gitignore，就是提交远程时忽视的内容，一定要注意！ tips1git fetch origin 得到所有的远程分支","link":"/2020/05/07/git%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"title":"iceberg","text":"大数据处理平台里的n多名词对我来说都很陌生，😔这篇主要是普及的东西，还没有形成自己的体系很乱有些东西也还没来得及写上去，持续补充….. Hadoop（分布式系统基础架构）一个开源的分布式计算框架，允许使用简单编程模型跨计算机集群处理大型数据集合的框架，设计初衷是将单个服务器扩展成上千个机器组成的一个集群为大数据提供计算服务。 Spark（计算引擎）Spark其实是最初的MapReduce计算引擎的二代版，优化了抽象层次低，中间结果难复用，交互性不好等问题 用于Hadoop数据的快速通用计算引擎，在大的Hadoop中的优势如下： 速度快 易用性：可以使用java，Scala，Python，R以及SQL快速写Spark应用 通用性：支持SQL，流数据处理及复杂分析 Spark SQL DataFrame API: 统计计算时，最常接触的部分 Spark Streaming: 流式计算，也可被用作数据集成工具，DataFlow 数据集成部分的实现载体 Spark Mlib: 机器学习部分，主要是统计学习相关，特征工程/分类/聚类/回归/频繁模式 … Spark GraphX: 图计算相关，标签传播 支持多种模式运行：Hadoop，Kubernete，云等 Scala（语言）一种语言，支持Spark（但Spark可以使用多种语言进行交互） HDFS（Hadoop Distributed File System）它是Hadoop兼容最好的标准级文件系统 Hive提供数据汇总和特定查询的数据仓库 Kudu列式存储，偏向于实时计算 OLAP HBase列式存储，偏向于海量事物 OLTP Impala/Presto内存计算MPP引擎，比 Spark 有速度&amp;并行查询优势 Flink比 Spark 做的更好的流计算。 流式模式： 延迟短 数据完整度较差：因为流式引擎不会等到所有数据到齐后再计算，有一个watermark的概念，当数据的时间小于watermark时就会被丢弃。在大部分场景中，用户需要开发两个程序，一是流式数据生产流式结果，二是批式计算任务，用于次日修复实时结果 成本高 批式模式：小时任务或者天任务来做数据计算 延迟：小时级或者天级别的延迟 数据完整度较高 成本低 Copy-On-Write Table 对于 Copy-On-Write Table，用户的 update 会重写数据所在的文件，所以是一个写放大很高，但是读放大为 0，适合写少读多的场景。对于这种 Table，提供了两种查询： Snapshot Query: 查询最近一次 snapshot 的数据，也就是最新的数据。 Incrementabl Query:用户需要指定一个 commit time，然后 Hudi 会扫描文件中的记录，过滤出 commit_time &gt; 用户指定的 commit time 的记录。 Merge-On-Read Table 对于 Merge-On-Read Table，整体的结构有点像 LSM-Tree，用户的写入先写入到 delta data 中，这部分数据使用行存，这部分 delta data 可以手动 merge 到存量文件中，整理为 parquet 的列存结构。对于这类 Tabel，提供了三种查询： Snapshot Query: 查询最近一次 snapshot 的数据，也就是最新的数据。这里是一个行列数据混合的查询。 Incrementabl Query:用户需要指定一个 commit time，然后 Hudi 会扫描文件中的记录，过滤出 commit_time &gt; 用户指定的 commit time 的记录。这里是一个行列数据混合的查询。 Read Optimized Query: 只查存量数据，不查增量数据，因为使用的都是列式文件格式，所以效率较高。 当 Flink 程序执行时，其被映射成 Streaming Dataflow，由如下的部分组成： Source (operator)：接收外部输入给 Flink； Transformation (operator)：中间对 stream 做的任何操作； Sink (operator)：Flink 输出给外部。 Druid预聚合CUBE引擎 ElasticSearch（搜索分析引擎）是一个分布式的开源搜索和分析引擎，适用于所有类型的数据，包括文本、数字、结构化和非结构化数据。 iceberg（数据湖框架）什么是数据湖框架？其实是一种对仓库中数据的管理框架，之前使用的大多是Hive，但是单一使用它作为数仓不能满足对数据存取效率的要求，现在出来的常用的三个开源软件Delta Lake，Apache Hudi和Apache iceberg都指向对Hive的改良，既提供一个数据仓库的功能，同时还给仓库配上标签信息、监控工具、智能运输等功能。其中iceberg就专注于用iceberg table来统一所有的table iceberg可适配Spark等引擎提供高性能的读写和元数据管理功能，介于计算引擎之下存储引擎之上的一种数据存储组织格式。 Q：隐式分区怎样做到的 流式计算checkpoint Streaming Write的模板代码 12345678val tableIdentifier: String = ...data.writeStream .format(&quot;iceberg&quot;) .outputMode(&quot;append&quot;) .trigger(Trigger.ProcessingTime(1, TimeUnit.MINUTES)) .option(&quot;path&quot;, tableIdentifier) .option(&quot;checkpointLocation&quot;, checkpointPath) .start() 文件存储的方式：哈希，csv，parquet，orc，Avro（向量化读取方式统一） 参考链接 https://www.cnblogs.com/wing1995/p/9300120.html https://www.elastic.co/cn/what-is/elasticsearch https://zhuanlan.zhihu.com/p/149706105","link":"/2021/01/21/iceberg/"},{"title":"lq决赛题练习","text":"11.14就是决赛了，还是抽时间来准备一下。 三角形面积已知三角形三个顶点在直角坐标系下的坐标分别为：(2.3, 2.5)(6.4, 3.1)(5.1, 7.2) 求该三角形的面积。 注意，要提交的是一个小数形式表示的浮点数。要求精确到小数后3位，如不足3位，需要补零。 海伦公式：$$A=\\sqrt{s(s-a)(s-b)(s-c)}$$其中$s=a+b+c$ 浮点数输出格式问题&quot;%3.0f&quot; ：输出的数整数部分需要占3个字符 &quot;%6.2f&quot; ：输出的小数部分至少占2位，不足补零，整个数需要占6位，其中包括小数2位和小数点1位，也就是整数部分占3位 阅兵方阵x国要参加同盟阅兵活动。主办方要求每个加盟国派出的士兵恰好能组成 2 个方阵。x国发现弱小的 y国派出了130人的队伍，他们的士兵在行进中可以变换2种队形： 130 = 81 + 49 = 9^2 + 7^2 130 = 121 + 9 = 11^2 + 3^2 x国君很受刺激，觉得x国面积是y国的6倍，理应变出更多队形。于是他发号施令：我们要派出一支队伍，在行进中要变出 12 种队形！！！ 手下人可惨了，要忙着计算至少多少人才能组成 12 种不同的双方阵。请你利用计算机的优势来计算一下，至少需要多少士兵。 （ps: 不要失去信心，1105人就能组成4种队形了） 注意，需要提交的是一个整数，表示至少需要士兵数目，不要填写任何多余的内容。 没有什么算法技巧，要么提前处理出平方数的表，要么整一个和的数组来看多久到12。总之相对来说都比较暴力。 找假币在8枚硬币中，有1枚假币，假币外观与真币一模一样，只是重量略轻或略重一点。给你一架天平，要求最多称3次，就找出假币，并且知道它是重一些还是轻一些。下面的代码给出一个解决方案，仔细分析逻辑，填写划线位置缺少的代码。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273#include &lt;stdio.h&gt;int balance(int a, int b){ if(a&lt;b) return -1; if(a&gt;b) return 1; return 0;}void judge(char* data, int a, int b, int std){ switch(balance(data[a],data[std])){ case -1: printf(&quot;%d light\\n&quot;, a); break; case 0: printf(&quot;%d heavy\\n&quot;, b); break; case 1: printf(&quot;err!\\n&quot;, b); }}// data 中8个元素，有一个假币，或轻或重void f(char* data){ switch( ____________________________________ ){ // 填空 case -1: switch(balance(data[0]+data[4],data[3]+data[1])){ case -1: judge(data,0,3,1); break; case 0: judge(data,2,5,0); break; case 1: judge(data,1,4,0); } break; case 0: judge(data,6,7,0); break; case 1: switch(balance(data[0]+data[4],data[3]+data[1])){ case -1: judge(data,4,1,0); break; case 0: judge(data,5,2,0); break; case 1: judge(data,3,0,1); } break; } }int main(){ int n; char buf[100]; scanf(&quot;%d&quot;, &amp;n); gets(buf); int i; for(i=0; i&lt;n; i++){ gets(buf); f(buf); } return 0;} 请注意：只需要填写划线部分缺少的内容，不要抄写已有的代码或符号。 这个代码有些个问题。解题思路就是不断比较，相等的结果就认为上称的都是对的，然后在剩下的里面找不等个数来替换，是一个人算的题目。 约瑟夫环n 个人的编号是 1~n，如果他们依编号按顺时针排成一个圆圈，从编号是1的人开始顺时针报数。（报数是从1报起）当报到 k 的时候，这个人就退出游戏圈。下一个人重新从1开始报数。求最后剩下的人的编号。这就是著名的约瑟夫环问题。 本题目就是已知 n，k 的情况下，求最后剩下的人的编号。 题目的输入是一行，2个空格分开的整数n, k要求输出一个整数，表示最后剩下的人的编号。 约定：0 &lt; n,k &lt; 1百万 例如输入：10 3 程序应该输出：4 推导公式：$$f(N, M)=(f(N-1,M)+M)%N$$其中N是指有N个人，M指第M个人退出，F返回的是退出的人的编号。代码如下： 1234567891011121314151617181920#include &lt;iostream&gt;using namespace std;const int N = 1000010;int f[N];int main(){ int n, k; cin &gt;&gt; n &gt;&gt; k; f[1] = 0; for (int i = 2; i &lt;= n; i ++ ) f[i] = (f[i - 1] + k) % i; cout &lt;&lt; f[n] + 1 &lt;&lt; endl; return 0;} 自描述序列小明在研究一个序列，叫Golomb自描述序列，不妨将其记作{G(n)}。这个序列有2个很有趣的性质: 对于任意正整数n，n在整个序列中恰好出现G(n)次。 这个序列是不下降的。 以下是{G(n)}的前几项： n 1 2 3 4 5 6 7 8 9 10 11 12 13G(n) 1 2 2 3 3 4 4 4 5 5 5 6 6 给定一个整数n，你能帮小明算出G(n)的值吗？ 主要是找规律，在list中记录，但是有个问题就是100%的数据中很大，int大概10位数，那个超过了，首先存储量是个问题。但是可以弄反函数，这样G(n)是没有超过那个开销的。 123456789101112131415161718192021222324252627282930313233#include &lt;iostream&gt;using namespace std;typedef long long LL;const int N = 1000010;int g[N]; //足够大的表来记录一些东西int main(){ LL n; cin&gt;&gt;n; g[1] = 1, g[2] = 2; //初始的一些值 //这里完全在模拟打表 for(int i=2, j=2; j&lt;N; i++) { for(int k=0; k&lt;g[i] &amp;&amp; j&lt;N; k++) g[j++] = i; } LL s=0, t=0; for(int i=1; i&lt;N; i++){ s+=i*(LL)g[i]; //这里乘起来不知道要干什么 if(s&gt;=n){ s-=i*(LL)g[i]; cout &lt;&lt; t+(n-s+i-1)/i &lt;&lt;endl; break; } t += g[i]; } return 0;}","link":"/2020/11/03/lq%E5%86%B3%E8%B5%9B%E9%A2%98%E7%BB%83%E4%B9%A0/"},{"title":"假设检验","text":"假设检验是统计推断的重要形式，分为两类问题，一类是参数的假设检验，一类是分布的假设检验。作出假设、根据样本所提供的信息，运用统计分析的方法进行判断，从而提出是接受还是拒绝$H_0$的决定，这就是假设检验问题。 假设检验的基本概念问题的提出 我们想要知道工厂生产的零件次品率是否小于4%，但是采用的是抽样检测。这里我们得到抽样检测的结果后，作出如下假设：$H_{0}: p \\leq 0.04, H_{1}: p&gt;0.04$ 公司的包装重量规定为500g，但存在随机误差，正常情况下符合正态分布$N(500,15^2)$，某日随机抽取一定的样本得到相关数据，现在作出假设：$H_0: \\mu=500, H_1: \\mu \\neq 500$ 我们通过计算机生产随机数，现在我们得到了一系列生成的[0,1]的随机数，想要知道这个随机数生成是否是[0,1]之间的均匀分布，作出假设：$H_0: X服从U(0,1) ,H_1:X不服从U(0,1)$ 以上例子中，分别为单侧假设检验、双侧假设检验和非参数的假设检验。 假设检验的接受域和拒绝域以2为例子，推导以下这个问题的解决思路。我们想要通过抽样的数据来判断整个阶段的产品是否正常，那么因为是独立同分布抽样的，抽样出来的产品本身的分布也应当是十分接近整阶段产品的分布才能基本认为$H_0$成立。这里使用样本均值$\\bar{X}$作为总体均值的一个较好估计量，那么$P{ |\\bar{X}-\\mu| &gt; k} = \\alpha$需要成立，其中$\\alpha$为一个小概率，简单来说就是$\\bar {X}$偏离$\\mu$的距离大于$k$这个事件概率足够小。通过现有数据的计算即可判断这个式子是否成立。 假设检验的两类错误 弃真：正确的被拒绝 纳伪：错误的被接受 （这里的分类很类似分类模型中的错误情况） 参数的假设检验单个正态总体均值$\\mu$的检验$H_0$的拒绝域是$|\\bar{X} - \\mu_0|$的值大于一个界限值得区域。 总体方差$\\sigma^2$已知时$$P{ \\frac {|\\bar{X} - \\mu_0|}{\\sigma/ \\sqrt{n} } &gt; u_{\\frac a2}} = \\alpha$$拒绝域为$|u| &gt; u_{\\frac a2}$ ，这里检验方使用了服从标准正态分布得统计量，则称为U检验法。 总体方差$\\sigma^2$未知时 用标准差$S$替代$\\sigma$，$T=\\frac {|\\bar{X} - \\mu_0|}{\\sigma/ \\sqrt{n}} - t(n-1)$，$$P{ \\frac {|\\bar{X} - \\mu_0|}{\\sigma/ \\sqrt{n} } &gt; t_{\\frac a2}(n-1)} = \\alpha$$这里使用了服从$t$分布的统计量，则称为$t$检验法 单侧检验问题 $H_1: \\mu &gt; \\mu_0$：拒绝域为$u &gt; u_{\\alpha}$，$t&gt; t_{\\alpha}(n-1)$ $H_1: \\mu &lt; \\mu_0$：拒绝域为$u &lt; -u_{\\alpha}$，$t&lt;-t_{\\alpha}(n-1)$ 单个正态总体方差$\\sigma^2$的检验[1] 两个正态总体均值差$\\mu_1-\\mu_2$的检验两个正态总体方差比$\\frac {\\sigma_1^2}{\\sigma_2^2}$的检验大样本检验分布的假设检验后续扩展[1] 概率论教材P187 今天时间不够就没有整理完全 碎碎念封面图是动画《借东西的小人阿莉埃蒂》，从小到大我都梦想着有一个小人家族生活在我身旁。选了这张图是因为很喜欢这个拿着武器走向外面的背影，郁郁葱葱又暗藏危机。","link":"/2020/11/09/%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C/"},{"title":"leecode做题笔记","text":"这一部分没什么条理地放我的leecode算法心得 1 两数之和原题链接：https://leetcode-cn.com/problems/two-sum/ 题解链接：https://github.com/Garlicisnotmyfavor/leetcode-practice/blob/master/1.cpp（输入方式有修改） 方法一使用简单的全部遍历，复杂度是$O(n^2)$，我最开始用的就是这个办法，运行速度是384ms（C++确实比python还是快很多😂） 方法二在二层循环中，找另外一个数其实不用全部遍历，而是遍历第一个数后面的即可（这类型的简化方法在当初素数求解算法中有一点点类似） 方法三使用字典来模拟哈希求解，字典是python里的语法，在C++中，可以用数组其实也能达到相同的目的。就是类似把索引和数值的关系反一下，下标来装数值，下标对应的值装的是index。初始化的时候可以所有都放-1，用来判断是否存在这个数值。不过这个方法会空间换时间，出现浪费的空间（对于C++的话是这样，对python的字典倒不存在这个顾虑） 834 树中距离之和原题链接：https://leetcode-cn.com/problems/sum-of-distances-in-tree/ 题解链接：https://github.com/Garlicisnotmyfavor/leetcode-practice/blob/master/834.cpp 拿到这题我感觉会用一点深度/广度优先搜索的思想，感觉是有技巧的一道题，但是我确实….把这些忘完了，然后开始用数组装，暴力求解（用数组是因为我vector用的不熟呀）。暴力结果就是运行一些例子可以，但是总容易出错，不严谨，因为暴力的遍历是会忽略他的树形结构的。下面就主要介绍比较标准的算法和vector使用的一些技巧。 主要方法：树形动态规划 补充代码中的细节： 基于范围的for循环(auto是自动匹配变量类型) 123456789101112int my_array[5] = {1, 2, 3, 4, 5};// 每个数组元素乘于 2for (int &amp;x : my_array){ x *= 2; cout &lt;&lt; x &lt;&lt; endl; }// auto 类型也是 C++11 新标准中的，用来自动获取变量的类型for (auto &amp;x : my_array) { x *= 2; cout &lt;&lt; x &lt;&lt; endl; } 容器的resize()函数：用来划定容器的大小，如 12dp.resize(N, 0);graph.resize(N, {}); 2 两数相加原题链接：https://leetcode-cn.com/problems/add-two-numbers/ 题解链接：https://github.com/Garlicisnotmyfavor/leetcode-practice/blob/master/2.cpp 注意几点坑（以后我做之前一定要想清楚这题到底可以用什么办法，别再暴力了😂）。顺序的问题，按照方便的顺序是无法解读出他本来的值的，我这样弄错了，然后再逆序但是0也会出问题。第二就是有两个0相加的用例，要考虑边界情况。第三就是树的使用，这个我真的生疏了，语法的东西甚至都有点点忘记。（这道题不用将两个数分别给求出来再相加，应该直接相加） 方法一将长度较短的链表末尾补0，让两个长度相等后再一个一个元素对其相加。 获取两个链表的长度 在较短的链表末尾补零 对齐相加考虑进位 方法二不对齐补零，若链表不为空则用 sum(代表每个位的和的结果)加上，考虑进位。 141 环形链表题目链接：https://leetcode-cn.com/problems/linked-list-cycle/ 题解链接：https://github.com/Garlicisnotmyfavor/leetcode-practice/blob/master/141.cpp 解答摘取一个leecode上的作者，他的总结很到位链接：https://leetcode-cn.com/problems/linked-list-cycle/solution/yi-wen-gao-ding-chang-jian-de-lian-biao-wen-ti-h-2/ 无法高效获取长度，无法根据偏移快速访问元素，是链表的两个劣势。然而面试的时候经常碰见诸如获取倒数第k个元素，获取中间位置的元素，判断链表是否存在环，判断环的长度等和长度与位置有关的问题。这些问题都可以通过灵活运用双指针来解决。 Tips：双指针并不是固定的公式，而是一种思维方式~ 先来看”倒数第k个元素的问题”。设有两个指针 p 和 q，初始时均指向头结点。首先，先让 p 沿着 next 移动 k 次。此时，p 指向第 k+1个结点，q 指向头节点，两个指针的距离为 k 。然后，同时移动 p 和 q，直到 p 指向空，此时 q 即指向倒数第 k 个结点。 获取中间元素的问题。设有两个指针 fast 和 slow，初始时指向头节点。每次移动时，fast向后走两次，slow向后走一次，直到 fast 无法向后走两次。这使得在每轮移动之后。fast 和 slow 的距离就会增加一。设链表有 n 个元素，那么最多移动 n/2 轮。当 n 为奇数时，slow 恰好指向中间结点，当 n 为 偶数时，slow 恰好指向中间两个结点的靠前一个(可以考虑下如何使其指向后一个结点呢？)。 是否存在环的问题。如果将尾结点的 next 指针指向其他任意一个结点，那么链表就存在了一个环。 上一部分中，总结快慢指针的特性 —— 每轮移动之后两者的距离会加一。下面会继续用该特性解决环的问题。当一个链表有环时，快慢指针都会陷入环中进行无限次移动，然后变成了追及问题。想象一下在操场跑步的场景，只要一直跑下去，快的总会追上慢的。当两个指针都进入环后，每轮移动使得慢指针到快指针的距离增加一，同时快指针到慢指针的距离也减少一，只要一直移动下去，快指针总会追上慢指针。 根据上述表述得出，如果一个链表存在环，那么快慢指针必然会相遇。实现代码如下： 123456789101112131415161718class Solution {public: bool hasCycle(ListNode *head) { ListNode *slow = head; ListNode *fast = head; while(fast != nullptr) { fast = fast-&gt;next; if(fast != nullptr) { fast = fast-&gt;next; } if(fast == slow) { return true; } slow = slow-&gt;next; } return nullptr; }}; 最后一个问题，如果存在环，如何判断环的长度呢？方法是，快慢指针相遇后继续移动，直到第二次相遇。两次相遇间的移动次数即为环的长度。 3 无重复字符的最长字串字串问题感觉是个典型类问题。相关标签是：哈希表、滑动窗口、双指针。 最暴力的算法是以每个字符为开头去找一个最长的无重复字串，但时间复杂度高了。这里考虑使用滑动窗口思想，设置两个int指向窗口的头和尾。 题目链接：https://leetcode-cn.com/problems/longest-substring-without-repeating-characters/ 题解链接：https://github.com/Garlicisnotmyfavor/leetcode-practice/blob/master/3.cpp 1108 IP地址无效化题目链接：https://leetcode-cn.com/problems/defanging-an-ip-address/ 题解链接：https://github.com/Garlicisnotmyfavor/leetcode-practice/blob/master/1108.cpp 没什么难度，熟悉一下字符串的一些函数即可 16 最接近的三数之和题目链接：https://leetcode-cn.com/problems/3sum-closest/ 题解链接：https://github.com/Garlicisnotmyfavor/leetcode-practice/blob/master/16.cpp 最暴力的就是$O(n^3)$，想要优化时间复杂度，先对数组进行排序，之后固定一个值，对另外两个值使用双指针，有针对性地调节一端的值，能将时间复杂度降到$O(n^2)$ 910 最小差值题目链接：https://leetcode-cn.com/problems/smallest-range-ii/ 题解链接：https://github.com/Garlicisnotmyfavor/leetcode-practice/blob/master/910.cpp 贪心，主要靠数学推理和直觉，重点在于想到要以某个点，大的全减，小的全加 104 二叉树的最大深度题目链接：https://leetcode-cn.com/problems/maximum-depth-of-binary-tree/ 题解链接：https://github.com/Garlicisnotmyfavor/leetcode-practice/blob/master/104.cpp 二叉树的基础问题注意分左右去递归处理 142 环形列表2题目链接：https://leetcode-cn.com/problems/linked-list-cycle-ii/ 题解链接：https://github.com/Garlicisnotmyfavor/leetcode-practice/blob/master/142.cpp 沿袭141的基础做法，计算环的长度，再移动得到切入节点地址，综合应用了双指针的知识 795 区间子数组个数题目链接：https://leetcode-cn.com/problems/number-of-subarrays-with-bounded-maximum/ 题解链接：https://github.com/Garlicisnotmyfavor/leetcode-practice/blob/master/795.cpp 我的方法有做出来，但是相对比较复杂，相当于按照其测试用例改出来的。但看来官方解答，这题确实比较数学。 144 二叉树的前序遍历题目链接：https://leetcode-cn.com/problems/binary-tree-preorder-traversal/题解链接：https://github.com/Garlicisnotmyfavor/leetcode-practice/blob/master/144.cpp 简单的递归，我这里没有考虑使用迭代 612 任务调度器题目链接：https://leetcode-cn.com/problems/task-scheduler/ 解题链接：https://github.com/Garlicisnotmyfavor/leetcode-practice/blob/master/621.cpp 主要靠数学思维 416 分割等和子集题目链接：https://leetcode-cn.com/problems/partition-equal-subset-sum/ 解题链接：https://github.com/Garlicisnotmyfavor/leetcode-practice/blob/master/416.cpp 0-1背包问题 1365 有多少小于当前数字的数字题目链接：https://leetcode-cn.com/problems/how-many-numbers-are-smaller-than-the-current-number/题解链接：https://github.com/Garlicisnotmyfavor/leetcode-practice/blob/master/1365.cpp 计数排序 530 二叉搜索树的最小绝对差题目链接：https://leetcode-cn.com/problems/minimum-absolute-difference-in-bst/ 一个知识点（但我当时做的时候还没有掌握），就是二叉搜索树的中序遍历数值是排好序了的。 546 移动盒子题目链接：https://leetcode-cn.com/problems/remove-boxes/ 动态规划，深度优先搜索，我还是没有掌握解这题的诀窍。 24 两两交换链表中的节点题目链接：https://leetcode-cn.com/problems/swap-nodes-in-pairs/ 使用递归的方法，比较简单好想 840 矩阵中的幻方https://leetcode-cn.com/problems/magic-squares-in-grid/ 暴力算法，加一点数学推导的规律 快慢指针/反转列表1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950class Solution {public: bool isPalindrome(ListNode* head) { if (head == nullptr) { return true; } // 找到前半部分链表的尾节点并反转后半部分链表 ListNode* firstHalfEnd = endOfFirstHalf(head); ListNode* secondHalfStart = reverseList(firstHalfEnd-&gt;next); // 判断是否回文 ListNode* p1 = head; ListNode* p2 = secondHalfStart; bool result = true; while (result &amp;&amp; p2 != nullptr) { if (p1-&gt;val != p2-&gt;val) { result = false; } p1 = p1-&gt;next; p2 = p2-&gt;next; } // 还原链表并返回结果 firstHalfEnd-&gt;next = reverseList(secondHalfStart); return result; } ListNode* reverseList(ListNode* head) { ListNode* prev = nullptr; ListNode* curr = head; while (curr != nullptr) { ListNode* nextTemp = curr-&gt;next; curr-&gt;next = prev; prev = curr; curr = nextTemp; } return prev; } ListNode* endOfFirstHalf(ListNode* head) { ListNode* fast = head; ListNode* slow = head; while (fast-&gt;next != nullptr &amp;&amp; fast-&gt;next-&gt;next != nullptr) { fast = fast-&gt;next-&gt;next; slow = slow-&gt;next; } return slow; }};","link":"/2020/10/06/leecode%E5%81%9A%E9%A2%98%E7%AC%94%E8%AE%B0/"},{"title":"动态规划","text":"动态规划，我的难点在于不知道什么时候是dp，二是转移方程我还不熟练，自己不太能写出来，最后就是代码阶段了，不过多见些题，经典的题目搞懂的话，问题应该不是很大。 514 自由之路视频游戏“辐射4”中，任务“通向自由”要求玩家到达名为“Freedom Trail Ring”的金属表盘，并使用表盘拼写特定关键词才能开门。 给定一个字符串 ring，表示刻在外环上的编码；给定另一个字符串 key，表示需要拼写的关键词。您需要算出能够拼写关键词中所有字符的最少步数。 最初，ring 的第一个字符与12:00方向对齐。您需要顺时针或逆时针旋转 ring 以使 key 的一个字符在 12:00 方向对齐，然后按下中心按钮，以此逐个拼写完 key 中的所有字符。 旋转 ring 拼出 key 字符 key[i] 的阶段中： 您可以将 ring 顺时针或逆时针旋转一个位置，计为1步。旋转的最终目的是将字符串 ring 的一个字符与 12:00 方向对齐，并且这个字符必须等于字符 key[i] 。 如果字符 key[i] 已经对齐到12:00方向，您需要按下中心按钮进行拼写，这也将算作 1 步。按完之后，您可以开始拼写 key 的下一个字符（下一阶段）, 直至完成所有拼写。 示例： 1234567输入: ring = &quot;godding&quot;, key = &quot;gd&quot;输出: 4解释:对于 key 的第一个字符 'g'，已经在正确的位置, 我们只需要1步来拼写这个字符。 对于 key 的第二个字符 'd'，我们需要逆时针旋转 ring &quot;godding&quot; 2步使它变成 &quot;ddinggo&quot;。当然, 我们还需要1步进行拼写。因此最终的输出是 4。 提示： ring 和 key 的字符串长度取值范围均为 1 至 100； 两个字符串中都只有小写字符，并且均可能存在重复字符； 字符串 key 一定可以由字符串 ring 旋转拼出。 回溯的基本套路如下： 12345678910result = []def backtrack(路径, 选择列表): if 满足结束条件: result.add(路径) return for 选择 in 选择列表: 做选择 backtrack(路径, 选择列表) 撤销选择 字符串的排序 注意点：字符中的元素可以重复，我使用下标号来特异性，但是会导致最后有重复的情况，这里我又去重，相对较麻烦。去重代码如下： 12sort(result.begin(), result.end());result.erase(unique(result.begin(), result.end()), result.end()); 然后需要要提升速度的话，可以使用剪枝，就是用一个set来装这一层选择过的值，保证无重复。","link":"/2020/11/11/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"},{"title":"决策树","text":"第四章，决策树 基本流程决策树处理分类问题，其学习目的就是产生一个泛化能力强，即处理未见示例能力强的决策树。算法流程如下图所示： 其中在三类情况下会return，即不继续划分： D中样本都属于一个类别，直接将这个类别作为节点类别，不需要划分 A属性集为空或者D样本在属性集中无区别，也就是D的样本无法从属性数据中看出其类别区分，因此这里直接将他们中数量最多的样本的类别作为这个节点的类别，这是利用了一个后验分布 当选取的子样本集为空时，其节点类别直接使用父节点中数量最多的样本的类别，这里利用的先验分布 对于这个算法图，不是很理解其中for循环中的内容，目前的感觉是找到一个区分度比较高的属性，根据这个属性值对大样本做一个子集划分，然后将每个子集递归拿进去继续划分（此时就可以去除掉这个属性，因为每个子集中样本的这个属性值都是相等的），写到这里，感觉我又懂了。😄 划分选择划分选择就是对应上面代码的第8行，选择最优划分属性。 信息增益“信息熵”是度量样本集合纯度最常用的指标，同时我们希望决策树的最终节点的划分能够越纯越好，其表达式为：$$Ent(D) = - \\sum_{k=1}^{|y|}p_klog_2P_k$$其中$p_k$代表集合D中第k类样本所占比例，这里$Ent(D)$值越小，纯度越高。 可以看到在第8行代码中我们要选择一个能够很好划分D的属性a，但这里的判断依据应当是什么呢？既然有了纯度的检验概念，我们可以将纯度越高作为我们的判断依据，那就可以去比较用不同的属性来划分后，纯度的增加最大的那个，用$Gain(D,a)$表示纯度增加，专业点说是“信息增益”，那么我们的优化目标就是：$a_* = arg max Gain(D,a)$，如何计算这个变化值$Gain(D,a)$呢？ 在我们对一个D依照a做划分后，需要对每个节点分配不同的权重，很直接的选择是按照这个划分的样本数量安排权重，$Garin$表达式呼之欲出：$$Gain(D,a) = Ent(D)-\\sum_{v=1}^V \\frac {|D^v|}{|D|} Ent(D^v)$$ 增益率 使用信息增益的缺点是偏向于可取值数目多的属性（直观理解就是它的纯度很高，如变化这种唯一性的），为平衡这一点提出了一个“增益率”：$$Gain_ratio(D,a) = \\frac {Gain(D,a)}{IV(a)}$$ $$IV(a) = - \\sum_{v=1}^V \\frac {|D^v|}{|D|}log_2 \\frac {|D^v|}{|D|}$$ 增益率对可取值数目较少的属性有所偏好[1]。他们容易反复横跳，因此最后采用的是一个启发式：从候选划分属性中找到信息增益高于平均水平的属性，再从中选择增益率最高的。 基尼指数$$Gini(D) = 1- \\sum_{k=1}^{|y|}p_k^2$$ 表示的是从D中随机抽取两个样本，其类别标记不一样的概率。优化目标是：$$Gini_index(D,a) = \\sum_{v=1}^V \\frac {|D^v|}{|D|} Gini(D^v)$$最终需要的是：$a_* = arg min Gini_index(D,a)$ 剪枝处理剪枝处理是为了解决过拟合问题，目前有两种方式，其中后剪枝得到的树通常比预剪枝的欠拟合风险小，但因为是在整个树生成结束后剪枝，因此其复杂度更高。 预剪枝是否剪枝的判断依据：在验证集中的正确率表现。缺陷是基于“贪心”，只看这一步的好坏，不管后面。下图分别为未剪枝和预剪枝示例。 后剪枝 连续与缺失值连续值处理处理方法是连续属性离散化，最简单的是“二分法”，即对这个属性找到一个划分点$t$，然后去判断选择这个属性这个划分的条件下对整个模型的优化能力。如果这个样本关于这个连续属性的取值有n个，那么可以选择的划分点有n-1个，即排序后每两个点之间。进一步可以对信息增益表达式做修改：$$Gain(D,a) = max Gain(D,a,t) = max Ent(D)-\\sum_{\\lambda \\in {-,+}} \\frac {|D_t^\\lambda|}{|D|}Ent(D_t^{\\lambda})$$但区别于离散属性的另外的点还在于，连续属性后续还可以使用来划分。 缺失值处理先把一些表达式给出来。 $\\tilde D$：$D$中在属性$a$上没有缺失值的子集 $\\tilde D^v$：若$a$有v个属性取值，则它表示取值为v的样本子集 $\\tilde D^k$：$\\tilde {D}$中的第k类样本子集 $\\omega_x$：给每个样本赋予的权重$$\\rho =\\frac {\\sum_{x \\in \\tilde D} \\omega_x}{\\sum_{x \\in D} \\omega_x}$$ $$\\tilde p_k =\\frac {\\sum_{x \\in \\tilde D_k} \\omega_x}{\\sum_{x \\in \\tilde D} \\omega_x}$$ $$\\tilde r_v =\\frac {\\sum_{x \\in \\tilde D_v} \\omega_x}{\\sum_{x \\in \\tilde D} \\omega_x}$$ 需要解决两个问题： 如何在属性值缺失的情况下进行划分属性选择； 重点在于“选择”，这里将会用$\\rho$来减弱对缺失属性的选择可能，推广信息增益表达式为$$Gain(D,a) = \\rho \\times Gain(\\tilde D,a)$$ 给定划分属性，若样本在该属性上的值缺失，如何对样本进行划分； 重点在于“划分”，将缺失的样本的权重按照每个分类的比例，即$\\tilde r_v$来分散到不同的节点中。 多变量决策树习题后续扩展[1] 这里$IV(a)$表达式和之前的$Ent(D^v)$的不同之处，理解上比较绕 碎碎念 发现我的封面图很多都裂了，那就随便找些个填上，最近来不及搞这些细节了。图书馆好冷呀，心酸…💔","link":"/2020/11/11/%E5%86%B3%E7%AD%96%E6%A0%91/"},{"title":"图","text":"之前关于算法的文章都是比较随意，这次想按照专题的方式来记录做算法题的一些体会和学习到的知识点。 这篇是图论相关。 127 单词接龙给定两个单词（beginWord 和 endWord）和一个字典，找到从 beginWord 到 endWord 的最短转换序列的长度。转换需遵循如下规则： 每次转换只能改变一个字母。 转换过程中的中间单词必须是字典中的单词。 说明: 如果不存在这样的转换序列，返回 0。 所有单词具有相同的长度。 所有单词只由小写字母组成。 字典中不存在重复的单词。 你可以假设 beginWord 和 endWord 是非空的，且二者不相同。 示例 1: 12345678输入:beginWord = &quot;hit&quot;,endWord = &quot;cog&quot;,wordList = [&quot;hot&quot;,&quot;dot&quot;,&quot;dog&quot;,&quot;lot&quot;,&quot;log&quot;,&quot;cog&quot;]输出: 5解释: 一个最短转换序列是 &quot;hit&quot; -&gt; &quot;hot&quot; -&gt; &quot;dot&quot; -&gt; &quot;dog&quot; -&gt; &quot;cog&quot;, 返回它的长度 5。 示例 2: 12345678输入:beginWord = &quot;hit&quot;endWord = &quot;cog&quot;wordList = [&quot;hot&quot;,&quot;dot&quot;,&quot;dog&quot;,&quot;lot&quot;,&quot;log&quot;]输出: 0解释: endWord &quot;cog&quot; 不在字典中，所以无法进行转换。 思路首先要意识到这道题本质上是一道广度优先搜索找最短路径的题。难点有以下几个： 如何建图 最容易的方式是建立一个邻接矩阵，然后单词两两比对，看是否能连接（无向边） 建立矩阵表示图关系，需要一个id和word的映射，使用哈希表 两两搜索比较时间耗费比较大，这里在官方答案中有比较新颖的做法，建立虚拟节点，之后细说 如何搜索 最基础的广度优先搜索 双向搜索，从beginword，endword一起搜索，直到两者重合 id和word的映射使用C++的map容器，但这里因为对顺序没什么要求，因此使用的是unordered_map，常用的map底层使用的红黑树来达到顺序存储的功能。 12345678910unordered_map&lt;string, int&gt; wordId;vector&lt;vector&lt;int&gt;&gt; edge;int nodeNum = 0;void addWord(string&amp; word) { if (!wordId.count(word)) { wordId[word] = nodeNum++; edge.emplace_back(); }} 这里用nodeNum来分配word的id，每次增加一个word时，对应它的wordid增加1。wordId.count 返回的是这个key在其中出现的次数（这里有待确认，因为次数不应该只有01么），在代码中就是判断这个word是否有出现过，如果有的话，则为这个word分配一个id，且建立这个点的可到达edge，即对应代码中的emplace_back()。 这里补充说明一下push_back() 和 emplace_back() 的区别，前者在使用时会创建一个对象且使用构造函数创建一个空间，后者仅声明，但不会有创建空间的开销。 虚拟节点建图这里虚拟节点指的是，图内节点不仅是给出的那些单词，而是也包含了它可以转换的各种形式。如”hit”，可以连接的点就是”*it”，“h*t”，“hi*”这三个，如果另外的节点可以和它相连的话，如”hot”，那必然是可以通过”h*t”这个虚拟节点间接相连的。这一个虚拟节点的思想使我们省去了判断节点是否相通的步骤，但是需要注意的就是在最后计算长度的时候需要除以二以排除虚拟节点的计算量。 12345678910111213void addEdge(string&amp; word) { addWord(word); int id1 = wordId[word]; for (char&amp; it : word) { char tmp = it; it = '*'; addWord(word); int id2 = wordId[word]; edge[id1].push_back(id2); edge[id2].push_back(id1); it = tmp; } } 代码中需要关注的是for循环的使用，这里for(char&amp; it:word) 通常来讲C++ String的遍历有三种方式： operator[]遍历 1for(int i=0; i&lt;s.size(); i++){} 迭代器遍历 正向（可读可写） 12string::iterator p = s.begin();while(p != s.end()){} 这里p是地址，因此可以修改 反向（可度不可写） 12string::reserse_iterator p = s.ebegin();while(p != s.rend()){} 新式（即这里使用的） 123for(auto e:s){}for(char e:s){}for(char&amp; e:s){} 前两种是一样的都是遍历s中的char字符，但是最后一个指定得到的是字符的地址，也就是这道题代码中使用的。 三种遍历方式参考链接 基础广度优先搜索1234567891011121314151617181920212223242526272829int ladderLength(string beginWord, string endWord, vector&lt;string&gt;&amp; wordList) { for (string&amp; word : wordList) { addEdge(word); } addEdge(beginWord); if (!wordId.count(endWord)) { return 0; } vector&lt;int&gt; dis(nodeNum, INT_MAX); int beginId = wordId[beginWord], endId = wordId[endWord]; dis[beginId] = 0; queue&lt;int&gt; que; que.push(beginId); while (!que.empty()) { int x = que.front(); que.pop(); if (x == endId) { return dis[endId] / 2 + 1; } for (int&amp; it : edge[x]) { if (dis[it] == INT_MAX) { dis[it] = dis[x] + 1; que.push(it); } } } return 0; } （懒得调缩进😂） 代码中vector&lt;int&gt; dis(nodeNum, INT_MAX) 表示声明一个nodeNum大小的vector，其中每个初始化大小为INT_MAX。因为构建的是虚拟节点图，所以在最后计算长度时dis[end]/2+1 。广度优先搜索使用队列可以很容易的实现，即每次将一个点取出，然后看他可以到达哪些点，将那些加入到队尾，然后这样依次计算下去，需要注意的是我们会用一个向量dis来更新距离。 双向广度优先搜索 单向的广度优先搜索是呈指数级别增长的，但是双向会减少搜索数量。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354int ladderLength(string beginWord, string endWord, vector&lt;string&gt;&amp; wordList) { for (string&amp; word : wordList) { addEdge(word); } addEdge(beginWord); if (!wordId.count(endWord)) { return 0; } vector&lt;int&gt; disBegin(nodeNum, INT_MAX); int beginId = wordId[beginWord]; disBegin[beginId] = 0; queue&lt;int&gt; queBegin; queBegin.push(beginId); vector&lt;int&gt; disEnd(nodeNum, INT_MAX); int endId = wordId[endWord]; disEnd[endId] = 0; queue&lt;int&gt; queEnd; queEnd.push(endId); while (!queBegin.empty() &amp;&amp; !queEnd.empty()) { int queBeginSize = queBegin.size(); for (int i = 0; i &lt; queBeginSize; ++i) { int nodeBegin = queBegin.front(); queBegin.pop(); if (disEnd[nodeBegin] != INT_MAX) { return (disBegin[nodeBegin] + disEnd[nodeBegin]) / 2 + 1; } for (int&amp; it : edge[nodeBegin]) { if (disBegin[it] == INT_MAX) { disBegin[it] = disBegin[nodeBegin] + 1; queBegin.push(it); } } } int queEndSize = queEnd.size(); for (int i = 0; i &lt; queEndSize; ++i) { int nodeEnd = queEnd.front(); queEnd.pop(); if (disBegin[nodeEnd] != INT_MAX) { return (disBegin[nodeEnd] + disEnd[nodeEnd]) / 2 + 1; } for (int&amp; it : edge[nodeEnd]) { if (disEnd[it] == INT_MAX) { disEnd[it] = disEnd[nodeEnd] + 1; queEnd.push(it); } } } } return 0; } 原理明白后双向和单向的代码是产不多的，他们的轮替顺序是一个的这一层遍历完再遍历另一个。其实我的思路里当时难处理的层数现在想来也容易，忘记用size遍历完一层罢了😭 我的思路的坑用广度优先搜索我还是想到了的，但是想要偷懒不建图，直接每层去找，但是面临层数问题的bug没有解开，还有就是最后一个要超时。并且我的算法没有考虑环，因为每次使用后我就把相应的单词放到使用结束的集合中，无法再加边了，不知道这里是否会有隐藏bug。 参考链接https://leetcode-cn.com/problems/word-ladder/solution/dan-ci-jie-long-by-leetcode-solution/ 你这个学期必须选修 numCourse 门课程，记为 0 到 numCourse-1 。 在选修某些课程之前需要一些先修课程。 例如，想要学习课程 0 ，你需要先完成课程 1 ，我们用一个匹配来表示他们：[0,1] 给定课程总量以及它们的先决条件，请你判断是否可能完成所有课程的学习？ 207 课程表示例 1: 输入: 2, [[1,0]]输出: true解释: 总共有 2 门课程。学习课程 1 之前，你需要完成课程 0。所以这是可能的。示例 2: 输入: 2, [[1,0],[0,1]]输出: false解释: 总共有 2 门课程。学习课程 1 之前，你需要先完成课程 0；并且学习课程 0 之前，你还应先完成课程 1。这是不可能的。 提示： 输入的先决条件是由 边缘列表 表示的图形，而不是 邻接矩阵 。详情请参见图的表示法。你可以假定输入的先决条件中没有重复的边。1 &lt;= numCourses &lt;= 10^5 思路：本质是一道判断图是否有环的题目，一种方法就是拓扑图，建立图的邻接矩阵和入度矩阵，最基础的点一定是入度为0的，我们将当前所有入度为0的点放入一个队列中，对于队列中每个点遍历，去除其本身并且将它相关联的点的入度也减1，之后重复这个过程，直到再无可遍历的点，然后看看是否此时所有点都入度都变为0了，如果还有不为0的则说明此图有环。 12345678910111213141516171819202122232425262728293031323334353637383940class Solution {public: bool canFinish(int numCourses, vector&lt;vector&lt;int&gt;&gt;&amp; prerequisites) { //需要是一个无环图 拓扑排序 //构建入度表 int indu[numCourses]; memset(indu, 0, sizeof(indu)); //邻接矩阵 vector&lt;vector&lt;int&gt;&gt; table(numCourses); for(auto prerequisite:prerequisites){ indu[prerequisite[0]]++; table[prerequisite[1]].push_back(prerequisite[0]); } //建队列放入度为0的节点 int all = numCourses; queue&lt;int&gt; que; for(int i=0; i&lt;numCourses; i++){ if(indu[i] == 0) que.push(i); } while(all&gt;0 &amp;&amp; !que.empty()){ int temp = que.front(); que.pop(); //使用了后入度标记为-1 indu[temp] = -1; //修改相关联节点的入度 for(auto connect:table[temp]){ indu[connect]--; if(indu[connect] == 0){ que.push(connect); all--; } } } for(int i=0; i&lt;numCourses; i++){ if(indu[i] &gt; 0) return false; } return true; }}; 332 重新安排行程给定一个机票的字符串二维数组 [from, to]，子数组中的两个成员分别表示飞机出发和降落的机场地点，对该行程进行重新规划排序。所有这些机票都属于一个从 JFK（肯尼迪国际机场）出发的先生，所以该行程必须从 JFK 开始。 提示： 如果存在多种有效的行程，请你按字符自然排序返回最小的行程组合。例如，行程 [“JFK”, “LGA”] 与 [“JFK”, “LGB”] 相比就更小，排序更靠前所有的机场都用三个大写字母表示（机场代码）。假定所有机票至少存在一种合理的行程。所有的机票必须都用一次 且 只能用一次。 来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/reconstruct-itinerary 思路：使用深度优先遍历，并且要结合离散数学中欧拉图的性质。","link":"/2020/12/07/%E5%9B%BE/"},{"title":"基于对称密码的加密流量异常检测系统","text":"网络中间设备想要完成流量异常检测通常需要获取明文，我们希望设计出一个在加密状态、保护用户隐私状态下依旧可以进行分布式数据库入侵检测的系统。 涉及的密码学技术： 对称可搜索加密算法 高安全、高效哈希函数 随机数生成器 可搜索加密算法 用户隐私等数据在网络上传播时要求是密文形式，但是如果对存储的密文数据查找时，会由于密文已改变了原索引条件从而造成一定的检索困难。可搜索加密算法就是设计出一个加密算法，使得在不解密为明文的条件下，能够在密文域实现较好的关键词搜索功能。 第一篇阅读的文献：PrivDPI: Privacy-Preserving Encrypted Traffic Inspection with Reusable Obfuscated Rules 论文笔记 第二篇阅读文献：论文笔记","link":"/2020/09/22/%E5%9F%BA%E4%BA%8E%E5%AF%B9%E7%A7%B0%E5%AF%86%E7%A0%81%E7%9A%84%E5%8A%A0%E5%AF%86%E6%B5%81%E9%87%8F%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E7%B3%BB%E7%BB%9F/"},{"title":"密钥交换协议实现","text":"在基础的DH密钥交换协议中，为了防止重放和中间人攻击加入了签名认证，在加密和整体算法设计上使用了SM2和SM3 后续会在这里总结一些密钥交换安全基本的安全模型的东西 库的安装： 12pip3 install -i https://pypi.douban.com/simple pycryptodome(pip3 install pycryptodome我会报错) pip3 install gmssl 服务端代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980import sysfrom socket import *from gmssl import sm2, funcfrom Crypto.Util.number import *from hashlib import sha256# A B 公私钥和IDIDA = '777'IDB = '321'p = 94313901681443578942367588303266881874224725225732200536290302381507159900682469308699917405398797416164103517997923683453556485646066908743873506178671593391576338559435459952848528080908486150955455121162744500566000141128127091521308011640679378126882461641894837342623287738615768137692674805041029879683private_key_A = '0' #fake_key true_key_is #'00edf68bdc69e6441770027c8867072dd4089bbb00b833e35636d0909ccf545545'public_key_A = 'e27ccfa5d1392615b5545159288b20a513dc188661fa5d31e2a5d9bba0094dbffb3f6945f605be0ee1f4207efb861ec9d63f8e3a24ade7c11d29d0bcc7d7e042'sm2_crypt_A = sm2.CryptSM2( public_key=public_key_A, private_key=private_key_A)private_key_B = '00B9AB0B828FF68872F21A837FC303668428DEA11DCD1B24429D0C99E24EED83D5'public_key_B = 'B9C9A6E04E9C91F7BA880429273747D7EF5DDEB0BB2FF6317EB00BEF331A83081A6994B8993F3F5D6EADDDB81872266C87C018FB4162F5AF347B483E24620207'sm2_crypt_B = sm2.CryptSM2( public_key=public_key_B, private_key=private_key_B) host = sys.argv[1]port = int(sys.argv[2]) #创建SockettcpSocket = socket(AF_INET, SOCK_STREAM) #绑定tcpSocket.bind((host, port)) #设置最大连接数，超过后排队tcpSocket.listen(5) while True: #建立连接 connect, addr = tcpSocket.accept() while True: #接收客户端发来的数据并且小于1024字节的数据 A_2 = connect.recv(1024) #如果客户端退出，则执行以下语句 if not A_2: break #转换 A_2 = str(bytes_to_long(A_2)) print(&quot;received g^a is&quot; + A_2) B = int(input(&quot;input B that you want: &quot;)) B_2 = str(pow(2,B,p)) #签名后消息发送数据给客户端 data = A_2 + B_2 + IDB data = data.encode() random_hex_str = func.random_hex(sm2_crypt_B.para_len) sign = sm2_crypt_B.sign(data, random_hex_str) B_2_sign = (B_2 + '!!!' + sign).encode() #bytes #print(&quot;A_2: &quot;+A_2+'\\n'+&quot;B_2: &quot;+B_2+'\\n'+&quot;sign: &quot;+sign+'\\n'+'!!!'+IDB) connect.send(B_2_sign) #接收用于验证为篡改的签名 B_2_sign = B_2_sign.decode() total = connect.recv(8192).decode() A_2_new = total[:total.find(&quot;###&quot;)] sign_data = total[total.find('###') + 3:] if sm2_crypt_A.verify(sign_data, (A_2 + B_2_sign + A_2_new + IDA).encode()) == False: print(&quot;sign error connection break&quot;) break #ACK 说明收到并通过验证 skey = sha256(long_to_bytes(pow(int(A_2),B,p))).hexdigest() print(&quot;success and the key is: &quot; + skey) connect.send(b&quot;ACK&quot;) break #关闭连接套接字 connect.close() #关闭套接字tcpSocket.close() 客户端代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768import sysfrom socket import *from gmssl import sm2, funcfrom Crypto.Util.number import *from hashlib import sha256#16进制的公钥和私钥IDA = '777'IDB = '321'p = 94313901681443578942367588303266881874224725225732200536290302381507159900682469308699917405398797416164103517997923683453556485646066908743873506178671593391576338559435459952848528080908486150955455121162744500566000141128127091521308011640679378126882461641894837342623287738615768137692674805041029879683private_key_A = '00edf68bdc69e6441770027c8867072dd4089bbb00b833e35636d0909ccf545545'public_key_A = 'e27ccfa5d1392615b5545159288b20a513dc188661fa5d31e2a5d9bba0094dbffb3f6945f605be0ee1f4207efb861ec9d63f8e3a24ade7c11d29d0bcc7d7e042'sm2_crypt_A = sm2.CryptSM2( public_key=public_key_A, private_key=private_key_A)private_key_B = '0' #fake_key true_key is '00B9AB0B828FF68872F21A837FC303668428DEA11DCD1B24429D0C99E24EED83D5'public_key_B = 'B9C9A6E04E9C91F7BA880429273747D7EF5DDEB0BB2FF6317EB00BEF331A83081A6994B8993F3F5D6EADDDB81872266C87C018FB4162F5AF347B483E24620207'sm2_crypt_B = sm2.CryptSM2( public_key=public_key_B, private_key=private_key_B) host = sys.argv[1]port = int(sys.argv[2])#创建SockettcpSocket = socket(AF_INET, SOCK_STREAM)#与服务端建立连接tcpSocket.connect((host, port))while True: A = int(input(&quot;input A that you want: &quot;)) A_2 = pow(2,A,p) #如果输入exit，则执行以下语句 if A == &quot;exit&quot;: break #发送数据给服务端发起请求 tcpSocket.send(long_to_bytes(A_2)) #接收服务端的签名数据并验签 B_2_sign = tcpSocket.recv(4096).decode() B_2 = B_2_sign[ : B_2_sign.find(&quot;!!!&quot;)] sign = B_2_sign[B_2_sign.find(&quot;!!!&quot;) + 3: ] #print(&quot;A_2: &quot;+str(A_2)+'\\n'+&quot;B_2: &quot;+B_2+'\\n'+&quot;sign: &quot;+sign+'\\n'+'!!!'+IDB) if sm2_crypt_B.verify(sign, (str(A_2) + B_2 + IDB).encode()) == False: print(&quot;sign error connection break&quot;) break print(&quot;received g^b is&quot; + B_2) #确认未篡改的签名 data = str(A_2) + B_2_sign + str(A_2) + IDA random_hex_str = func.random_hex(sm2_crypt_A.para_len) sign_data = sm2_crypt_A.sign(data.encode(), random_hex_str) total = (str(A_2)+ &quot;###&quot; + sign_data).encode() tcpSocket.send(total) #收到ACK ack = tcpSocket.recv(1024) if ack == b'ACK': skey = sha256(long_to_bytes(pow(int(B_2),A,p))).hexdigest() print(&quot;success and the key is: &quot; + skey) break#关闭套接字tcpSocket.close()","link":"/2020/06/28/%E5%AF%86%E9%92%A5%E4%BA%A4%E6%8D%A2%E5%8D%8F%E8%AE%AE%E5%AE%9E%E7%8E%B0/"},{"title":"支持向量机","text":"第六章 间隔与支持向量 如上图所示，在对+-分类时，我们希望找到一个较好的平面将他们分隔开来，直观上来说，这个平面能最”中间“，其鲁棒性最好。距离超平面最近的几个样本（图中圆圈的）被称作”支持向量“，因为它大体来确定了这个超平面的走向（其实其他点就是无用的了），而异类超平面之间的距离：$$\\gamma = \\frac {2}{||w||}$$被称作”间隔“。 直观上来说我们期待的是能够找到这个间隔最大的超平面作为分类标准，用数学式子表达如下（李宏毅老师课件，西瓜书里这里直接到标准式过度得不是很自然）： 现在需要简化，先做一个假设，即如果我们能把$y_n(w^Tx_n+b)$的范围确定到$\\geq 1$，且这个1一定存在，也就是最小的是1，那么$margin(b,w) = \\frac {1}{||w||}$，上面求max的也就简化了。这个假设很香，如何证明？ 这里就再假设一下，就是我们能确保所有$y_n(w^Tx_n+b) \\geq 1.23$都成立，但这时发现只要对$w,b$都除1.23那就可以改为1了。相悖，所以一定能找到最小的一个1。其实由于没有除以分子的$||w||$，值是可以随意改变的，我们之所以想要把它”定“下来是方便讨论，也可以从几何的角度去理解。 在对$\\frac {1}{||w||}$做一下变形就可以得到SVM的标准式子：$$\\underset {w,b}{min} \\quad \\frac 12 ||w||^2$$ $$s.t. y_i(w^Tx_i+b) \\geq 1, i=1,2,…,m.$$ 对偶问题上述的标准式子是凸二次规划，可以直接用现成的优化计算包完成，但这里主要介绍另一种高效的方式。 对标准式用拉格朗日乘子法[1]可得到其”对偶问题“(dual problem)：$$\\underset {\\alpha_i &gt;0}{L(w,b,\\alpha)} = \\frac 12||w||^2+\\sum_{i=1}^m\\alpha_i(1-y_i(w^Tx_i+b))$$这个式子和标准式是等效的(又是李老师讲的噢)，当样本不满足标准式的2式时，这个对偶式子的右边那一坨就一定是负数，那么求$min$是无穷小，会被算法淘汰，当它是支持向量时，右边为0。这样这个式子很好的包含了前面两个。 统一对偶式中的$min,max$：一定存在$$\\underset {w,b}{min} , (\\underset {\\alpha}{max} L(w,b,\\alpha)) \\geq \\underset {w,b}{min} , L(w,b,\\alpha)$$其中式子右侧的$\\alpha$为一定值。再拉格朗日中值：右式可以再变化为$\\underset {all , \\alpha}{max} , \\underset {w,b}{min} , L(w,b,\\alpha)$ 最终将这个大于等于强化为等号[2]，但需要满足KKT条件：$$\\begin{cases} \\alpha_i \\geq 0 \\\\[2ex] y_if(x_i)-1 \\geq 0 \\\\[2ex] a_i(y_if(x_i)-1) = 0 \\end{cases}$$ 化简对偶式，计算对$w,b$的偏导数为0时的式子，带入进入消参，得到：$$\\underset {\\alpha}{max} , \\sum_{i=1}^m \\alpha_i-\\frac 12 \\sum_{i=1}^m\\sum_{j=1}^m\\alpha_i\\alpha_jy_iy_jx_i^Tx_j$$其中$\\sum_{i=1}^m\\alpha_iy_i=0$和$a_i \\geq 0$ 求解上式，一个方式就是直接的二次规划问题，但是这里介绍更高效的方式SMO方法。 其基本思路是固定$\\alpha_i$以外的其他所有参数，求$\\alpha_i$的极值。由于存在约束条件$\\sum_{i=1}^m \\alpha_iy_i=0$，若固定其他变量，$\\alpha$可由他们导出。于是取两个变量$\\alpha_i$和$\\alpha_j$，代入3中的式子中更新他们的值。[3] 求出$\\alpha$取值后的$f$表达式：$f(x) = \\sum_{i=1}^m \\alpha_iy_ix_i^Tx+b$ 求解$b$，用所有支持向量求解出来的均值[4] 核函数前面的例子中有一个前提就是能找到支持向量机，是可分的。但如果在这一维中无法分呢？解决方法是从原始空间映射到一个高维空间中，只要维度一定高，就一定可分，对于公式而言，只需要将其中的$x$转化为$\\varphi(x)$，那对偶问题的公式中就会出现：$$\\underset {\\alpha}{max} , \\sum_{i=1}^m \\alpha_i-\\frac 12 \\sum_{i=1}^m\\sum_{j=1}^m\\alpha_i\\alpha_jy_iy_j\\varphi(x_i^T)\\varphi(x_j)$$两个$\\varphi$的相乘计算是很困难的，这里就需要使用我们的核函数$\\kappa(.,.)$： 他将这个计算转换到了原始空间中，降低运算复杂度。但这里相当于对训练又多了一个参数，因为我们不知道什么样的比较合适，但常用的如下： 除此之外，我们还可以糅合多个核函数，如线性组合、直积等 软间隔与正则化之前要求所有的分类要准确是”硬间隔“，但实际上我们就算找到时候的核函数也很难去找到一个合适的分割平面（要怕过拟合），因此我们可以允许一部分点被分错，即允许”软间隔“，如下图所示。 ”软间隔“的优化目标可以表示如下：$$\\underset {w,b}{min} \\frac 12||w||^2+C\\sum_{i=1}^m l_{0/1}(y_i(w^Tx+b)-1)$$其中$l_{0/1}$为”0/1损失函数”，常用的替代损失函数还有：hinge损失，指数损失和对率损失等，他们的曲线如下图所示： 引入”松弛变量“后，也可以用拉格朗日乘子法对其求解，与之前的”硬间隔“的主要区别在于对偶变量的约束不同（推导见书P131）。 对前面的”软间隔“的优化目标抽象一下的话：$$\\underset {f}{min} ,, \\Omega(f)+C\\sum_{i=1}^m l(f(x_i),y_i)$$ 结构风险：前部分，用户意图，削弱假设空间 经验风险：后部分，模型与训练数据的拟合程度 其中的C可以条件这两者的侧重，这里有涉及”正则化“问题（对不希望得到的结果施以惩罚，从而使得优化过程趋向于希望目标），$\\Omega(f)$为正则化项，$C$为正则化常数，$L_p$范数🍠为常用正则化项。 $L_2$：分量均衡 $L_0,L_1$：分量稀疏[5] 支持向量回归(SVR) 支持向量回归允许在一定区间内的错误不计。SVR函数可以表达为：$$\\underset {w,b}{min} , \\frac 12 ||w||^2+C\\sum_{i=1}^m l_{\\epsilon}(f(x_i)-y_i)$$这里的$l_{\\epsilon}$为$\\epsilon$-不敏感损失： 后文主要引入”松弛变量“[6]对公式进行推导。(P134) 核方法不考虑偏移项的话，SVM和SVR都可以表达为$\\kappa(x,x_i)$的线性组合，因此核函数对于他们都是十分重要的，而基于此发展出来的一系列学习方法就是核方法。(P137略) 后续扩展[1] 这个方法附录有单独介绍 [2] 这里我感觉应该因为我拉格朗日没到位，所以理解上有困难 [3] 关于变量的选择，和SOM高效的解释在书P125，这里暂时不阐述了 [4] 这里他们求出来的值不应当都相等么 [5] 这里讲的范数还太浅了点 [6] 松弛变量的概念 碎碎念巧克力豆奶确实有点容易腻呀🤮，只适合喝一点点。","link":"/2020/10/14/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/"},{"title":"模型评估与选择","text":"此为西瓜书的第二章。 经验误差与过拟合 error(误差)：学习器的实际预测输出与样本的真实输出之间的差值 training error(训练误差)：在训练集上的误差 empirical error(泛化误差)：在测试集的误差👍（我们更看重的是泛化误差） overfitting(过拟合)：学习能力过强时，会将在广样本中不具备的一些特质作为训练样本训练出的东西，这些在更广的测试集中不适用，导致泛化能力下降。过拟合问题不可避免（P≠NP） underfitting(欠拟合) 评估方法通常为了在几种模型中选择出我们期待的最好的模型，我们需要测试模型的泛化能力，一般使用测试集的数据。为了能更公证地比较，测试集的数据需要独立同分布地采样，同时尽量避免出现在训练集中，有以下方法可以使用： 留出法(hold-out)将数据集D划分为两个互斥的集合，一个作为训练集S，一个作为测试集T。需要注意： 训练/测试集的划分要尽可能保持数据分布的一致性。即如果S中正样本占50%，则T中也要使正样本比例接近50% 若S中包含大多的样本，则测试集的数据过少（甚至只有一个的话）那测出来的数据极不稳定；反之若T中样本过多也是同样的道理，会导致学习的模型不够完善。目前这个问题没有解决办法，一般的方式是2/3~4/5的样本用于训练 交叉验证法(cross validation)“p次k折交叉验证”指的是对于样本集，我们使用p中不同的划分方式，每次将样本集划分为数量相等的k份，然后每次用k-1份作为训练集训练，剩下的一份作为测试集，这样下来总过求p×k次的平均值作为结果来判断。如下图所示： 注意图中只展示了一次划分。特殊的，当k和样本的数量一致时，交叉验证法退化为留一法(Leave-One-Out)，LOO方法在数据较多时计算量过大。 自助法(bootstrapping)前面的方法在训练时因为需要拿出一部分作为测试集，因此训练样本的规模和全部样本的规模不一样，这里会产生偏差。这里的“自助法”以自助采样法(bootstrap sampling)为基础。 在数据集D中，有m个样本，现在我们想要用构造一个同样为m个样本的数据集D’，方式就是每次随机地从D中抽取一个样本放入D’中，放入后将这个样本放回去以保证下次依旧有机会再抽到。最后我们使用D’来做训练，而测试集是D-D’（即D中没有在D’中出现过的）。这里估计一下这个测试集大概的大小，即样本在m次采样中始终不被采到的概率:$$\\lim_{ m\\to \\infty } (1-\\frac 1m)^{ m } = \\frac 1e \\approx 0.368$$自助法在数据集较小、难以有效划分训练/测试集时很有用，对集成学习[1]等有很大的好处，但是其产生的数据集改变了初始数据集的分布，会引入估计偏差。 调参与最终模型调参比较苦💔，这里还提到一般我们在实际结果中的测试数据称为测试集，把训练数据划分为训练集和验证集（validation set） 性能度量衡量模型泛化能力的评价标准。 回归任务中最常用的是“均方误差”：$$E(f;\\mathcal D) = \\int_{ x \\rightarrow \\mathcal D }{ (f(x)-y)^2p(x) }, { \\rm d }x$$ 错误率与精度分类问题中常用[3]：$$E(f;\\mathcal D) = \\int_{ x \\rightarrow \\mathcal D }{ \\coprod (f(x)-y)^2p(x) }, { \\rm d }x$$ 查准率、查全率与F1根据样例真实类别和预测类别的组合可以分为以下四个：TP(真正例)，FN(假反例)，FP(假正例)，TN(真反例) 预测结果 真实情况 正例 反例 正例 TP(真正例) FN(假反例) 反例 FP(假正例) TN(真反例) 其中，查准率P:$$P=\\frac {TP}{TP+FP}$$代表的含义是在我预测为正的样例中，有多少是真的为正。查全率：$$R=\\frac {TP}{TP+FN}$$代表真正的正例有多少被预测为正例。通常来讲，这两个指标是矛盾的，一个越大，另一个越小。用P-R曲线表示如下： 如果一个学习模型的P-R曲线可以“包住”另一条，则其性能更好，图中A性能比C好，但是这里无法估测AB的性能，在这种情况下可以用查准率=查全率时候的值作为比较依据，即图中红色的虚线所交点——平衡点(BEP)。但BEP还是过于简化，在实际应用中，我们对查全率和查准率的偏好可能是不一样的，用$\\beta$代表查全率对查准率的相对重要性，则有如下指标：$$F_{\\beta} = \\frac {(1+\\beta^2)\\times P \\times R}{(\\beta^2 \\times P)+R}$$特殊的，当$\\beta$=1时，为标准的$F_1$。 当我们在分类问题中，计算了多次结果，有二分类混淆矩阵时，我们希望求得一个全局的值，有两种方式： 宏查全率/查准率/$F_1$：先计算出分别的这几个指标，再求平均值 微查全率/查准率/$F_1$：先计算值的平均，再计算指标[2] ROC与AUC一般情况下，对于分类问题，我们很可能是计算出一个介于0和1之间值，然后再给一个阈值(threshold)，通过比较结果值和阈值间的大小关系来判定分类。如果对数据结果进行排序，那么选择的这个截断点的不同会导致最后分类的查全率和查准率不同。实际上对模型能力的评估可以化为对结果排序准确度的评估，这里称作ROC(受试者工作特征)[4]。它的纵轴是“真正例率”，横轴是“假正例率”，其中纵轴的表达式和查全率一致，横轴表达式如下：$$FPR = \\frac {FP}{TN+FP}$$表达的是所有反例中错预测为正例的比率。作出ROC图如下： 比较性能除了通过曲线的“包住”关系外，还可以通过计算面积得到AUC。表达式如下：$$AUC = \\frac 12 \\sum_{i=1}^{m-1}(x_{i+1}-x_i)(y_i+y_{i+1})$$AUC是评估排序质量的值，与排序的误差紧密相关，考虑排序损失(loss)：$$\\mathcal l_{rank} = \\frac {1}{m^+m^-} \\sum_{x^+ \\in D^+} \\sum_{x^- \\in D^-} (\\coprod (f(x^+) &lt; f(x^-))+\\frac 12 \\coprod(f(x^+)=f(x^-)))$$这两个值之间的关系为：$AUC = 1-l_{rank}$ 代价敏感错误率与代价曲线在之前的计算中，将正例预测为反例和将反例预测为正例的代价是一样的，但是在实际场景中，这两种错误的代价会有偏重。因此这里设立代价矩阵，$cost_{10}$就是将第一类例子预测为第0类例子的代价。在非均等代价下，ROC曲线不能直接反映出学习器的期望总体代价[5]，而“代价曲线”(cost curve)则可以达到目的。横轴为正例概率代价：$$P(+)cost = \\frac {p \\times cost_{ 01 } }{p \\times cost_{01} + (1-p) \\times cost_{01} }$$纵轴为取值为[0,1]的归一化代价[6]：$$cost_{norm} = \\frac {FNR \\times p \\times cost_{01} + FPR \\times (1-p) \\times cost_{01} }{p \\times cost_{01} +(1-p) \\times cost_{01}}$$其中$p$为样例为正的概率，$FNR = 1-TPR$为假反例率。ROC中每一个点可以对应一条代价曲线，线段下的面积代表了该条件下的期望总体代价，如果将ROC每一个点的代价曲线都画出来，他们的下界围成的面积是在所有条件下学习器的期望总体代价，如下图所示： 比较检验主要使用统计假设检验的知识（hypothesis test），基础为概率论知识（❗这里的概率论知识多起来了，需要补充），因为我们能够得到的是测试集上的结果，但想要的其实是泛化能力，即模型总的指标，这个指标无法直接得到，但是我们可以用统计的知识给出这个指标为多少值的可行度（置信度，置信区间），这里我们就先主要考虑错误率指标$\\epsilon$ 假设检验假设检验的思想是，我对实际的错误率$\\epsilon$假设一个值的范围，如$\\epsilon \\leq \\epsilon_0$，然后需要判断是否能在置信度为$1-\\alpha$的条件下相信这个假设。具体应用里可能有二项分布，t分布等。假设检验概率论基础 交叉验证t检验对比两个学习器之间的性能差异，可以通过比较他们的错误率，如果错误率十分相似，那可以认为他们的性能是差不多的，如果不能认为相似的话，平均错误率小的更优。在具体使用时，一般每个学习器都会做k折交叉验证，我们对每次交叉验证时的一对错误率做假设检验，看他们的差值是否在一定的置信度下能够是近似为0的。即求$\\Delta_i = \\epsilon_i^A- \\epsilon_i^B$，得到$\\Delta_1,\\Delta_2,…,\\Delta_k$后，计算出均值和方差，在显著度$\\alpha$下，若变量：$$\\tau_T = |\\frac {\\sqrt k \\mu}{\\sigma}|$$小于临界值$t_{\\alpha/2,k-1}$则假设不能被拒绝。 但在实际操作时，由于k折方法在选取数据时可能存在两次之间抽取到了同样的数据，因此测试错误率并不完全独立，为了缓解这一问题，可以采用$5 \\times 2$交叉验证，即5次2折交叉验证。对于两个学习器A，B，每次会产生两对错误率，计算差值得到第一折的$\\Delta_i^1$和第二折的$\\Delta_i^2$，为了缓解测试错误率的非独立性[7]，我们对每次交叉验证计算$\\mu = 0.5(\\Delta_1^1+\\Delta_1^2)$和方差$\\sigma_i^2 = (\\Delta_i^1-\\frac {\\Delta_i^1+\\Delta_i^2}{2})^2+(\\Delta_i^2-\\frac {\\Delta_i^1+\\Delta_i^2}{2})^2$，变量：$$\\tau_t = \\frac {\\mu}{\\sqrt{0.2 \\sum_{i=1}^5\\sigma_i^2} }$$服从自由度为5的$t$分布，其双边检验的临界值$t_{\\alpha/2,5}$。 McNemar检验二分类问题中，比较学习器A和学习器B之间的关系，可以得到两者都正确，两者都错误，一个正确和一个错误的样本数，若性能相同，则一个正确一个错误的样本数$e_{01} = e_{10}$，则对于变量$|e_{01}=e_{10}|$应当服从正态分布，McNemar检验考虑变量：$$\\tau_{\\chi^2} = \\frac {(|e_{01}-e_{10}|-1)^2}{e_{10}+e_{01}}$$服从自由度为1的$\\chi^2$分布。（这里分子减1是由于他们的和很小，需要连续性校正[8]） Friedman检验与Nemenyi后续检验上面的交叉验证$t$检验和McNemar检验都是对两个学习器的性能的比较，但有时候我们需要对多个数据上多个算法的性能做比较，这时可以两两比较，但不够方便。Friedman检验是整体检验几个算法是否满足假设“所有算法性能相同”，而Nemenyi后续检验是给出两个算法性能接近的阈值，这样可以分别判断哪些算法是近似的，哪些有较大差异。 在Friedman算法中，我们首先对每个数据集上算法的表现做排名（相同名次的需要平分数值），得到下面的表格： 若算法性能相同，那么平均序值应当相等，，假设我们在N个数据集上比较k个算法，$r_i$表示第i个算法的平均序值，则变量：$$\\tau_{\\chi^2} = \\frac {k-1}{k}.\\frac {12N}{k^2-1}\\sum_{i=1}^k(r_i-\\frac {k+1}{2})^2$$在k和N都较大时，服从自由度为k-1的$\\chi^2$分布，优化后一般使用变量：$$\\tau_F = \\frac {(N-1)\\tau_{\\chi^2}}{N(k-1)-\\tau_{\\chi^2}}$$服从自由度为k-1和(k-1)(N-1)的$F$分布。 在后续Nemenyi检验中，计算这个平均序值差别的临界阈值：$$CD = q_\\alpha \\sqrt{\\frac {k(k+1)}{6N}}$$可以用下图比较直观的说明其含义，A&gt;B&gt;C，但其中AB,BC差异都不大，有重叠部分，但是AC差异大认为性能不同： 偏差与方差泛化误差可以做如下分解：$$E(f;D) = bias^2(x)+var(x)+\\varepsilon^2$$其中第一项偏差代表了模型的拟合能力，第二项方差代表了模型抗扰动的能力，第三项是噪声代表了模型的训练难度。其中偏差和方差是有冲突的： 习题习题答案参考链接 2.3 无直接联系（之前我对BEP的理解出现误区，列了个公式让查全率=查准率然后去推导出FP=FN这个结论，这个方式是不可行的，因为BEP曲线对于分类问题的阈值是变化的，而错误率是在阈值一定后计算的，两者无法相比）。 2.6 接着2.3回答，ROC曲线上的每个点可以对于一个错误率。 2.8 第一个方式容易受特殊点的影响，但计算相对简单 后续扩展[1] 集成学习 [2] 在不同场景的应用有什么不同 [3] 这里$\\coprod$表示指示函数，成立是为1，不成立为0 [4] P-R图和ROC曲线的不同：一个表明我们对查全率和查准率的倾向性（希望综合的考虑），一个是对排序性能的判断（前面相当于对应截断点的选择） [5] 均等条件下，ROC曲线可以反映出期望？ [6] 归一化的定义，同时对这个公式的理解不太透 [7] 这样为什么能缓解独立性 [8] 不是很懂连续性校正 碎碎念非自然死亡，很喜欢这部剧，因为讨论的社会问题有价值，同时我对悬疑没有抗拒力！ “有工夫绝望的话，还不如吃点好吃的去睡觉呢!”🍕 ”梦想什么的，用不着那么夸张的东西吧，有个目标就行了。目标吗?比如，发了工资要买什么，或者下次休假去哪玩，又或者为了谁而工作。“ ”世道如何，是看自己如何处世吧。“ 写完这里，又开始想中午吃什么了…..🐷","link":"/2020/09/06/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%B8%8E%E9%80%89%E6%8B%A9/"},{"title":"神经网络","text":"第五章啦~😊 神经元模型 如图所示为M-P神经元模型，其中对输入按照权重计算后与阈值做比较，最后输出再通过激活函数的处理（常用sigmod）。 感知机与多层网络 感知机：两层神经元，一个输入层一个输出层，只有输出层有包含一个激活函数（如上图所示），训练时的权重调整公式如下(将阈值的训练也糅合到权重中了)：$$\\omega_i \\leftarrow \\omega_i + \\Delta \\omega_i$$ $$\\Delta \\omega_i = \\eta(y- \\hat y)x_i$$ 能处理的都是线性可分问题，如下图中的abc类型，但不能处理d： 多层前馈神经网络：多层是指在输入层和输出层见加入多个隐藏层(hidden layer)，前馈神经网络指每层神经元和下一层完全链接，但是不存在同层和跨层链接，如下图所示，它可以解决上图的d异或问题了。 误差逆传播算法(BP)之前的感知机的学习规则不足够适用于多层网络的学习，因此出现了误差逆传播算法(error BackPropagation)，其基本思想是先计算出当前权重和阈值下最后的输出，根据输出和验证集计算出均分误差，然后由于这一个关系：$$上层输入值 + 链接权重\\overset{决定}{\\longmapsto} 计算值+阈值 \\overset{决定}{\\longmapsto} 这层输出值$$我们可以对error进行求导，将这个错误迭代传播到前面层中，起到模型调整的目的，这个算法就是基于梯度下降(gradient descent)策略，以目标的负梯度方向对参数进行调整：$$\\Delta \\omega_{fj} = - \\eta \\frac {\\partial E_k}{\\partial \\omega_{hj}}$$其中每层的学习率也可设置为不同的值。 累计误差逆传播算法：上面的标准BP算法是针对单个样例，但是也可以通过计算多个样例的平均值来优化 如何设置神经元个数：试错法 如何处理过拟合： 早停：当训练集误差降低但是训练集误差增加时就停止 正则化：在误差目标函数中增加一个用于描述网络复杂度的部分如：$$E = \\lambda \\frac 1m \\sum_{k=1}^m E_k + (1-\\lambda) \\sum_i \\omega_i^2$$ 全局最小和局部最小 上图能把这个意思表达得很明确了，目前有多种避免局部极小的策略： 不同的初始值训练后比较 模拟退火：一定的概率接受比当前更差的结果 随机梯度下降：即使在局部极小点，但可能梯度仍然不为0，则会继续搜索[1] 遗传算法 启发式算法，无理论依据。 其他常见神经网络RBF(Radial Basis Function)描述词：单隐层，前馈神经网络，激活函数为径向基函数[2]（通常为样本$x$到数据中心$c_i$之间的欧式距离的单调函数），表达式为：$$\\varphi(x) = \\sum_{i=1}^q \\omega_i \\rho(x, c_i)$$ $$\\rho(x, c_i) = e^{-\\beta_i ||x-c_i||^2}$$ 其中$q$是隐藏层的神经元个数，训练步骤是： 确定神经元中心$c_i$，常用的是随机采样、聚类等 利用BP算法训练参数 ART(Adaptive Resonance Theory) 竞争型学习（对抗学习？）：无监督学习策略[3]，神经元相互竞争，“胜者通吃”😥（我们社会也是嘛） 组成：比较层，识别层，识别阈值，重置模块 重点识别层： 获胜者将抑制失败者，判断获胜的依据是计算出的向量和各个模式的向量距离 阈值判断 大于阈值（距离小于某个界限）：被归为那一类，同时参数也会更新，以后类似的会更容易被分到这里 小于阈值：自成一派 优点：缓解了“可塑性-稳定性窘境”；可进行增量学习/在线学习[4] 可塑性：学习新知识的能力 稳定性：保持旧记忆力（突然想起LSTM[5]） SOM如下图所示，这里讲得有点抽象，大致是将高维的输入层映射到低维的输出层中（这里是二维），然后为了能更好地表征，输出层会角逐出获胜的神经元，调整它及其邻近神经元的权重，一种拓扑结构的改变。 级联相关网络结构自适应网络将网络结构也作为学习的目标之一，两个要点如下： 级联：最开始只有输出层和输出层，之后加层级结构 相关：最大化新神经元的输出与网络误差之间的相关性 缺点：数据小的时候容易过拟合 优点：无需设置网络层数、隐层神经元数目，训练速度较快 Elman不同于前馈神经网络（明白这里为什么叫前馈啦），“递归神经网络”允许出现环形结构，让一些神经元的输出反馈回来作为输入信号。其中Elman一个常用的递归神经网络，隐藏层的输出反馈作为其输入，激活函数为sigmoid，训练用BP。 Boltzman为网络定义一个能量，能量最小的时候网络达到理想状态，而Boltman就是这样的“基于能量的模型”。它的结构如下图所示： 神经元分为两层：显层（输入输出）和隐层（内在表达）。神经元是布尔类型，某一状态下的能量表达为：$$E(s) = - \\sum_{i=1}^{n-1}\\sum_{j=i+1}^n w_{ij}s_is_j-\\sum_{i=1}^n \\theta_is_i$$则这个状态出现的概率就是它的能量在所有状态总的能量和的占比。标准的Boltzman是全连接图，但是复杂度太高，所以简化成上图中b的受限状态。 受限Boltzman机常用“对比散度”（contrastive Divergence，简称CD）来进行训练。$$P(v|h) = \\prod_{i=1}^d P(v_i|h)$$ $$P(h|v) = \\prod_{i=1}^q P(h_j|v)$$ 先由显层样本的数据$v$求得隐层的分布，然后根据这个概率分布求采样得到$h$[6]，然后又从$h$求得$v’$.连接权的更新为：$$\\Delta w = \\eta(vh^T-v’h’^T)$$ 深度学习 增加层数比增加神经元更有效（能更大程度上增加复杂度） 多隐层神经网络很难用经典算法（如BP）进行训练，因为在逆传播时往往会“发散” 无监督逐层训练：训练多隐层网络，每次训练一层隐节点（基于上一层的输出，自己作为这层的输出者，夹在中间的感觉）每一层的训练为“预训练”，然后再用BP对整个进行微调，是一种局部+全局的方式。如深度信念网络(DBN) ”权共享“：一组神经元使用相同的连接权，在卷积神经网络中应用较多（CNN）[7] 后续扩展[1] 模拟退火&amp;&amp;随机梯度下降的区别 [2] 径向基函数的概念还是不太清楚 [3] 其他常用的无监督学习方法 [4] 增量学习/在线学习？ [5] 以后些些LSTM，也许嘻嘻 [6] 这里的反复跳转我总觉得学习信息会逐层流失，不是很明白 [7] 这里暂时不详谈 碎碎念银杏好美✨","link":"/2020/10/13/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"title":"线性模型","text":"进入🍉的第三章啦！之前有看过李宏毅老师的课，但是这本书看起来还是比较吃紧，冲！ 基本形式linear model是通过属性的线性组合来进行预测的函数，用向量形式表达的话就是：$$f(x) = \\omega^T x+b$$ 线性回归 最小二乘法：$$\\omega = \\frac {\\sum_{i=1}^m y_i(x_i-\\bar{x})}{\\sum_{i=1}^mx_i^2-\\frac 1m (\\sum_{i=1}^mx_i)^2}$$ $$b = \\frac 1m \\sum_{i=1}^m(y_i-\\omega x_i)$$ 多元线性回归$$\\hat \\omega^* = arg min(y-X\\hat \\omega)^T(y-X\\hat \\omega)$$其中$\\hat \\omega = (\\omega;b)$,$$X =\\begin{pmatrix} x_{11} &amp; x_{12} &amp; \\cdots &amp; x_{1d} &amp; 1\\\\ x_{21} &amp; x_{22} &amp; \\cdots &amp; x_{2d} &amp;1\\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ x_{m1} &amp; x_{m2} &amp; \\cdots &amp; x_{md} &amp;1\\\\ \\end{pmatrix} $$求导可得：$2X^T(X\\hat \\omega-y)$ 如果$X^TX$为满秩矩阵（正定矩阵）[1]则可直接求唯一解，当实际情况中$X$的列数多于行数，不是满秩，则变为求解方程组，存在多组解，需要在其中选择最合适的，常见方法是使用正则化[2] 广义线性模型：$$y = g^{-1}(\\omega^Tx+b)$$其中$g(.)$为单调可微函数，如$ln$ 对数几率回归如果需要用回归来做分类问题，最粗暴的是给一个零界点来判断（单位跃阶函数），但是他不是连续的也不可导，所以我们更普遍地使用”Sigmoid函数”，表达式为：$$y= \\frac {1}{1+e^{-z}}$$将$z$代入为$\\omega ^Tx+b$再转化形式为$ln \\frac {y}{y-1} = \\omega^Tx +b$其中$\\frac {y}{y-1}$就是几率，用线性回归模型的预测结果去逼近真实标记的对数几率，因此较多”对数几率回归”，又叫”逻辑回归“，这是一个凸函数，可以用梯度下降法或者牛顿法来求其最优解[3]，关于求最优解的过程，包括将y看作后验概率估计，用极大似然法的内容这里不赘述，详见书P59页。 线性判别分析 线性判别分析(LDA)直观上来说就是我们想要把样本投影到一条直线上，根据直线上两样本的距离来判断他们是否是相似的，因此优化目标就是：同一类的样本占据的总长度尽可能近，不同类的样本他们的中心点尽可能原，翻译成数学语言就是：$$J = \\frac {||\\omega^T\\mu_0-\\omega^T\\mu_1||_2^2}{\\omega^T\\sum_0\\omega+\\omega^T\\sum_1\\omega}$$对于两个样本要足够大，其中$\\mu_i,\\sum_i$分别代表样本的均值向量和协方差矩阵[3]，分子就是中心点距离足够大，分母就是协方差足够小。 推导最优解的过程略去(书P61)，但其从贝叶斯决策理论的角度来阐述，两类数据同先验、满足高斯分布且协方差相等时，可以达到最优解[4]。应用到多分类时，将样本投影到$d’$维空间，由于其维度小于数据原有的属性数量，且投影过程中使用了类别信息，因此也被视作典型的监督降维技术[5]。 多分类学习处理多分类问题一般是需要将其拆分为多个二分类问题，然后再集成为最终结果。 拆分方法： 一对一(OvO)：每两个分类组合，最后看每个分类被选择的次数 一对其余(OvR)：如图所示，最后看每个预测结果的置信度 多对多(MvM)：选一些做正类，一些做反类，常用的方法是”纠错输出码”(ECOC)，如下图所示： 对N分类问题做M次划分，最后看每个分类的结果组成的编码，通过计算和各类编码的距离来做分类判断。这里说它是纠错码的原因就是对错误有一定的包容度。 类别不平衡问题如果样例中的正反数量非常不一致，是很难训练出不错的效果的。通常我们判断是以0.5为界限，即$\\frac {y}{y-1} &gt;1$，但如果正反例数量不同，$m^+$和$m^-$分别代表正反例数目，则观测几率为$\\frac {m^+}{m^-}$，使用”再缩放“则可以将判断式子修正为：$$\\frac {y}{y-1} \\times \\frac {m^+}{m^-} &gt;1$$但这个方法并不简单，还有另外两种方式可以修改这个比例： 欠采样：EasyEnsemble，拆分 过采样：SMOTE，不能简单重复 习题习题答案参考链接 后续扩展[1] 正定矩阵的知识补充，我记得的是$P^TMP&gt;0$，还有其可逆，但是其他的记不得了 [2] 正则化是啥也忘记了 [3] 协方差的具体含义忘记了 [4] 这个结论和贝叶斯决策的东西都不太了解 [5] 投影后维度降了，之前直观理解中的距离概念应该是怎样的呢 碎碎念喜欢女孩和梧桐树的故事，那一段的风景","link":"/2020/09/10/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/"},{"title":"西瓜书绪论","text":"第一章主要是引入机器学习的背景，给出基础的术语。 引言机器学习是什么？在人的认识中，通常是根据先前的经验，加上这次的现象来推测结果，如西瓜书🍉中喜欢举的例子，我们以往的经验表明色泽青绿、根蒂蜷缩、敲声浊响的一般是好瓜，借这个经验我们可以来判断当前手里的瓜好不好。但如果希望计算机也能有这个能力的话，那么经验对于的就是数据，而这个判断按过程对于的就是我们的学习模型。 基本术语 data set：数据集，即一系列的样本的数据，如（色泽=浅白；根蒂=硬挺；敲声=浊响），（色泽=乌黑；根蒂=硬挺；敲声=浊响）…. sample：样本，上面数据集中一个（）内的内容即是一个样本的数据 feature：特征，如第一个样本的特征有浅白，硬挺，浊响 feature vector：特征空间，一个样本的所有特征可以组成一个特征向量，向量所在的空间可以是特征空间 label：一个样本的结果是它的标记 supervised learning(有label) classification：分类，预测的是离散值，如“好瓜”，“坏瓜” binary classification：二分类，只有两个类别，为positive class和negative class multi-class classification：多分类 regression：回归，预测的是连续值，如结果为[0,1]的值 unsupervised learning(无label) clustering：聚类，分类标准不是事前设定的，是一个训练的结果 generalization：泛化能力，模式适用于“新样本”的能力。通常来讲我们都是从所有的数据中抽取一部分来训练，我们这里的抽取是独立同分布的，一般来说，抽取的越多我们模型的泛化能力也越强 假设空间在西瓜🍉的这个例子中，我们如果只有三个特征，即色泽，根蒂和敲声，而又假设每个特征只有三个取值空间，那么如果我们期待从已有的数据中得到“好瓜”的判断逻辑表达式的话，只需要在27个中做选取，并且这27个中可能不止一个满足我们training test中的数据，之后将考虑如何从候选的表达中选取最好的一个。 归纳偏好承接上面的问题，如何选择？任何一个有效的机器学习算法必有其归纳偏好，否则它将被假设空间中看似在训练集上“等效”的假设所迷惑。这个有一个常用的判断价值观，即“奥卡姆剃刀”：“若有多个假设与观察一致，则选最简单的那个”，在图像中可能就是更平滑的曲线。但这个理论绝不是一定的，如下图所示： 在不同的情况下，他们的优劣并不明显显示，由没有免费的午餐理论（NFL，证明这里略过，见P9）[1]，即无论学习算法聪明/笨拙，他们的期望是一样的，和随机差不多，但这里的前提是“所有”问题出现的概率是相同，实际情况中，我们只用关注于特定的问题，因此这个结论并没有那么致命。它更重要的是告诉我们，针对一个具体任务，要具体的选择解决方案 习题1.2 在我前面文章的基础上，这里就是27×26×….×（27-k+1） 1.3 关注正确的百分率，偏好是能符合更多样本的更平滑的曲线 后续扩展[1] “没有免费的午餐的证明”","link":"/2020/09/06/%E8%A5%BF%E7%93%9C%E4%B9%A6%E7%BB%AA%E8%AE%BA/"},{"title":"集成学习","text":"集成学习(ensemble learning昂桑宝~)通过构建并结合多个学习器来完成学习任务，第八章 个体与集成集成学习特点：随着集成中个体分类器数量的增大，集成错误率将呈指数级下降，最终趋于零。但这里假设了各个学习器之间的错误率是相互独立的，但实际中因为是同一个样本集训练出来的其必然存在有联系，因此如何找到”好而不同“的学习器组合就是关键。 依据其学习器的类型分： 同质：里面的个体学习器用的一种类型的，里面的个体学习器叫做”基学习器“ 异质：相反，”组件学习器“ 依据个体学习器的生成方式分类： 个体学习器之间存在强依赖关系，串行生成，Boosting 个体学习器之间不存在强依赖关系，并行生成，Bagging，随机森林 Boosting特定：将弱学习器提升为强学习器，关注于降低偏差，基本只适合二分类问题。 其中最著名的代表是AdaBoosting，而使用”加性模型“会好推导一些（略，见书P174） 其中$D_t(x)$表示的是这一轮中样本的分布，在初始化第一行的时候我们可以看出他是均匀分布的，而推算一下第七行我们可以发现这里给分类错误的样本的分布系数更高了，也就是更关注分类错误的样本需要在后面的轮数中纠正，而7中的分子$Z_t$是一个保持$D$为分布的参数。为达到这个分布可以有两种方式：自身可带权训练的模型和每次”重新抽样“，前者可能会中途无法过if判断导致中断，而后者给了一个重新开始的机会能坚持到T轮结束。在推导中我们需要最小化的目标函数是指数损失函数：$$l_{exp}(H|D)= \\mathbb E_{x \\in D}[e^{-f(x)h(x)}]$$ Bagging与随机森林我们要希望集成后的模型泛化能力强的话，就更希望每个学习器较独立，但是这个独立已经说了，是不容易的，但是可以有促进的方式，如我们使每个基学习器所使用的样本不完全相同，即使用相互有交叠的采样子集。 bagging 特点：基于Bootstrap，降低方差，并行式，可用于多分类、回归问题。 算法：Bootstrap后训练完每个基学习器后，在集成时分类任务使用投票法，回归任务使用平均值。 Bootstrap对其的帮助： 每个样本大致能抽样63.2%，剩下的可以做泛化误差的”包外估计“ 决策树时用包外样本做剪枝辅助/估计后验概率帮助处理0样本特征 神经网络中辅助早期停止减小过拟合风险 随机森林随机森林是在bagging的基础上，限制了基学习器使用决策树，同时对决策树选择最优属性这个步”放宽“：从这个点的所有属性中随机选择一个子集，再从子集中计算选择一个最优属性。相当于基础的bagging只是对样本的选择增加了扰动，而随机森林对基学习器的训练步骤中也增加了扰动，根据上面的描述可以得出随机森林的一些特点： 基学习器较少的错误率较高，如下图的前面部分线段 最后通常会收敛到更低的泛化误差 训练效率优于bagging，因为不需要大量精准地计算最优属性了 结合策略集成的一个关键也在于如何”合“，即怎样将各个学习器学到的东西合起来，后面讲会介绍几种策略。首先学习器结合有以下优点： 统计角度：在一个大的假设圈里选择相信一个学习器的结果会是危险的，结合多个更稳妥 计算原因：容易陷入局部最优，如上图b所示，单个的学习器都没有指向真正f的位置，但是他们合起来的趋向是表征了f的位置的 表示原因：有时候我们的最优f并不在我们的假设空间中的（假设我们想错了分布一类的），这时如果是单个的假设不太能表示出f的位置，但如果多个学习器结合起来就可能描摹出f的轮廓来 平均法适合数值型的，可以做绝对的平均或者是加权平均，但是需要注意的是加权平均不一定就比绝对平均好，注意过拟合！！！ 投票法适合平均型，可以分为如下几类： 学习法前面两种都是较直接地结合，但也是可以用学习器来结合的，用次级学习器来结合之前初级学习器的结果，即将初级学习器的输出特征作为次级学习器的输入特征。常用方法是stacking，常用的次级学习器是多响应线性回归（MLR），整个学习法的算法流程图如下： 多样性暂时略 后续补充 后续拓展","link":"/2020/09/16/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/"},{"title":"贝叶斯分类器","text":"贝叶斯分类器，概率框架下… 贝叶斯决策论定义一个多分类问题上的条件风险：$$R(c_i|x) = \\sum_{j=1}^N \\lambda_{ij}P(c_j|x)$$此式子的含义是，将$x$分错类的损失（本来是$c_i$类）是$x$为每一个类别的概率乘以权重的和，如果是想要最小化分类错误率，则当$i=j$时，$\\lambda_{ij}=0$，其他情况下为1。此时的条件风险可以简化为：$$R(c|x) = 1-P(c|x)$$即条件风险为1-把$x$分对类的概率。这样我们的优化目标是最小化条件风险，那么就是$h^*(x) = arg , max P(c|x)$。那任务就转化为更准确估计$P(c|x)$后验概率（给出了相关证据和数据后的条件概率）。有两种方式： 判别式模型：直接建模$P(c|x)$，如决策树，BP神经网络，支持向量机等 生成式模型：先给出联合概率分布$P(c,x) = \\frac {P(c)P(x|c)}{P(x)}$，其中分母是归一化因子[1]，给定样本后其和标记无关，因此可以略了，考虑最大化分母，分母中$P(c)$可以通过大数定理频率计算得出，而$P(x|c)$表达的是在c类别(这里c是所有类别的意思)中$x$出现的概率。但并不好计算，因为类别很多且有些类别可能还不出现。 极大似然估计 概率论中的概念，假设$P(x|c)$具有确定的形式且被参数向量$\\theta_c$唯一确定，那我们的任务就转变为通过训练集估计参数$\\theta_c$，参数估计有两种不同的解决方案： 贝叶斯学派：参数本身也有分布 频率主义学派：参数未知但固定——极大似然估计法 $$LL(\\theta_c) = log , P(D_c|\\theta_c) = \\sum_{x \\in D_c} log,P(x|\\theta_c)$$ 最后是需要找到使得这个表达式最大的参数$\\theta_c$的值，但因为提前假设了分布，如果这个猜测不准确的话，对估计的准确度影响很大。 朴素贝叶斯分类器在贝叶斯策论中提到$P(x|c)$不方便计算，原因是要考虑在某一个分类下一个样本出现的概率它是对所有特征的联合考虑，很难从有限的样本中估计得来[2]。但朴素贝叶斯分类器考虑”属性条件独立性假设“：对已知类别，假设所有属性相互独立，换言之，假设贝格属性独立地对分类结果发生影响。基于这个假设，可写出贝叶斯判定准则：$$h_{nb}(x) = \\underset{c \\in y}{arg , max} , P(c)\\prod_{i=1}^dP(x_i|c)$$如果在一个类别$c$中某个属性$x_i$没有出现过呢？这里放0的话，会导致连乘式子整个为0，这是不符合直觉的。因此我们使用平滑(smoothing)，常用”拉普拉斯修正“：$$\\hat {P}(c) = \\frac {|D_c|+1}{|D|+1}$$在使用方式上也有多种： 提前计算出所有的概率估值 更新频繁的使用”懒惰学习“(lazy learning)，用的时候再算 数据不断增加，支队新增的样本的属性值和涉及的概率估计量做修正，实现增量学习(ART对抗网络) 半朴素贝叶斯分类器前面的贝叶斯分类器假设了所有属性相互独立，但实际中这样的情况是很少出现的，这里的半朴素贝叶斯分类器就是有考虑特征之间的关联，有以下几种处理方式： 独依赖估计(ODE)：假设每个属性都最多依赖于一个父属性。 SPODE(Super-Parent ODE)：如何找父属性？这里可以对所有属性找一个共同的父属性，即”超父“ TAN(Tree Augmented naive Bayes)基于最大带权生产树[3]，保留了强相关属性之间的依赖性[4]： 计算任意两个属性间的条件互信息：$$I(x_i,x_j|y) = \\sum_{x_i,x_j;c \\in y} P(x_i,x_j|c) log \\frac {P(x_i,x_j|c)}{P(x_i|c)P(x_j|c)}$$ 以属性为结点构建完全图，任意两个节点之间边的权重设为上述的条件互信息 构建完全图[5]的最大带权生成树，挑选根变量，边置为有向 加入类别节点y，增加从y到属性的有向边 AODE(Averaged One-Dependent Estimator)：将每个属性作为超类来构建SPODE，然后将有足够训练数据支撑的SPODE集成起来作为最终结果（有集成学习的思想在这里，同时”有足够训练数据支撑“代表它会对参与训练的数据数量做一个阈值过滤）$$P(c|x) \\Rightarrow \\sum_{i=1, |D_{x_i}|\\geq m’}^d p(c,x_i) \\prod_{j=1}^d P(x_j|c,x_i)$$数量的过滤就可以从公式的$|D_{x_i}|\\geq m’$看出来啦，同时为了规避0样本数的出现，也需要smoothing：$$\\hat P(c,x_i) = \\frac {|D_{c,{x_i}}|+1}{|D|+N \\times N_i}$$ $$\\hat P(x_j|c,x_i) = \\frac {|D_{c,x_i,x_j}|+1}{|D_{c,x_i}|+N_j}$$ 这里面的$N$是指$D$中可能的类别数，$N_i$是第i个属性可能的取值数。 贝叶斯网也叫”信念网“，借助于”有向无环图“来刻画属性间的依赖关系，使用条件概率表(CPT)来描述属性的联合概率分布。 因此一个贝叶斯网$B=&lt;G, \\Theta&gt;$，其中$G$表达的是图的拓扑结构，而$\\Theta$表达的是图中节点关系，节点其实就是属性，关系就是一组条件概率表，为子属性的每一个种类在父属性的每一个种类下的条件概率。如下图所示： 结构贝叶斯网描述了不同特征之间的联系，那我们如何用它来刻画之前难以确定的”部分属性联合“呢？答案就是根据边的连接关系来分离，我们只认为直接相连的属性有联系，间接相连的是独立的（可能说法有误，其实也是间接联系），由此得到多个属性的联合概率分布：$$P_B(x_1,x_2,…,x_d) = \\prod_{i=1}^d P_B(x_i|\\pi_i) = \\prod_{i=1}^d \\Theta_{x_i|\\pi_i}$$如上图的西瓜问题的几个属性的联合概率分布就是：$$P(x_1,x_2,x_3,x_3,x_4,x_5)=P(x_1)P(x_2)P(x_3|x_1)P(x_4|x_1,x_2)P(x_5|x_2)$$具体从图中可以归纳出三种结构： 同父结构：如果$x_1$确定，那么$x_3,x_4$就相互独立 顺序结构：同理，如果$x$定了的话 V型结构：$x_4$确定的话，上面的父亲不能相互独立，儿子随机的话倒是相互独立（证明见书P158），称作”边际独立性“ 为了更方便分析里面的独立关系，我们使用”有向分离“： 找出V型结构，将两个父亲用无向线连起来 全部化为无向 其实这里主要目的就是将V型不能确定一个独立两个这个特定固定下来（毕竟儿子不能真随便呀），而另外两个结构其实含义一样，那就可以不用箭头了，变成了”道德图“😄（这名字很神奇） 学习学习就需要一个归纳偏好，这里给出的是”评分函数“（信息论准则，”最小描述长度“[6]）：$$min , s(B|D)=f(\\theta)|B|-LL(B|D)$$其中$|B|$表示参数个数，$f(\\theta)$表示参数编码长度，右边是对数似然，表征了概率分布对D描述的好坏程度。 $f(\\theta)=1$：AIC $f(\\theta)=0$：退化为负对数似然 $f(\\theta)= \\frac 12logm$：BIC 由于在参数格式确定时，左边是固定的，同时似然函数的各个经验概率也可计算，因此变成了一个对所有网络结构的遍历过程，这个是NP问题，有两种策略可以”放松“条件： 贪心：从初始网络出发，做调整一条值直到不能再低 对网络结构做限制，如只要树结构等 推断 推断就是用一些特征（证据）来得到另一些特征出现的概率。直接用联合概率分布是NP问题，这里采用”吉布斯采样“。它使用的是一种在子空间”随机漫步“的采样，即”马尔可夫链“[7]，基于证据的特征，每一步改变一下，经过t次采样后后计算此时打中”推断“所占的比例，就是这个条件概率。理论依据在于马尔可夫链第t步状态在步数无穷大的时候会收敛于一个平稳分布，我们就是要让他平稳，然后得到这个分布。 缺点：收敛慢，极端情况不保证平稳收敛。 EM算法 前面都假设的每个属性的每个特征都有样本可以观测，那如果没有对应的样本(即隐变量)应该怎么处理呢？（和之前smoothing想要解决的问题类似[8]）这里使用EM算法(Expectation-Maximization)，其思想是先确定$\\Theta$来估计$Z$隐变量的分布，表达出$\\Theta$的极大似然估计式子，再对这个式子最大化来得到新的一个$\\Theta$，如此迭代运算最终收敛于最优解，是一种非梯度优化方法。 后续扩展[1] 归一化 [2] 如我们判断在好瓜的条件下，$x$样本={$x_1$=1,$x_2$=0,…,$x_n$=1}的概率，借助大样本中出现的频率作为概率的话，我们需要找和$x$特征值完全相符的来计算，但是很多情况下特征值很多其组合可能大于样本数，那么很可能根本找不到这个一样的，更别说这样的估计看起来就很不准确，因此这里被这个联合概率击败 [3] 最大带权生成树🌲 [4] 是指有向边代表了其父属性关系是8 [5] 完全图定义补充 [6] 为什么喜欢短的呀 [7] 马尔可夫链14章 [8] 但我感觉前面是有用过smoothing的呀","link":"/2020/09/15/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8/"},{"title":"基础算法复习","text":"算法方面忘得很多了，也比较长时间没有使用C/C++，这学期事情不是很多，有时间可以看看。 暴力求解判断输入是否结束：while (scanf(&quot;%d, &amp;h&quot;) != EOF) 在事先不清楚有多少数据的情况下通过 scanf 的返回值，即成功赋值的个数来达到判断的功能 日期题目闰年的判断语句：(year%4 == 0 &amp;&amp; year%100 != 0)||(year%400 == 0) 排序和查找sort函数：12#include &lt;algorithm&gt;sort(first, last, comp) 默认为升序排列，若要更灵活地实现排序，则要自己编写comp函数 1234567bool Compare(Student x, Student y){ if(x.score == y.score){ return x.number &lt; y.number }else{ return x.score &lt; y.score }} 在设计排序算法时的一个tip：当比较函数的返回值是true时，表示的是比较函数的第一个参数将会排在第二个参数前面。 对于结构体或类的自定义排序，还可以用sort函数按照题面要求定义不同的排序规则。 二分查找123456789101112131415bool BinarySearch(int n, int target){ int left = 0; int right = n-1; whhile(left &lt; right){ int middle = (left+right)/2; if(arr[middle] &lt; target){ left = middle+1; }else if(target &lt; arr[middle]){ right = middle-1; }else{ return true; } } return false;} 当数据很大时，为防止溢出，可以用 int middle = left+(right-left)/2替代 int middle = (left+right)/2 字符串string的使用1234567891011121314151617181920string str = &quot;hello world&quot;;n = str.size()//迭代器访问for(string::iterator it = str.begin(); it != str.end(); ++it){ printf(&quot;%c&quot;, *it);}//在任意位置插入元素str.insert(str.size(), &quot;end world&quot;);//在任意位置删除元素str.erase(7);//将字符串清空str.clear();//可以使用加号拼接字符串str1 = str+str2;//判断字符串关系str1 &lt;= str2;//find查找特定字符串，若找到对应的字符/字符串就返回对应下标；找不到则返回string::nposint found = str.find(&quot;world&quot;);//返回字符串子串的函数substr()string str2 = str1.substr(3,5); 当输入是一行字符串时，使用：while(getline(cin, str)){} 初始化数组：memset(number, 0, sizeof(number)); 字符串匹配(KMP)12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364#include &lt;iostream&gt;#include &lt;cstdio&gt;using namespace std;const int MAXM = 10000;const int MAXN = 1000000;int nextTable[MAXM];int pattern[MAXM];int text[MAXN];void GetNextTable(int m){ int j = 0; nextTable[j] = -1; int i = nextTable[j]; while(j &lt; m){ if(i == -1 || pattern[j] == pattern[i]){ i++; j++; nextTable[j] = i; }else{ i = nextTable[i]; } } return ;}int KMP(int n, int m){ GetNextTable(m); int i = 0; int j = 0; while(i&lt;n &amp;&amp; j&lt;m){ if(j == -1 || text[i] == pattern[j]){ i++; j++; }else{ j = nextTable[j]; } } if(j == m){ return i-j+1; }else{ return -1; }}int main(){ int caseNumber; scanf(&quot;%d&quot;, &amp;caseNumber); while(caseNumber--){ int n, m; scanf(&quot;%d%d&quot;, n, m); for(int i=0; i&lt;n; i++){ scanf(&quot;%d&quot;, &amp;text[i]); } for(int j=0; j&lt;m; j++){ scanf(&quot;%d&quot;, &amp;pattern[j]); } printf(&quot;%d\\n&quot;, KMP(n, m)); } return 0;} 数据结构向量vector 头文件和声明：#include &lt;vector&gt; vector&lt;typename&gt; name vector的状态：当前是否为空的 empty(), 返回当前向量元素个数 size() vector尾部元素的添加或删除。push_back() pop_back() 元素的访问：下标访问，从0到size()-1；通过迭代器访问，类似指针 元素操作：insert() erase() clear() 迭代器操作：首元素 begin() 尾元素 end() 使用场合：在数据量不确定的情况下完成数据的处理，还可以实现图论中的邻接表 队列Queue 定义：#include &lt;queue&gt; queue&lt;typename&gt; name 判断是否为空：empty() 元素个数：size() queue元素的添加或删除：push() pop() queue元素的访问：front() back() 栈stack 定义：#include &lt;stack&gt; stack&lt;typename&gt; name 判断是否为空：empty() 元素个数：size() stack元素的添加或删除：push() pop() stack元素的访问：top() 一个字符串小技巧：string answer(str.size(), ' '); 典型题：括号匹配，简单计算器 数学问题进制转换基本代码如下，一般情况下会遇到只能以字符串形式储存，需要设计字符串计算的函数 12345678910111213141516171819202122#include &lt;iostream&gt;#include &lt;cstdio&gt;#include &lt;vector&gt;using namespace std;int main(){ unsigned int n; while(scanf(&quot;%d&quot;, &amp;n) != EOF){ vector&lt;int&gt; binary; while(n != 0){ binary.push_back(n % 2); n /= 2; } for(int i = binary.size()-1; i&gt;= 0; i--){ printf(&quot;%d&quot;, binary[i]); } printf(&quot;\\n&quot;); } return 0;} 最大公约数与最小公倍数最大公约数 12345678910111213141516171819#include &lt;iostream&gt;#include &lt;cstdio&gt;using namespace std;int GCD(int a, int b){ if(b == 0){ return a; } else{ return GCD(b, a%b); }}int main(){ int a, b; while(scanf(&quot;%d%d&quot;, &amp;a, &amp;b) != EOF){ printf(&quot;%d\\n&quot;, GCD(a, b)); } return 0;} 最小公倍数用的公式就是：a*b/GCD(a, b) 质数 判断是否为素数 123456789101112bool Judge(int x){ if(x&lt;2){ return false; } int bound = sqrt(x); for(int i=2; i &lt; bound; i++){ if(x % i == 0){ return false; } } return true;} 素数筛法 123456789101112131415void Initial(){ for(int i = 0; i &lt; MAXN; i++){ isPrime[i] = true; } isPrime[0] = false; isPrime[1] = false; for(int i = 0; i &lt; MAXN; i++){ if(!isPrime[i]) continue; prime.push_back(i); for(int j=i*i; j&lt;MAXN; j+=i){ isPrime[j] = false; } } return;} 分解质因数：在素数筛法的基础上完成 快速幂 12345678910111213int FastExponentiation(int a, int b, int mod) { int answer = 1; while(b != 0){ if(b % 2 == 1){ answer *= a; answer %= mod; } b /= 2; a *= a; a %= mod; } return answer;} 矩阵与矩阵快速幂 12345678910111213141516171819202122232425262728293031323334353637383940414243#include &lt;iostream&gt;#include &lt;cstdio&gt;using namespace std;struct Matrix { int matrix[10][10]; int row, col; Matrix(int r, int c): row(r), col(c){}};Matrix Multipy(Matrix x, Matrix y){ Matrix answer(x.row, y.col); for(int i=0; i &lt; answer.row; i++){ for(int j=0; j&lt;answer.col; j++){ answer.matrix[i][j] = 0; for(int k=0; j &lt; answer.col; k++){ answer.matrix[i][j] += x.matrix[i][k]*y.matrix[k][j]; } } } return answer;}void PrintMatrix(Matrix x){}Matrix FastExponentiation(Matrix x, int k){ Matrix answer(x.row, x.col); for(int i=0; i&lt;answer.row; i++){ for(int j=0; j&lt;answer.col; j++){ if(i == j) answer.matrix[i][j] = 1; else answer.matrix[i][j] = 0; } } while(k != 0){ if(k % 2 == 1){ answer = Multipy(answer, x); } k /= 2; x = Multipy(x, x); } return answer;} 其核心思想和前面的非矩阵快速幂一致 高精度整数（给一个模板，但只适合正整数） 1234567891011121314151617181920struct BigInteger{ int digit[MAXN]; int length; BigInteger(); BigInteger(int x); BigInteger(string str); BigInteger(const BigInteger&amp; b); BigInteger operator=(int x); BigInteger operator=(string str); BigInteger operator=(const BigInteger&amp; b); bool operator&lt;=(const BigInteger&amp; b); bool operator==(const BigInteger&amp; b); BigInteger operator+(const BigInteger&amp; b); BigInteger operator-(const BigInteger&amp; b); BigInteger operator*(const BigInteger&amp; b); BigInteger operator/(const BigInteger&amp; b); BigInteger operator%(const BigInteger&amp; b); friend istream&amp; operator&gt;&gt;(istream&amp; in, BigInteger&amp; x); friend ostream&amp; operator&lt;&lt;(ostream&amp; out, const BigInteger&amp; x);}; 其中每一个部分都有相应板块的代码，具体见书P107（太长了，最好理解了敲来背） 贪心策略 贪心策略一般用在优化问题上，其核心思想是选择当前状态下的最优解，即不以整体最优进行考虑，而只考虑当下这一步。但在某些问题中，局部最优能收敛到全局最优，使用贪心就很有效果。这类最优问题的特点是具备无后效性，即某个状态以前的过程不会影响以后的状态，而只与当前状态有关。 区间贪心指当有多个不同的区间存在，且这些区间有可能相互重叠的时候，如何选择才能从众多区间中，选取最多的两两互不相交的区间。 列题：搭桥问题 有n个岛屿，每个岛屿都可以用直线上不相交的线段表示，岛屿的坐标为$[l_i, r_i]$，对于所有$1 \\leq i \\leq n-1$都有$r_i &lt; l_{i+1}$为了能让两个临近的岛屿相连接，需要在其之间架一座桥。长度为a的桥可以架在第i和第i+1号岛屿之间，如果它们的坐标为x和y，则有$l_i \\leq x \\leq r_i$，$l_{i+1} \\leq y \\leq r_{i +1}$和$y-x=a$。 我们可以使用m座桥，每座桥最多可以使用一次。请确定他可用的桥梁是否能够连接每对相邻的岛屿。 题解： 一共n个岛屿的话，可以得到n-1个需要架的桥的区间（相邻的才架），对于每个区间设定[minimum, maxmum]，对区间按照minimum排序，对给的桥按照length排序。最后在所有能满足的区间中，选择maxmum最小的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687#include &lt;iostream&gt;#include &lt;cstdio&gt;#include &lt;cstring&gt;#include &lt;algorithm&gt;#include &lt;queue&gt;using namespace std;const int MAXN = 200001;struct Island{ long long left; long long right;};struct Bridge{ long long length; long long index;};struct Interval{ long long minimum; long long maxmum; long long index; //区间编号 bool operator&lt; (Interval x) const{ //操作符的重载 return maxmum &gt; x.maxmum; }};//自定义比较函数bool IntervalCompare(Interval x, Interval y){ if(x.minimum == y.minimum){ return x.maxmum &lt; y.maxmum; } else { return x.minimum &lt; y.minimum; }}bool BridgeCompare(Bridge x, Bridge y){ return x.length &lt; y.length;}Island island[MAXN];Bridge bridge[MAXN];Interval interval[MAXN];long long answer[MAXN];bool Solve(int n, int m){ priority_queue&lt;Interval&gt; myQueue; //优先队列的性质 int position = 0; //当前区间的下标 int number = 0; //搭建桥的数目 for(int i=0; i&lt;m; i++){ while(myQueue.top().maxmum &lt; bridge[i].length &amp;&amp; !myQueue.empty()){ myQueue.pop(); } while(position &lt; n-1 &amp;&amp; (interval[position].minimum &lt;= bridge[i].length) &amp;&amp; (interval[position].maxmum &gt;= bridge[i].length)){ myQueue.push(interval[position]); position++; } if(!myQueue.empty()){ Interval current = myQueue.top(); myQueue.pop(); answer[current.index] = bridge[i].index; number++; } } return number == (n-1);}int main(){ int n, m; while(scanf(&quot;%d%d&quot;, &amp;n, &amp;m) != EOF){ memset(island, 0, sizeof(island)); memset(bridge, 0, sizeof(bridge)); memset(interval, 0, sizeof(interval)); memset(answer, 0, sizeof(answer)); for(int i=0; i&lt;m; i++){ scanf(&quot;%lld%lld&quot;, &amp;island[i].left, &amp;island[i].right); } for(;;){ //输入桥的信息 } //计算区间，排序，选择 }} 上面代码涉及到优先队列，他的用法和概念后面说。 递归与分治构成递归需要具备两个条件： 子问题必须与原始问题相同，且规模更小，尝试列出等式 不能无限制地调用本身，必须有一个递归出口 分治法，“分而治之”，即把复杂的问题分成两个或更多个子问题，子问题间相互独立且与原问题相同或相似，持续分直到最后的子问题可以简单直接求解。分治法中也和递归有结合，它们是相互依存的。 搜索宽度优先搜索 状态。需要确定所求解问题中的状态，通过状态的扩展，遍历所有的状态，从中寻找需要的答案 状态的扩展方式。 有效状态。有一些状态不需要再次扩展可以直接舍弃 队列。为了使得状态能够先扩展，使用队列，将得到的状态依次放入队尾，每次取对头元素进行扩展 标记。区分有效和无效的状态（比如下面代码要区分已经访问过了还是没有访问） 有效状态数。估计是否在时间范围内能完成整个搜索 最优。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#include &lt;iostream&gt;#include &lt;cstdio&gt;#include &lt;cstring&gt;#include &lt;queue&gt;using namespace std;const int MAXN = 100001;//储存位置和时间struct Status{ int n, t; Status(int n, int t): n(n), t(t){}};bool visit[MAXN];int BFS(int n, int k){ queue&lt;Status&gt; myQueue; myQueue.push(Status(n, 0)); visit[n] = true; while(!myQueue.empty()){ Status current = myQueue.front(); myQueue.pop(); if(current.n == k){ return current.t; } for(int i=0; i&lt;3; i++){ Status next(current.n, current.t+1); if(i == 0){ next.n += 1; } else if(i == 1){ next.n -= 1; } else{ next.n *= 2; } if(next.n &lt; 0 || next.n &gt;= MAXN || visit[next.n]){ continue; } myQueue.push(next); visit[next.n] = true; } }}int main(){ int n, k; scanf(&quot;%d%d&quot;, &amp;n, &amp;k); memset(visit, false, sizeof(visit)); printf(&quot;%d\\n&quot;, BFS(n, k)); return 0;} 深度优先搜索通常使用递归函数，一般不能来求最优解，而是使用来判断有无解，是存在性问题。注意不能递归层数太深，可能会出现“爆栈”的问题 数据结构二二叉树前序遍历先根节点-左-右 中序遍历左-根-右 后序遍历左-右-根 层次遍历需要设置队列来装 二叉排序树二叉排序树的特点： 左子树非空的话，左子树上所有结点关键字的值小于根结点关键字的值 右子树非空的话，右子树上所有结点关键字的值大于根结点关键字的值 左右子树本身也是一棵二叉排序树 优先队列能够将数据按事先规定的优先级进行动态组织的数据结构称为优先队列，访问元素时，只能访问当前队列中优先级最高的元素。 在头文件queue中，定义为priority_queue&lt;typename&gt; name 元素个数size()，是否为空empty()，push()，pop()，访问top() 默认为大顶堆，即优先级高的先输出。要改为小顶堆：priority_queue&lt;typename, vector&lt;typename&gt;, greater&lt;typename&gt;&gt; name 哈夫曼树：带权路径长度和最小的二叉树。求解时每次找最小的两个结点组合起来。 散列表一般的搜索方式，无论是向量还是树，结构中元素存放位置与元素的关键字之间并不存在确定的关系，因此在查找时需要对关键字进行比较，最好也就是$O(log_n)$，但是使用散列表直接对关键字进行访问的话，可以在$O(1)$下完成。 先介绍标准库中的map，map是将关键字和映射值形成一一映射绑定存储的容器，底层是用红黑树实现的，内部依然有序，所以查找效率为$O(log_n)$。标准库中还有一个无序映射unordered_map，底层是散列表，期望查找效率为$O(1)$。在数据量不大时，map可以完成几乎所有工作了，如果实在需要使用unordered_map，直接改一下名称就好，用法基本一样。 定义：在 &lt;map&gt;中，需要 map&lt;typename1, typename2&gt; name 状态有两个，empty()和size() 添加和删除：insert() erase() 访问用[key]或者at()或者迭代器 查找特定元素find()，找到时返回的是该元素的迭代器，没找到就返回迭代器end() 映射清空的操作clear() map迭代器操作：begin() end() 图论图的结构可以用邻接矩阵或邻接表表示，分类上可以分为有向/无向图，是否带权。 并查集并查集用于处理一些不交集的合并和查询问题。有以下两个功能： 判断任意两个元素是否属于同一个集合； 按照要求合并不同的集合； 首先将集合在逻辑上表示为树结构，每个结点都指向其父节点，而树中的元素无顺序之分，在同一棵树上的就是一个集合中的。并查集有两个操作，查找和合并 查找：确定元素属于哪个集合。不断向上查找，直到找到他的根结点，之后根据根节点是否相同来判断两个元素是否属于一个集合。 合并：将一棵树作为另一颗树的子树，从而使得两棵树变为一棵更大的树。 为了避免不好的树的形态（最差的就是退化为单链表），需要对合并做一定的约束和优化，具体下来就是路径压缩。在查找到某个结点的根结点时，将其与根节点之间的所有结点都直接指向根结点。且还有个小技巧，就是在合并时，总是将高度较低的树，作为高度较高的树的子树进行合并。 应用：在图论中，用来判断是否为连通图，或用来求图的连通分量。 连通图的定义：在一个无向图G中，若顶点u到顶点v有路径相连，则两点是相连的。若图中任意两点都是连通的，则为连通图。而G中的一个极大连通子图为G的一个连通分量。连通图只有自己为唯一的连通分量 最小生成树如果存在一个连通子图，包含原图中所有顶点和部分边，且这个子图不存在回路，则 为原图的一棵生成树。在带权无向连通图中，所有生成树中边权的和最小的那一颗被称为该无向图的最小生成树。常见算法：Kruskal和Prim 最短路径Dijkstra算法 拓扑排序针对的有向无环图。按照方向排一个序。 关键路径动态规划动态规划通常用于求解最优解的问题，与分治法类似，基本思想都是将待求问题分解成若干个子问题，先求解子问题，然后从这些子问题中得到原问题的解。但与分治法不同的是，适合用于动态规划求解的问题，经分解得到的子问题往往不是相互独立的。若用分治法来解这类问题，则分解得到的子问题太多，有些子问题会被重复计算很多次。而动态规划的做法是将已解决子问题的答案保存下来，在需要子问题答案的时候便可直接获得，而不需要重复计算，这样可以避免大量的重复计算，提高效率。 递推求解最大连续子序列和最长递增子序列最长公共子序列背包问题","link":"/2020/09/21/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95%E5%A4%8D%E4%B9%A0/"},{"title":"BSNN","text":"论文理解本质其实是一个文本分类问题，解决的问题是对网络协议分类，但不同于以往的协议分类问题，这篇论文不使用报文头等特征信息，而是纯粹地从payload特征提取角度对网络协议分类。因此可以看作一个文本分类问题，输入一个packet的payload部分，输出报文协议类型。其优点在于： 可以学习新的协议，而不被限制于已有协议 不需要繁复的对报文头特征信息的挖掘（并且这些信息可能是不靠谱的，可以修改的话） 模型结构如上所示，是一个Hierarchical attention network。 先解释一下模型中的各个字段的意思。Datagram指的是一个packet中的payload部分，如下图wireshark抓包后蓝色的byte部分。进一步对Datagram做划分可以得到很多个长度均等的Segment，这里如果设定每个segment长度都为5的话，一个segment就可以表达为下图中红色方框部分。可以看到一个segment[3b, de, 01, 00, 00]里有多个十六进制字符。 这里为了更好的理解，可以做一个类比： 一篇文章 ==&gt; datagram ==&gt; [3b, de, 01, 00, 00, 01, 00, 00……] 文章中的句子 ==&gt; segment ==&gt; [3b, de, 01, 00, 00] 句子中的单词 ==&gt; 3b 现在要对这样一个结构的datagram做训练，最后需要学到它所属的协议类型。模型的直觉就是我们首先去关注一个句子（segment）中单词（character）的表达，使用rnn(LSTM/GRU)训练并且每个单词对于这个句子的重要性是不同的（attention机制），通过这样一个过程得到这个句子（segment）的表达。之后再重复类似的过程，在一篇文章（datagram）中，不同句子的重要性不同，关注于“焦点”，通过一个attention encoder得到这篇文章（datagram）的表达，使用softmax等最后得到这个文章（datagram）的类别。 整个模型有两层attention encoder，使用的RNN Unit是LSTM/GRU（我后面实现的GRU，因为对我的电脑友好一些🐶），且是bidirectional的（双向），因为这里上下文都是有意义的，需要全局的。实现细节上使用Focal Loss，主要是为了处理样本数据不均衡的问题（好巧不巧我做数据的时候正好每个类别都是均分的，似乎对我这个没有多大用处，我的错），评估指标使用$F_1$。 代码复现代码目录中data文件夹内为数据，try文件夹中为第一次尝试的pytorch代码（nn结构有问题，当时不太搞明白多层attention怎么写，但也是个实践过程先保存下来），run_BSNN保存的运行数据，pre.py做数据预处理，DataUtil.py做数据padding及划分，BSNN.py放模型，train.py为运行入口。 tensorflow版本为1.14（主要想使用一个老版本的库，降到这个版本，warning还是有的😅），pre使用的pytorch（但是相关数据预处理已运行出来保存好了，因此不需要再使用pytorch运行pre.py） 数据预处理论文中数据集是自己收集了，并且在网上找了一下现存数据集，比较难得到条件适合的，因此自己流量抓包收集了300笔数据（多了我电脑伤不起欸😭）。数据特征如下： 抓的是DNS，OICQ，QUIC三个协议，每个抓取了100笔，其中后两个是google使用的快传协议和QQ使用的协议 一些报文内容较短，一些很长，这个特点使得做数据padding时较难选择一个合适的统一长度（我这里最后选择的100作为固定长） 因为是连续地抓取，前后报文相似度很多，因此每类协议多样性不足 预处理流程如下图所示： pre.py中数据处理代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869# -*- coding: utf-8 -*-import jsonimport csvimport pandas as pdimport numpy as np# 一个segment的长度，论文中推荐的是L=8SEGMENT_LEN = 8packets = []# 下面三个都是对报文数据做处理，提取出需要的payload部分，存储下来with open('data/QUIC.json', 'r', encoding='UTF-8') as reader: content = json.load(reader) #len(content) 先弄小一点的数据集 for i in range(0, 100): packet = ['0', content[i][&quot;_source&quot;][&quot;layers&quot;][&quot;udp&quot;][&quot;udp.payload&quot;]] packets.append(packet) reader.close()# QQ的协议with open('data/OICQ.json', 'r', encoding='UTF-8') as reader: content = json.load(reader) #len(content) 先弄小一点的数据集 for i in range(0, 100): packet = ['1', content[i][&quot;_source&quot;][&quot;layers&quot;][&quot;udp&quot;][&quot;udp.payload&quot;]] packets.append(packet) reader.close()with open('data/DNS.json', 'r', encoding='UTF-8') as reader: content = json.load(reader) #len(content) 先弄小一点的数据集 for i in range(0, 100): packet = ['2', content[i][&quot;_source&quot;][&quot;layers&quot;][&quot;udp&quot;][&quot;udp.payload&quot;]] packets.append(packet) reader.close()# train数据写入csv ==&gt; payload.csvcsv_fp = open(&quot;data/train.csv&quot;, &quot;w&quot;, encoding='utf-8', newline='')writer = csv.writer(csv_fp)writer.writerow(['label', 'payload'])writer.writerows(packets)csv_fp.close()&quot;&quot;&quot;将payload中字符转化为0-255数字将每个datagram的payload按照长度N=SEGMENT_LEN划分return: [[label, [[0,1,2,3,...][]....]]]&quot;&quot;&quot;def segment_slice(): data = pd.read_csv('data/train.csv', encoding='UTF-8') labels = data['label'] payloads = data['payload'].apply(lambda x :x.split(':')) Datagrams = [] # [[label, [0,255,...]],...] for i in range(0, len(data)): Datagram = [] # [label, [0,255,...]] for j in range(0, len(payloads[i])): Datagram.append(int(payloads[i][j], 16)) Datagrams.append([labels[i], Datagram]) # 切片 for i in range(0, len(Datagrams)): last_num = len(Datagrams[i][1]) % SEGMENT_LEN Datagrams[i][1] = Datagrams[i][1] + [0]*(SEGMENT_LEN-last_num) temp = np.array(Datagrams[i][1]) temp = temp.reshape(-1, SEGMENT_LEN) Datagrams[i][1] = temp return Datagrams DataUtil.py中进一步处理 123456789101112131415161718192021222324252627282930313233343536373839404142434445import numpy as npimport pre as preimport random&quot;&quot;&quot;datagram的segment数量不一致，都统一为maxlen大小 空的填充0向量不足：0的填充比较多&quot;&quot;&quot;def pad_data_x(data_xs, maxlen=100, PAD=0): padded_data_xs = [] for data_x in data_xs: # 一个datagram的 if len(data_x) &gt;= maxlen: padded_data_x = data_x[:maxlen] else: padded_data_x = data_x zero_len = maxlen-len(padded_data_x) zero = np.zeros([zero_len,8], int) padded_data_x = np.insert(padded_data_x, len(data_x), values=zero, axis=0) padded_data_xs.append(padded_data_x) return padded_data_xsdef read_dataset(): num_classes = 3 datagrams = pre.segment_slice() random.shuffle(datagrams) # 打乱数据集 data_x = [] data_y = [] for datagram in datagrams: label = datagram[0] labels = [0] * num_classes labels[label-1] = 1 # 转化为one-hot data_y.append(labels) data_x.append(datagram[1]) data_x = pad_data_x(data_x) # 划分训练集，验证集 length = len(data_x) train_x, dev_x = data_x[:int(length*0.9)], data_x[int(length*0.9)+1 :] train_y, dev_y = data_y[:int(length*0.9)], data_y[int(length*0.9)+1 :] return train_x, train_y, dev_x, dev_y 模型构建模型主要分为四个部分： word encoder （BiGRU layer） word attention （Attention layer） sentence encoder （BiGRU layer） sentence attention （Attention layer） GRU原理 GRU是RNN的一个变种，使用门机制来记录当前序列的状态。在GRU中有两种类型的门（gate）: reset gate和update gate。这两个门一起控制来决定当前状态有多少信息要更新。 reset gate是用于决定多少过去的信息被用于生成候选状态，如果Rt为0，表明忘记之前的所有状态：$$r_t = \\sigma(W_rx_r+U_rh_{y-1}+b_r)$$根据reset gate的分数可以计算出候选状态：$$\\hat{h_t} = tanh(W_hx_t+r_t\\oplus(U_hh_{t-1}+b_h))$$update gate是用来决定由多少过去的信息被保留，以及多少新信息被加进来：$$z_t = \\sigma(W_zx_r+U_zh_{t-1}+b_z)$$最后，隐藏层状态的计算公式，有update gate、候选状态和之前的状态共同决定：$$h_t = (1-z_t)\\oplus h_{t-1}+z_t \\oplus \\hat{h_t}$$ Attention原理 1、word encoder layer首先，将每个segment中的character做embedding转换成向量（这里使用one-hot），然后输入到双向GRU网络中，结合上下文的信息，获得该character对应的隐藏状态输出$h_{it}=[\\overrightarrow{h_{it}}, \\overleftarrow{h_{it}}]$$$x_{it} = W_cw_{it}, t \\in [i,T]$$ $$\\overrightarrow{h_{it}} = \\overrightarrow{GRU}(x_{it})$$ $$\\overleftarrow{h_{it}} = \\overleftarrow{GRU}(x_{it})$$ 2、word attention layerattention机制的目的就是要把一个segment中，对segment表达最重要的character找出来，赋予一个更大的比重。 首先将word encoder那一步的输出得到的$h_{it}$输入到一个单层的感知机中得到结果$u_{it}$作为其隐含表示$$u_{it} = tanh(W_wh_{it}+b_w)$$接着为了衡量character的重要性，定义了一个随机初始化的character层面上下文向量$u_w$，计算其与segment中每个charater的相似度，然后经过一个softmax操作获得了一个归一化的attention权重矩阵$\\alpha_{it}$，代表segement i中第t个charater的权重： $$\\alpha_{it} = \\frac {exp(u_{it}^Tu_w)}{\\sum_t(exp(u_{it}^Tu_w))}$$于是，segment的向量$s_i$就可以看做是segment中character的向量的加权求和。这里的character层面上下文向量是$u_w$随机初始化并且可以在训练的过程中学习得到的。$$s_i = \\sum_{t} \\alpha_{it}h_{it}$$ 3、sentence encoder通过上述步骤我们得到了每个segment的向量表示，然后可以用相似的方法得到datagram向量$h_{i}=[\\overrightarrow{h_{i}}, \\overleftarrow{h_{i}}]$：$$\\overleftarrow{h_{i}} = \\overleftarrow{GRU}(s_{i}), i \\in [i,L]$$ $$\\overrightarrow{h_{i}} = \\overrightarrow{GRU}(s_{i}), i \\in [1,L]$$ 4、sentence attention 和character级别的attention类似，使用一个segment级别的上下文向量$u_s$,来衡量一个segment在datagram的重要性。$$u_{i} = tanh(W_sh_{i}+b_s)$$ $$\\alpha_i = \\frac {exp(u_i^Tu_s)}{\\sum_t(exp(u_t^Tu_s))}$$ $$d = \\sum_{t} \\alpha_{i}h_{i}$$ 5、softmax上面的$d$向量就是我们的到的最后的datagram表示，然后输入一个全连接的softmax层进行分类就ok了。 BSNN.py中包含了最重要的模型代码: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176import tensorflow as tffrom tensorflow.contrib import rnnfrom tensorflow.contrib import layersdef getSequenceLength(sequences): &quot;&quot;&quot; :param sequences: 所有的segmetn长度，[a_size,b_size,c_size,,,] :return:每个segment进行padding前的实际大小 &quot;&quot;&quot; abs_sequences = tf.abs(sequences) # after padding data, max is 0 abs_max_seq = tf.reduce_max(abs_sequences, reduction_indices=2) max_seq_sign = tf.sign(abs_max_seq) # sum is the real length real_len = tf.reduce_sum(max_seq_sign, reduction_indices=1) return tf.cast(real_len, tf.int32)class BSNN(object): def __init__(self, max_sentence_num, max_sentence_length, num_classes, vocab_size, embedding_size, learning_rate, decay_steps, decay_rate, hidden_size, l2_lambda, grad_clip, is_training=False, initializer=tf.random_normal_initializer(stddev=0.1)): self.vocab_size = vocab_size # 对应我的char数量 256 self.max_sentence_num = max_sentence_num self.max_sentence_length = max_sentence_length self.num_classes = num_classes # 分类数 3 self.embedding_size = embedding_size # 对于char的emb_size=256 论文中初始化为one-hot self.hidden_size = hidden_size self.learning_rate = learning_rate self.decay_rate = decay_rate self.decay_steps = decay_steps self.l2_lambda = l2_lambda # l2范数 self.grad_clip = grad_clip self.initializer = initializer self.global_step = tf.Variable(0, trainable=False, name='global_step') # placeholder self.input_x = tf.placeholder(tf.int32, [None, max_sentence_num, max_sentence_length], name='input_x') self.input_y = tf.placeholder(tf.int32, [None, num_classes], name='input_y') self.dropout_keep_prob = tf.placeholder(tf.float32, name='dropout_keep_prob') if not is_training: return word_embedding = self.word2vec() # 对于char表达，初始化为one-hot sen_vec = self.sen2vec(word_embedding) # 对应一个segment表达 doc_vec = self.doc2vec(sen_vec) # 对应datagram表达 self.logits = self.inference(doc_vec) self.loss_val = self.loss(self.input_y, self.logits) self.train_op = self.train() self.prediction = tf.argmax(self.logits, axis=1, name='prediction') self.pred_min = tf.reduce_min(self.prediction) self.pred_max = tf.reduce_max(self.prediction) self.pred_cnt = tf.bincount(tf.cast(self.prediction, dtype=tf.int32)) self.label_cnt = tf.bincount(tf.cast(tf.argmax(self.input_y, axis=1), dtype=tf.int32)) self.accuracy = self.accuracy(self.logits, self.input_y) def word2vec(self): with tf.name_scope('embedding'): self.embedding_mat = tf.Variable(tf.eye(self.vocab_size), name='embedding') # 构造256维度单位one-hot向量 # [batch, sen_in_doc, wrd_in_sent, embedding_size] word_embedding = tf.nn.embedding_lookup(self.embedding_mat, self.input_x) return word_embedding def BidirectionalGRUEncoder(self, inputs, name): &quot;&quot;&quot; 双向GRU编码层，将一segment中的所有character或者一个datagram中的所有segment进行编码得到一个2xhidden_size的输出向量 然后在输入inputs的shape是： input:[batch, max_time, embedding_size] output:[batch, max_time, 2*hidden_size] :return: &quot;&quot;&quot; with tf.name_scope(name), tf.variable_scope(name, reuse=tf.AUTO_REUSE): fw_gru_cell = rnn.GRUCell(self.hidden_size) bw_gru_cell = rnn.GRUCell(self.hidden_size) fw_gru_cell = rnn.DropoutWrapper(fw_gru_cell, output_keep_prob=self.dropout_keep_prob) bw_gru_cell = rnn.DropoutWrapper(bw_gru_cell, output_keep_prob=self.dropout_keep_prob) # fw_outputs和bw_outputs的size都是[batch_size, max_time, hidden_size] (fw_outputs, bw_outputs), (fw_outputs_state, bw_outputs_state) = tf.nn.bidirectional_dynamic_rnn( cell_fw=fw_gru_cell, cell_bw=bw_gru_cell, inputs=inputs, sequence_length=getSequenceLength(inputs), dtype=tf.float32 ) # outputs的shape是[batch_size, max_time, hidden_size*2] outputs = tf.concat((fw_outputs, bw_outputs), 2) return outputs def AttentionLayer(self, inputs, name): &quot;&quot;&quot; inputs是GRU层的输出 inputs: [batch, max_time, 2*hidden_size] :return: &quot;&quot;&quot; with tf.name_scope(name): context_weight = tf.Variable(tf.truncated_normal([self.hidden_size*2]), name='context_weight') # 使用单层MLP对GRU的输出进行编码，得到隐藏层表示 # uit =tanh(Wwhit + bw) fc = layers.fully_connected(inputs, self.hidden_size*2, activation_fn=tf.nn.tanh) multiply = tf.multiply(fc, context_weight) reduce_sum = tf.reduce_sum(multiply, axis=2, keep_dims=True) # shape: [batch_size, max_time, 1] alpha = tf.nn.softmax(reduce_sum, dim=1) # shape: [batch_size, hidden_size*2] atten_output = tf.reduce_sum(tf.multiply(inputs, alpha), axis=1) return atten_output def sen2vec(self, word_embeded): with tf.name_scope('sen2vec'): &quot;&quot;&quot; GRU的输入tensor是[batch_size, max_time,...]，在构造segment向量时max_time应该是每个segment的长度， 所以这里将batch_size*sen_in_doc当做是batch_size，这样一来，每个GRU的cell处理的都是一个character的向量 并最终将一segment中的所有character的向量融合（Attention）在一起形成segment向量 &quot;&quot;&quot; # shape：[batch_size * sen_in_doc, word_in_sent, embedding_size] word_embeded = tf.reshape(word_embeded, [-1, self.max_sentence_length, self.embedding_size]) # shape: [batch_size * sen_in_doc, word_in_sent, hiddeng_size * 2] word_encoder = self.BidirectionalGRUEncoder(word_embeded, name='word_encoder') # shape: [batch_size * sen_in_doc, hidden_size * 2] sen_vec = self.AttentionLayer(word_encoder, name='word_attention') return sen_vec def doc2vec(self, sen_vec): with tf.name_scope('doc2vec'): &quot;&quot;&quot; 跟sen2vec类似，不过这里每个cell处理的是一个segment的向量，最后融合成为datagram的向量 &quot;&quot;&quot; sen_vec = tf.reshape(sen_vec, [-1, self.max_sentence_num, self.hidden_size*2]) # shape: [batch_size，sen_in_doc, hidden_size * 2] doc_encoder = self.BidirectionalGRUEncoder(sen_vec, name='doc_encoder') # shape: [batch_size，hidden_size * 2] doc_vec = self.AttentionLayer(doc_encoder, name='doc_vec') return doc_vec def inference(self, doc_vec): with tf.name_scope('logits'): fc_out = layers.fully_connected(doc_vec, self.num_classes) return fc_out def accuracy(self, logits, input_y): with tf.name_scope('accuracy'): predict = tf.argmax(logits, axis=1, name='predict') label = tf.argmax(input_y, axis=1, name='label') acc = tf.reduce_mean(tf.cast(tf.equal(predict, label), tf.float32)) return acc def loss(self, input_y, logits): with tf.name_scope('loss'): losses = tf.nn.softmax_cross_entropy_with_logits(labels=input_y, logits=logits) loss = tf.reduce_mean(losses) if self.l2_lambda &gt;0: l2_loss = tf.add_n([tf.nn.l2_loss(cand_var) for cand_var in tf.trainable_variables() if 'bia' not in cand_var.name]) loss += self.l2_lambda * l2_loss return loss def train(self): learning_rate = tf.train.exponential_decay(self.learning_rate, self.global_step, self.decay_steps, self.decay_rate, staircase=True) # use grad_clip to hand exploding or vanishing gradients optimizer = tf.train.AdamOptimizer(learning_rate) grads_and_vars = optimizer.compute_gradients(self.loss_val) for idx, (grad, var) in enumerate(grads_and_vars): if grad is not None: grads_and_vars[idx] = (tf.clip_by_norm(grad, self.grad_clip), var) train_op = optimizer.apply_gradients(grads_and_vars, global_step=self.global_step) return train_op 训练参数训练参数的设定可以看下面代码中configuration的内容，这里说一下论文中提到的几个参数，$\\gamma = 1$，$\\alpha$均等，segment长度设定为8，batch_size为30（与原文一致），epoch=10。 train.py 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110import tensorflow as tfimport timeimport osimport datetimefrom BSNN import BSNNfrom DataUtil import read_dataset#configurationtf.flags.DEFINE_float(&quot;learning_rate&quot;,0.001,&quot;learning rate&quot;)tf.flags.DEFINE_integer(&quot;num_epochs&quot;,10,&quot;embedding size&quot;)tf.flags.DEFINE_integer(&quot;batch_size&quot;, 30, &quot;Batch size for training/evaluating.&quot;) #批处理的大小 32--&gt;128tf.flags.DEFINE_integer(&quot;num_classes&quot;, 3, &quot;number of classes&quot;)tf.flags.DEFINE_integer(&quot;vocab_size&quot;, 256, &quot;vocabulary size&quot;)tf.flags.DEFINE_integer(&quot;decay_steps&quot;, 12000, &quot;how many steps before decay learning rate.&quot;)tf.flags.DEFINE_float(&quot;decay_rate&quot;, 0.9, &quot;Rate of decay for learning rate.&quot;) #0.5一次衰减多少tf.flags.DEFINE_string(&quot;ckpt_dir&quot;,&quot;text_han_checkpoint/&quot;,&quot;checkpoint location for the model&quot;)tf.flags.DEFINE_integer('num_checkpoints',5,'save checkpoints count') tf.flags.DEFINE_integer('max_sentence_num',100,'max sentence num in a doc')tf.flags.DEFINE_integer('max_sentence_length',8,'max word count in a sentence')tf.flags.DEFINE_integer(&quot;embedding_size&quot;,256,&quot;embedding size&quot;)tf.flags.DEFINE_integer('hidden_size',50,'cell output size')tf.flags.DEFINE_boolean(&quot;is_training&quot;,True,&quot;is traning.true:tranining,false:testing/inference&quot;)tf.flags.DEFINE_integer(&quot;validate_every&quot;, 100, &quot;Validate every validate_every epochs.&quot;) #每10轮做一次验证tf.flags.DEFINE_float('validation_percentage',0.1,'validat data percentage in train data')tf.flags.DEFINE_float(&quot;dropout_keep_prob&quot;, 0.5, &quot;Dropout keep probability (default: 0.5)&quot;)tf.flags.DEFINE_float(&quot;l2_reg_lambda&quot;, 0.0001, &quot;L2 regularization lambda (default: 0.0)&quot;)tf.flags.DEFINE_float('grad_clip',2.0,'grad_clip') # 和类别数相关tf.flags.DEFINE_boolean(&quot;allow_soft_placement&quot;, True, &quot;Allow device soft device placement&quot;)tf.flags.DEFINE_boolean(&quot;log_device_placement&quot;, False, &quot;Log placement of ops on devices&quot;)FLAGS = tf.flags.FLAGS# load datasettrain_x, train_y, dev_x, dev_y = read_dataset()print (&quot;data load finished&quot;)with tf.Graph().as_default(): sess_conf = tf.ConfigProto( allow_soft_placement=FLAGS.allow_soft_placement, log_device_placement=FLAGS.log_device_placement) sess = tf.Session(config=sess_conf) with sess.as_default(): timestamp = str(int(time.time())) out_dir = os.path.abspath(os.path.join(os.path.curdir, 'run_BSNN', timestamp)) if not os.path.exists(out_dir): os.makedirs(out_dir) checkpoint_dir = os.path.abspath(os.path.join(out_dir, FLAGS.ckpt_dir)) if not os.path.exists(checkpoint_dir): os.makedirs(checkpoint_dir) checkpoint_prefix = os.path.join(checkpoint_dir, 'model') bsnn = BSNN(FLAGS.max_sentence_num, FLAGS.max_sentence_length, FLAGS.num_classes, FLAGS.vocab_size, FLAGS.embedding_size, FLAGS.learning_rate, FLAGS.decay_steps, FLAGS.decay_rate, FLAGS.hidden_size, FLAGS.l2_reg_lambda, FLAGS.grad_clip, FLAGS.is_training) saver = tf.train.Saver(tf.global_variables(), max_to_keep=FLAGS.num_checkpoints) sess.run(tf.global_variables_initializer()) def train_step(x_batch, y_batch): feed_dict = {bsnn.input_x: x_batch, bsnn.input_y: y_batch, bsnn.dropout_keep_prob: FLAGS.dropout_keep_prob } tmp, step, loss, accuracy, label_cnt, pred_cnt, pred_min, pred_max = sess.run( [bsnn.train_op, bsnn.global_step, bsnn.loss_val, bsnn.accuracy, bsnn.label_cnt, bsnn.pred_cnt, bsnn.pred_min, bsnn.pred_max,], feed_dict=feed_dict) print('train_label_cnt: ', label_cnt) print('train_min_max:', pred_min, pred_max) print('train_cnt: ', pred_cnt) time_str = datetime.datetime.now().isoformat() print(&quot;{}:step {}, loss {:g}, acc {:g}&quot;.format(time_str, step, loss, accuracy)) return step def dev_step(dev_x, dev_y): feed_dict = {bsnn.input_x: dev_x, bsnn.input_y: dev_y, bsnn.dropout_keep_prob: 1.0 } step, loss, accuracy, label_cnt, pred_cnt = sess.run( [bsnn.global_step, bsnn.loss_val, bsnn.accuracy, bsnn.label_cnt, bsnn.pred_cnt,], feed_dict=feed_dict) time_str = datetime.datetime.now().isoformat() print(&quot;dev result: {}:step {}, loss {:g}, acc {:g}&quot;.format(time_str, step, loss, accuracy)) for epoch in range(FLAGS.num_epochs): print('current epoch %s' % (epoch + 1)) for i in range(0, 270, FLAGS.batch_size): x = train_x[i:i + FLAGS.batch_size] y = train_y[i:i + FLAGS.batch_size] train_step(x, y) cur_step = tf.train.global_step(sess, bsnn.global_step) print('\\n') dev_step(dev_x, dev_y) path = saver.save(sess, checkpoint_prefix, global_step=epoch) print('Saved model checkpoint to {}\\n'.format(path)) 结果 epoch 结果 1 loss 1.17914, acc 0.206897 2 loss 1.16526, acc 0.206897 3 loss 1.17013, acc 0.206897 4 loss 1.16233, acc 0.206897 5 loss 1.14642, acc 0.448276 6 loss 1.04893, acc 0.448276 7 loss 0.898174, acc 0.448276 8 loss 0.708184, acc 0.827586 9 loss 0.616511, acc 0.827586 10 loss 0.4711, acc 0.827586 部分输出细节见下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149current epoch 12021-02-05T23:28:26.090626:step 1, loss 1.18368, acc 0.2333332021-02-05T23:28:26.623201:step 2, loss 1.17141, acc 0.3666672021-02-05T23:28:27.112586:step 3, loss 1.17092, acc 0.22021-02-05T23:28:27.600048:step 4, loss 1.16999, acc 0.3333332021-02-05T23:28:28.092669:step 5, loss 1.16888, acc 0.42021-02-05T23:28:28.593807:step 6, loss 1.1664, acc 0.42021-02-05T23:28:29.085813:step 7, loss 1.17391, acc 0.2333332021-02-05T23:28:29.577284:step 8, loss 1.16082, acc 0.4333332021-02-05T23:28:30.078963:step 9, loss 1.17725, acc 0.3dev result: 2021-02-05T23:28:30.484341:step 9, loss 1.17914, acc 0.206897Saved model checkpoint to C:\\Users\\Garli\\Desktop\\BSNN\\run_BSNN\\1612538901\\text_han_checkpoint\\model-0current epoch 22021-02-05T23:28:31.313493:step 10, loss 1.14458, acc 0.4666672021-02-05T23:28:31.801910:step 11, loss 1.16036, acc 0.3666672021-02-05T23:28:32.340277:step 12, loss 1.20258, acc 0.22021-02-05T23:28:32.840851:step 13, loss 1.16389, acc 0.3333332021-02-05T23:28:33.345806:step 14, loss 1.14916, acc 0.42021-02-05T23:28:33.865011:step 15, loss 1.15131, acc 0.42021-02-05T23:28:34.375607:step 16, loss 1.16807, acc 0.2333332021-02-05T23:28:34.888499:step 17, loss 1.15018, acc 0.4333332021-02-05T23:28:35.416810:step 18, loss 1.16337, acc 0.3dev result: 2021-02-05T23:28:35.609295:step 18, loss 1.16526, acc 0.206897Saved model checkpoint to C:\\Users\\Garli\\Desktop\\BSNN\\run_BSNN\\1612538901\\text_han_checkpoint\\model-1current epoch 32021-02-05T23:28:36.307796:step 19, loss 1.14345, acc 0.4666672021-02-05T23:28:36.807924:step 20, loss 1.15106, acc 0.3666672021-02-05T23:28:37.413876:step 21, loss 1.18131, acc 0.22021-02-05T23:28:37.979364:step 22, loss 1.1481, acc 0.3333332021-02-05T23:28:38.528895:step 23, loss 1.13485, acc 0.42021-02-05T23:28:39.053765:step 24, loss 1.14369, acc 0.42021-02-05T23:28:39.566839:step 25, loss 1.16878, acc 0.2333332021-02-05T23:28:40.087222:step 26, loss 1.1341, acc 0.4333332021-02-05T23:28:40.603841:step 27, loss 1.1617, acc 0.3dev result: 2021-02-05T23:28:40.796326:step 27, loss 1.17013, acc 0.206897Saved model checkpoint to C:\\Users\\Garli\\Desktop\\BSNN\\run_BSNN\\1612538901\\text_han_checkpoint\\model-2current epoch 42021-02-05T23:28:41.602442:step 28, loss 1.1145, acc 0.4666672021-02-05T23:28:42.144761:step 29, loss 1.14097, acc 0.3666672021-02-05T23:28:42.693294:step 30, loss 1.20376, acc 0.22021-02-05T23:28:43.229859:step 31, loss 1.14151, acc 0.3333332021-02-05T23:28:43.755452:step 32, loss 1.12037, acc 0.42021-02-05T23:28:44.263125:step 33, loss 1.13507, acc 0.42021-02-05T23:28:44.771254:step 34, loss 1.16051, acc 0.2333332021-02-05T23:28:45.294753:step 35, loss 1.11591, acc 0.4333332021-02-05T23:28:45.826330:step 36, loss 1.14527, acc 0.3dev result: 2021-02-05T23:28:46.004852:step 36, loss 1.16233, acc 0.206897Saved model checkpoint to C:\\Users\\Garli\\Desktop\\BSNN\\run_BSNN\\1612538901\\text_han_checkpoint\\model-3current epoch 52021-02-05T23:28:46.711379:step 37, loss 1.10953, acc 0.4666672021-02-05T23:28:47.210262:step 38, loss 1.13091, acc 0.3666672021-02-05T23:28:47.773246:step 39, loss 1.18087, acc 0.22021-02-05T23:28:48.286123:step 40, loss 1.13255, acc 0.3333332021-02-05T23:28:48.789008:step 41, loss 1.11187, acc 0.42021-02-05T23:28:49.302116:step 42, loss 1.13908, acc 0.42021-02-05T23:28:49.805403:step 43, loss 1.1431, acc 0.2666672021-02-05T23:28:50.314138:step 44, loss 1.11676, acc 0.4333332021-02-05T23:28:50.827770:step 45, loss 1.12081, acc 0.366667dev result: 2021-02-05T23:28:51.000757:step 45, loss 1.14642, acc 0.448276Saved model checkpoint to C:\\Users\\Garli\\Desktop\\BSNN\\run_BSNN\\1612538901\\text_han_checkpoint\\model-4current epoch 62021-02-05T23:28:51.710229:step 46, loss 1.1051, acc 0.5666672021-02-05T23:28:52.197731:step 47, loss 1.09202, acc 0.52021-02-05T23:28:52.747259:step 48, loss 1.15978, acc 0.3333332021-02-05T23:28:53.266820:step 49, loss 1.09888, acc 0.52021-02-05T23:28:53.778483:step 50, loss 1.04828, acc 0.62021-02-05T23:28:54.300956:step 51, loss 1.10639, acc 0.52021-02-05T23:28:54.807825:step 52, loss 1.06262, acc 0.52021-02-05T23:28:55.310532:step 53, loss 1.03075, acc 0.52021-02-05T23:28:55.833391:step 54, loss 1.02559, acc 0.466667dev result: 2021-02-05T23:28:56.026642:step 54, loss 1.04893, acc 0.448276Saved model checkpoint to C:\\Users\\Garli\\Desktop\\BSNN\\run_BSNN\\1612538901\\text_han_checkpoint\\model-5current epoch 72021-02-05T23:28:56.747713:step 55, loss 0.996561, acc 0.5666672021-02-05T23:28:57.233785:step 56, loss 0.973121, acc 0.52021-02-05T23:28:57.788470:step 57, loss 1.10553, acc 0.3333332021-02-05T23:28:58.301127:step 58, loss 0.873215, acc 0.52021-02-05T23:28:58.816781:step 59, loss 0.839209, acc 0.6333332021-02-05T23:28:59.331319:step 60, loss 0.928375, acc 0.5333332021-02-05T23:28:59.847088:step 61, loss 0.837925, acc 0.52021-02-05T23:29:00.344677:step 62, loss 0.871867, acc 0.5333332021-02-05T23:29:00.813062:step 63, loss 0.89659, acc 0.5dev result: 2021-02-05T23:29:00.985665:step 63, loss 0.898174, acc 0.448276Saved model checkpoint to C:\\Users\\Garli\\Desktop\\BSNN\\run_BSNN\\1612538901\\text_han_checkpoint\\model-6current epoch 82021-02-05T23:29:01.699028:step 64, loss 0.867806, acc 0.6333332021-02-05T23:29:02.186859:step 65, loss 0.826654, acc 0.6333332021-02-05T23:29:02.737684:step 66, loss 1.01797, acc 0.4333332021-02-05T23:29:03.243936:step 67, loss 0.765, acc 0.6666672021-02-05T23:29:03.746920:step 68, loss 0.721655, acc 0.82021-02-05T23:29:04.245246:step 69, loss 0.937242, acc 0.82021-02-05T23:29:04.742633:step 70, loss 0.662761, acc 0.7666672021-02-05T23:29:05.246319:step 71, loss 0.838433, acc 0.82021-02-05T23:29:05.758371:step 72, loss 0.69352, acc 0.833333dev result: 2021-02-05T23:29:05.941858:step 72, loss 0.708184, acc 0.827586Saved model checkpoint to C:\\Users\\Garli\\Desktop\\BSNN\\run_BSNN\\1612538901\\text_han_checkpoint\\model-7current epoch 92021-02-05T23:29:06.681740:step 73, loss 0.615287, acc 0.8333332021-02-05T23:29:07.155841:step 74, loss 0.634121, acc 0.8333332021-02-05T23:29:07.706681:step 75, loss 0.863259, acc 0.72021-02-05T23:29:08.233564:step 76, loss 0.527865, acc 0.8666672021-02-05T23:29:08.728556:step 77, loss 0.626868, acc 0.82021-02-05T23:29:09.239092:step 78, loss 0.655192, acc 0.8333332021-02-05T23:29:09.747197:step 79, loss 0.518165, acc 0.8333332021-02-05T23:29:10.261518:step 80, loss 0.557925, acc 0.8666672021-02-05T23:29:10.763176:step 81, loss 0.600361, acc 0.833333dev result: 2021-02-05T23:29:10.931726:step 81, loss 0.616511, acc 0.827586Saved model checkpoint to C:\\Users\\Garli\\Desktop\\BSNN\\run_BSNN\\1612538901\\text_han_checkpoint\\model-8current epoch 102021-02-05T23:29:11.619203:step 82, loss 0.579097, acc 0.8333332021-02-05T23:29:12.099981:step 83, loss 0.531345, acc 0.8333332021-02-05T23:29:12.636098:step 84, loss 0.777414, acc 0.72021-02-05T23:29:13.135171:step 85, loss 0.438025, acc 0.8666672021-02-05T23:29:13.644192:step 86, loss 0.477813, acc 0.8333332021-02-05T23:29:14.140262:step 87, loss 0.545707, acc 0.8333332021-02-05T23:29:14.631534:step 88, loss 0.440086, acc 0.8333332021-02-05T23:29:15.129455:step 89, loss 0.427449, acc 0.8666672021-02-05T23:29:15.646563:step 90, loss 0.474299, acc 0.833333dev result: 2021-02-05T23:29:15.826884:step 90, loss 0.4711, acc 0.827586Saved model checkpoint to C:\\Users\\Garli\\Desktop\\BSNN\\run_BSNN\\1612538901\\text_han_checkpoint\\model-9 不足 数据集收集时间比较仓促，因此样本不够满意，数据量由于电脑性能限制也比较少 Focal Loss针对我的数据特点使用$\\alpha=[[1],[1],[1]],\\gamma=1$等同于softmax_cross_entropy_with_logits，效果不错，但没有做详尽的对比实验较难看出它的优势 embedding的维度设置的256，但感觉数据表示比较稀疏 对于character的这一层的训练，我的直觉上来说是远不如单词训练之于句子的意义性，因为相同的byte可能不具有很强的关联性，如果直接将segment的数字表示作为输入，减少一层不知道效果是否会退化很多 参考链接https://ieeexplore.ieee.org/abstract/document/8624128 https://www.aclweb.org/anthology/N16-1174.pdf https://zihuaweng.github.io/2018/04/01/loss/ https://zhuanlan.zhihu.com/p/80594704 https://zhuanlan.zhihu.com/p/35571412","link":"/2021/02/05/BSNN/"}],"tags":[{"name":"git","slug":"git","link":"/tags/git/"},{"name":"docker","slug":"docker","link":"/tags/docker/"},{"name":"k8s","slug":"k8s","link":"/tags/k8s/"},{"name":"Hadoop","slug":"Hadoop","link":"/tags/Hadoop/"},{"name":"Spark","slug":"Spark","link":"/tags/Spark/"},{"name":"IceBerg","slug":"IceBerg","link":"/tags/IceBerg/"},{"name":"假设检验","slug":"假设检验","link":"/tags/%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C/"},{"name":"概率论","slug":"概率论","link":"/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/"},{"name":"动态规划","slug":"动态规划","link":"/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"},{"name":"ML","slug":"ML","link":"/tags/ML/"},{"name":"决策树","slug":"决策树","link":"/tags/%E5%86%B3%E7%AD%96%E6%A0%91/"},{"name":"图","slug":"图","link":"/tags/%E5%9B%BE/"},{"name":"算法","slug":"算法","link":"/tags/%E7%AE%97%E6%B3%95/"},{"name":"密码学","slug":"密码学","link":"/tags/%E5%AF%86%E7%A0%81%E5%AD%A6/"},{"name":"网络安全","slug":"网络安全","link":"/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"},{"name":"SVM","slug":"SVM","link":"/tags/SVM/"},{"name":"NN","slug":"NN","link":"/tags/NN/"},{"name":"线性模型","slug":"线性模型","link":"/tags/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/"},{"name":"集成学习","slug":"集成学习","link":"/tags/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/"},{"name":"贝叶斯","slug":"贝叶斯","link":"/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF/"}],"categories":[{"name":"开发","slug":"开发","link":"/categories/%E5%BC%80%E5%8F%91/"},{"name":"论文","slug":"论文","link":"/categories/%E8%AE%BA%E6%96%87/"},{"name":"Spring boot框架","slug":"开发/Spring-boot框架","link":"/categories/%E5%BC%80%E5%8F%91/Spring-boot%E6%A1%86%E6%9E%B6/"},{"name":"大数据","slug":"开发/大数据","link":"/categories/%E5%BC%80%E5%8F%91/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"网络安全","slug":"论文/网络安全","link":"/categories/%E8%AE%BA%E6%96%87/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"},{"name":"区块链","slug":"开发/区块链","link":"/categories/%E5%BC%80%E5%8F%91/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"版本管理","slug":"开发/版本管理","link":"/categories/%E5%BC%80%E5%8F%91/%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86/"},{"name":"算法","slug":"算法","link":"/categories/%E7%AE%97%E6%B3%95/"},{"name":"基础学科","slug":"基础学科","link":"/categories/%E5%9F%BA%E7%A1%80%E5%AD%A6%E7%A7%91/"},{"name":"机器学习","slug":"机器学习","link":"/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"网络安全","slug":"网络安全","link":"/categories/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"},{"name":"概率论","slug":"基础学科/概率论","link":"/categories/%E5%9F%BA%E7%A1%80%E5%AD%A6%E7%A7%91/%E6%A6%82%E7%8E%87%E8%AE%BA/"},{"name":"西瓜书","slug":"机器学习/西瓜书","link":"/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%A5%BF%E7%93%9C%E4%B9%A6/"},{"name":"网络协议分类","slug":"论文/网络协议分类","link":"/categories/%E8%AE%BA%E6%96%87/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%E5%88%86%E7%B1%BB/"}]}