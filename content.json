{"pages":[],"posts":[{"title":"ETDS的代码实现","text":"这部分紧跟上一篇关于Encrypted Traffic Detection System原理的文章，进行代码的实现，目前是看学长的代码，把细节和可以效率优化的部分做好。这一版本测试出来运行时间是7s，需要更快。 github链接： 代码整体结构 项目的文件结果大致如上所示，其中data专门一个文件夹，用以存放原始数据和中间生成的各种数据，主要是npy格式文件。关于算法部分的文件如上所示，在下载完nltk库后就可以直接使用了，运行main.py文件跑出结果，显示各个环节的运行时间。这里没有去考虑系统的数据交流环节，至少没有设计在网络环境下的交换时间，那个也不是重点考虑的部分。这里只涉及了几个中间部分处理数据的时间，其余的交互环节主要是保障安全性。 nltk库的使用这是一个语料库，用来做一些基础的文本处理。在我们的代码中，我们希望是用这个库来生成我们的token。但目前我有疑惑关于这里生成的是否都长度一致。 首先是下载nltk： pip install nltk 在运行的时候报错，提示我要依次执行： 12&gt;&gt;&gt; import nltk&gt;&gt;&gt; nltk.download('punkt') 之后就可以正常使用了，具体的nltk库的其他使用可以参考官方文档：给个链接 字典树核心思想是空间换时间，利用字符串的共同前缀作为存储依据，用来节省存储空间，加速搜索时间。Trie的字符串搜索时间复杂度为$O(m)$，$m$为最长的字符串长度，其查询性能与集合中的字符串的数量无关。其在搜索字符串时表现出的高效，使得特别适用于构建文本搜索和词频统计等应用。 参考链接 字典树的性质 根节点不包含字符，除根结点外的每一个节点都仅包含一个字符； 从根节点到某一结点路径上所经过的字符连接起来，即为该节点对应的字符串； 任意节点的所有子节点所包含的字符都不相同 Trie关键词查找过程 每次从根节点开始搜索 获取关键词的第一个字符，根据该字符选择对应的子节点，转到该子节点继续检索 在相应的子节点上，获取关键词的第二个字符，进一步选择对应的子节点进行检索 以此类推，进行迭代过程； 在某个节点处，关键词的所有字母已被取出，则读取附在该节点上的信息，查找完成 toolsHMAC伪随机序列的生成性能测试和可提高的部分 搜索算法是否可以更优 中间盒32行两个循环合并一下 问题 节省时间这里的代码没有包含多次使用同一模糊规则的环节 一些检验验证的时间也是忽略了么，是否能保证和前面那篇文章同样的变量控制 token的处理这里也是提前弄好的，但是实际中这里应该也会花一些时间吧 m-n那块我还没有论文对应起来 hash和fF都是用的相似的方法，它们有什么区别么？","link":"/2020/10/02/ETDS%E7%9A%84%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/"},{"title":"PrivDPI","text":"论文原链接： keywords：Network privacy; Encrypted traffic inspection; Middlebox privacy 研究的主要问题在数据传输过程中，我们通常需要一个中间件来完成对传输内容的检测（不然，有人发敏感信息我们怎么拿住他❕），在传统模式里，赋予了中间件可解密信息的权力，他们通过对解密后的明文信息进行检测发现异常流量。However，现在人们十分注重个人隐私，我们不希望在传输过程中有中间者窥探我们的信息，但同时也不能让整个流量传输毫无监管。在这样的场景下，我们需要研究出一个能对密文关键词（敏感词）做检索的系统。可以想象，我们有一下安全需求： 传输的双方不可以通过手段获取我们的关键词检测规则，否则他们可以针对检测的关键词做绕过等小聪明处理 中间件不可以获取到任何有关明文的信息 已有研究成果已有的BlindBox可以完成大多数的功能，如密文关键词检索 本论文主要贡献点 时间上通过每次会话只建立一次缩短，且关键词信息可重复使用 加密规则生成得更有效果 重点算法设计 这个图是整个系统最关键的组成部分。他们的角色分工如下：RG：规则(rule)的制订者，他来告诉MB也就是做检测工作的工具人做事儿的规矩（MB：教我做事儿？？💢）。数学表达上，它传输过去的将是一个三元组。 MB：检测工具人，执行各种机械操作。他既不能知道C和S在交换什么小秘密，也不能去揣测上级RG大哥的具体规则要求，并且要为RG大哥的规则做掩护。因此简单来说，他主要是一个比对操作，用从RG处得到的规则来审查C。 C：👦 S：👩 Notation TLS传输协议： Obfuscated rule： 整体工作流程Setup完成基本准备工作，MB从RG那里获取规则集；C和S建立会话密钥key PreprocessingMB和C&amp;&amp;S交流得以获取一系列可重复使用的模糊规则（reusable obfuscated rule），所谓模糊就是这个过程要让双方都相互看不起，即MB无法得到C和S使用的key，同时C和S无法知晓MB从RG处得到的规则 Session Rule Preparation在preprocessing阶段生成的reusable obfuscated rule是一个C/S交流过程中比较固定的参数，在它的基础上我们生成每个会话的session rule（至于为什么session rule和obfuscated rule不可以是一个，是因为我们不希望每次会话建立，每次会话密钥改变就重新走一套preprocessing的过程，很废时间），在这里可以把obfuscated rule看作是“seed🌱”。 Token EncryptionC将它要传输的数据tokenizes，生成的token在加密传输给MB Token Detection这一步主要就是由MB控制完成，他收到来自C的加密后的token，同时他手里有之前从RG里得到的rule以及在session rule preparation中得到的session rule。第一步，他先用session rule来加密他的rule(📄这里的rule定义有点多，要注意区分)，然后就是比对的工作了 Token Validation这个工作仅当C/S中有一个是坏人的时候实施。方法是验证他们的token（这我还没理解清楚） Setup在setup过程中，我们规定了如下内容： 在RG中有很多rule，对于他的rule集合，我们取${r_i \\in R}$（这里$R$是rule domain），对于每一个$r_i$，RG选择一个随机的$\\alpha \\in Z_p$，以及随机的$s_i \\in Z_p$（这些随机的数字会方便之后来构造规则的保密性）。在前面选取的随机数基础上，我们计算出$A=g^a$，$R_i=g^{\\alpha \\cdot r_i+s_i}$，同时为了认证RG的身份，需要计算出$signs (R_i)$，最终RG把三元组$(s_i, R_i, signs(R_i))$发送给MB。 因为我们设计的是一个非对称密钥体系，所以需要设置公钥和私钥。公钥就是$A$，私钥则是CS握手建立TLS连接时产生的伪随机数，之后以这个伪随机数为源，生成以下三个keys： $k_{rand}$：作为生成之后的randomness的”seed🌱”，并且由于CS拥有的同样的$k_{rand}$，因此之后生成的随机序列也应当是一样的 $k$：用来生成reusable obfuscated rules，以及随后的session rules，且$k \\in Z_p$ $k_{TLS}$：用来加密TLS传输的流量 Preprocessing Protocol 这一步需要在第一次TLS session建立完成后立马执行，目的在于建立一系列快速、可重复使用的obfuscated rule。 这个可重复使用的rule就是： ​ $$I_i=g^{k \\cdot \\alpha \\cdot r_i +k^2}$$ 在最简单情况中，这个$I_i$是通过MB与C的交流形成的， MB计算$R_i=g^{\\alpha \\cdot r_i+s_i}$传给C，C计算出$I_i$后再传给MB 。但是我们需要基于此，做一些优化以增强安全性保护。 为了防止MB出了异心，比如自己去构造一个$R_i$，因为这里面有关键词匹配，它就可以用来解读密文信息，我们添加了一个$signs(R_i)$，利用签名防伪性（这里需要C去验证签名） 为了防止C出现异心，比如传MB一个$k_c$，自己却用别的，或者在之后的由$k_c$生成的$k_i$中出岔子，MB必须做一定的检查，在检查第一个$k_c$时，通过去比对C传的和S传的是否相等来做（要是CS都是骗子，那没办法噢）；在验证后续的$k_i$是否正确时，MB直接自己一个个算，再和C比对。上述是可用的方法之一，论文后面有提到效率更高的方式 为了防止C去窥探到rule的秘密，我们生成$R_i$的时候加入了随机数，就是这个作用 Session Rule Preparation Protocol 流程图已经很明确地表示出算法的过程，这里只需要强调一点，即为了防止暴力攻击，在一定session结束后会重新启动一次preprocessing Token Encryption Algorithm 这一步主要作用是C在操作，它需要将信息隐晦地传输给MB，而不能直接明文将关键词传输过去，因为之后MB要用session rule和它传输过来的内容做比对，因此C对文本的操作需要和MB保持一致性。 首先是一般文字$\\rightarrow$token：最直接的是把整个单词记录下来放在8byte大小的token里，改进后可以设置前缀后缀，或者语句的边界（我们可以思考更新的方式） token$\\rightarrow$加密后的token：加密方式和MB的rule的加密方式一致（之前相当于已经商量出一个共同密钥了），同样也要区分第一次还是后续的 token的可重复使用：这里使用一个记录三元组的counter table，每次遇到新的再添加，已有的话主要增加次数或者因为整体更新后（上面一块提到过重新启动的问题）去更新参数，这样可以提升效率 token防频率攻击：这里token最后会有一个hash(AES)，并且加入随机salt。salt是根据$k_{rand}$生成的，所以也不需要每次和MB同步 Token Detection Algorithm 就是最后比较的步骤，其中$ct_{r_i}$指这个rule出现的次数，初始置为0。 fast search tree 可拓展的点 在获取token时加入机器学习的算法 使用区块链分布式算法","link":"/2020/09/24/PrivDPI/"},{"title":"Spring boot的第一个简单应用","text":"​ 计网实验的时候需要自己写网页来抓包，我本来也想了解一下spring boot架构，之前用过beego，但时间有限，就直接抓起来弄，没有系统地去看，粗制滥造了一个，但是有些遇到的问题和感受还是想记录下来，之后去学这个框架的时候，也可回过头看看。 ​ 目前实现了几个页面，部署在服务器，没有用数据库，就是展示页面，然后设置了一些http缓存，安全验证的东西。 创建spring boot项目直接上官网或者idea里弄，需要支持spring web和spring security，官网上弄得话，下载解压，用idea打开即可。没有配置maven的记得提前弄好。（补充这东西的作用，目前看可以方便写代码时的智能补充+package） 打开后可以先添加为maven project，会有诸多好处。如下图所示，点击+号添加这个项目的pom.xml后，再点击package运行： （运行是点击Maven Projects框框里的小绿箭头噢） 这样一弄后有些东西用起来就舒服多啦，比如import不用去刻意写，可以直接点击错误的地方，看提示直接加进去就好，运行也不必输命令行：mvnw spring boot:run。之后肯定想测试一下，就打开上图的那个文件，这里有个main，是项目的入口，初始里面的内容和我们使用的spring security有关。 和这个含有main的文件同一路径下添加MainController.java文件（这个controller的含义可以具体去看看MVC模型是怎么回事儿的，这里不详细展开），然后将下面的内容复制进去。 123456789101112131415package com.zjn.network2;//这里根据你的名称改import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.ResponseBody;@Controllerpublic class MainController { @RequestMapping(&quot;/hello&quot;) @ResponseBody public String task1() { return &quot;Hello world!&quot;; }} 之后直接去main那里运行，没有错误的话，到浏览器localhost:端口号/hello上打开，它会跳转到login界面，用户名可以随便一点，密码在你的终端运行内容有，复制登陆进去，就可以看到打印的hello world字符。这个端口号一般默认是8080，但我部署设置后在application.properties中改动为了8800，这个不担心，看看终端输出即可。 返回html页面上面的hello例子，直接返回了字符串，但如果要返回html文档页面呢？我给出下面的例子： 12345678910111213141516171819202122232425262728293031323334package com.zjn.network2;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.ResponseBody;@Controllerpublic class MainController { @RequestMapping(&quot;/task1&quot;) @ResponseBody public String task1() { return &quot;Hello zjn 这是计网实验一的第一项&quot;; } @RequestMapping(&quot;/task2&quot;) public String task2() { return &quot;task 2&quot;; } @RequestMapping(&quot;/task3&quot;) public String task3() { return &quot;task 3&quot;; } @RequestMapping(&quot;/task4&quot;) public String task4() { return &quot;task 4&quot;; }} 还是刚刚创建的MainController文件，不过现在换成上面的内容。task1返回的是字符串，而后面几个是返回的对于名字的html文档。区别在哪里呢？看上面@的内容你就明白了，现在就要去创建这几个html文档，在下面目录中创建： 并且在application.properties中写下面内容： 1234# 定位模板的目录spring.mvc.view.prefix= /templates# 给返回的页面添加后缀名spring.mvc.view.suffix=.html 至于html的内容可以直接输入，想好看一点可以markdown直接转html，再自由一点自己去写html和css这些样式吧（作为后端的确实还弄不来…..）。弄好后，老样子去运行试试吧。 http304缓存机制https://www.jdon.com/50543这篇文章是我看到的最有用的一个，原文应该是搬运的英文的。但是在实现过程中还是做了一些修改。 文末提到的addUrlPatterns(&quot;/*&quot;)最好在我们的main中修改一下，这个很巧是在做security中自带的。 我的具体task 2代码如下： 12345678910111213141516@GetMapping(&quot;/task2&quot;) ResponseEntity&lt;String&gt; task2(WebRequest request) { ZonedDateTime expiresDate = ZonedDateTime.now().with(LocalTime.MAX); String expires = expiresDate.format(DateTimeFormatter.RFC_1123_DATE_TIME); String eTag = DigestUtils.md5DigestAsHex(expires.getBytes()); CacheControl cacheControl = CacheControl.maxAge(30, TimeUnit.MINUTES); if (request.checkNotModified(eTag)) { return null; } return ResponseEntity.ok() .eTag(eTag) .cacheControl(cacheControl) .body(&quot;task 2&quot;); } 注意到其实我舍弃了传我的html文档，因为ResponseEntity里面不是很好操作，一般需要和前端有一些交互才能做到。第二我要用LocalTime.MAX让我的时间是固定的，这样生成的etag才会一样，但其实这个值应该有真实含义，即最后一次修改时间，我这里只是达到一个出现304的需求，没有符合缓存设置的需求。其实这里看到了顺便去弄清ResponseBady和这个ResponseEntity用法区别，弄请http缓存设置是比较有益的。 部署到服务器这一篇内容真的很详实了https://blog.csdn.net/Mou_Yang/article/details/102137861我就总结一下步骤，和说一点小坑。 去阿里云等地方弄一个服务器，再找个趁手的远程连接软件，我用的xshell，用阿里云自己的倒也可以 服务器拿到手，当然得配置一些东西，其实部署上去就是让远程的另一台电脑帮你跑程序，用那个电脑的ip去访问页面，就不用在localhost了，并且日夜不息……所以你本地怎么让项目运行起来，那你就得让远程的怎么运行，不过这远程的是Linux，你不能照你本地的OS那么整，所以这个的话，其实就配个jdk就好，能跑java就行，现在还不用数据库。里面注意一点，在设置jdk环境变量的时候我总是弄不对，java -version找不到，它会提示一个命令，我后来没办法去试了一下，jdk给安好了，环境变量也没问题了……所以人家官方的错误提示还是很有用的！（可能不适用于所有人的情况） 把项目打包成jar，在服务器上运行，运行结果和本机没啥区别，再在浏览器上访问，完事儿。当然想日夜不息，添点东西就好咯，我这个简单的就没必要了 后记这个真的再简单不过，之前数据库要弄一个非常原始的java web项目都比这个要难一些，但也让我充分明白了框架真的好呀！（但全程自己写会加深对这个流程的理解），还有就是这个根本没有涉及到后端逻辑，最多熟悉一下spring boot使用哈哈哈。因为我是基本弄完以后才想着写这个，过程中的一些步骤错误可能会有点忘了，还有就是没有上几个对我帮助比较大的贴子（啊抱歉…他们还非常详细）下面的几点是我希望之后我来补充或者去学习的内容： spring boot的常用几个依赖的介绍（等我用的时候） 怎么去更好使用spring security，比如不要随机密码，不是每个页面都拦截，login页面的优化…. spring boot加入后端逻辑 有些网上图片的地址插入进来，抓包后只显示一次抓图片的过程（这大概是计网的问题… …………. github代码链接：https://github.com/Garlicisnotmyfavor/network1.git","link":"/2020/06/06/Spring-boot%E7%9A%84%E7%AC%AC%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E5%BA%94%E7%94%A8/"},{"title":"Encrypted Traffic Detection System","text":"这篇是目前老师正在做的一个，我们会参考一部分，但是内容不够完善，包括整体的书写，主体思路和PrivDPI相似，但是细节和使用的算法都有不同，文中还对系统的安全性有证明。 Notation 安全性分析的理论公式System概述依旧分为C、S、RG、MB，但是和PrivDPI在功能分配上有细小不同。 验证C/S的传输内容一致性上，PrivDPI主要是通过比较$g^k$来判断，而这篇论文是依靠验证双方的token是否相同。当不相同时，交给RG来仲裁 攻击模型C或者S不诚信但是这里即使不诚信，我们也只考虑其中一方欺骗别人，要是合起伙来欺骗，那确实…….😔 一般C有恶意的话，基本出于想要躲过MB的侦擦去发一个敏感不和规矩的词汇；如果是S有恶意，主要是去陷害C（hhhhh） MB有问题MB就算有问题，那也不是大坏人，而是honest-but-curious（他会依照规矩办事，不欺瞒任何人，但是他好奇别人在传输什么内容） RG联合MB的攻击RG也想知道别人传输的内容，但是他自己无法直接接触到，就让MB当他的眼睛👀 安全目标保证rule和传输信息的保密性，保证RG能分辨出C/S中谁是好人，并且效率要高 详细流程A. Setup密钥的生成$k_{TLS}$：只有CS手上有的，用来加密交流信息的 $k_s$：只有CS手上有的，作为随机生成函数的input的seed🌱 $k_r$和$k_h$：生成token set和rule set使用 密钥的传输和验证这里的密钥传输和验证指得是将$k_s$和$k_h$从C传到RG（中途要经过MB），第一次传输使用RG的公钥加密传过去，即$E(k_h^{‘}, k_r^{‘}){ {PK}{RG} }$ ，RG收到后解析出$k_h^{‘}$和$k_r^{‘}$。第二次用来验证收到的和传送的是否一致，使用密钥对随机数$rand_c$计算哈希值，传送$E(H(rand_c){k_h^{‘} }, H(rand_c){k_r^{‘} }){ {PK}{RG} }$，RG收到后解密出来与第一次收到的对比完成验证过程。 对TLS密钥的数字验证这一部主要避免在判断CS谁是骗子的问题上时的无据可依。首先在最开始，MB分别传输给CS一个$rand_{MB}$，然后CS分别计算$E(rand_{MB}){k{TLS} }$并传给MB，MB比较一致性，通过后把$&lt;rand_{MB},E(rand_{MB})_{k_{TLS} }&gt;$记录下来 B. Obfuscated rule Generation下图的伪代码说明得很好了 C. Randomized Token Generation 伪代码说明得比较清楚，只需要注意在验证通过后还需要去验证CS是否都诚信，具体过程间前所述。同时这里可以参考PrivDPI整一个table来记录次数 D. Token Detection E. Trafﬁc Consistency Detection这里使用S来验证C发送的明文和token是否一致，即S也用明文来生成token，对比之后就可以确认 F. Disputes Resolution当出现攻击模型中的第一种，即CS中有一个有恶意的情况时，就需要RG做一个裁判了。S将$k_{TLS}$和$E(M){k{TLS} }$传给RG，当然为了防止被别人看到可以用RG的公钥加密。然后MG把之前setup存的数字收据发给RG，他经过一波验证后，可以判断出S的真实性。既然S真实了，那么C的验证RG直接把明文解析出来手动检测有没有敏感流量就👌 安全性分析","link":"/2020/09/25/Encrypted-Traffic-Detection-System/"},{"title":"docker,k8s,虚拟机","text":"因为项目原因，使用过docker，tke（腾讯云）的k8s，平时用虚拟机也挺多，但是一直对容器，云服务这块的概念不是很深，这篇文章就是想要梳理一下这些概念，同时完成本地的一个k8s部署环境。 现在运行一个应用并不是最初课程中接触的那样：购买一个远程服务器，把远程服务器的环境配好，让服务器日夜不停地运行然后用户来访问。首先我们希望每次换一个机器跑应用时不需要重新配置哪些杂碎的东西。其次我们可能不能很好利用一整个服务器的资源，更节约的方式是按使用的资源来付费。最后，我们希望一个应用能较自动地在多个服务环境中运行，并且他们能相互协调，调整负载，调整运行状态。下面先从云计算。 云计算云计算是分布式计算、并行计算、网络存储、虚拟化、负载均衡、内容分发网络等融合的产物。 按需分配资源，如在以前的开发模式下，你需要用一整台服务器来运行调试你的应用程序，但是其实你用不了这个服务器的全部资源，这会物超所值，因此产生了云服务的模式，它是按照你使用的存储空间，耗费的计算资源来收费的，用多少给多少，而不是一台一台卖。 软硬件是分散在分布式计算机中的，而不是特定的本地计算机或者远程服务器。 公共云 Software-as-a-Service, SaaS（软件即服务）：如Gmail，以单一网络软件为主导。 Platform-as-a-Service, PaaS（平台即服务）：以平台形式提供应用开发、部署平台等系统功能。 Infrastructure-as-a-Service, IaaS（基础设施即服务）：提供顶尖的软硬件服务（感觉像拆开卖东西），如服务器、存储系统、网络硬件、虚拟化软件等。 私有云 大企业不希望将自己的信息放在公共平台上。 软件开发中，环境配置是很麻烦的，如操作系统的不统一、库的下载、组件的安装。“在我的机器可以跑了”并不意味在别人的电脑里能轻松跑一起。我们期待一个能复制打包相同环境的机制。在谈及docker之前，先简单介绍一些其他的环境解决方案。 虚拟机他可以完成在一个机器中创建你想要的运行环境，即便操作系统不同也可以，并且它不会影响你本机的各种运行。缺点在于，它模拟了底层环境，因此资源占用多；作为完整的操作系统，它需要你手动做用户登录等系统级操作；启动慢。 Linux容器（LXC）不模拟一个完整的操作系统，而是对进程进行隔离。对于容器里的进程来说，它接触到的各种资源都是虚拟的，从而实现与底层系统的隔离。相比于虚拟机，它启动快，是启动本机的一个进程；资源占用少，多个容器还可以共享资源；体积小，只包含使用到的组件。 docker属于LXC的一种封装，提供简单易用的容器使用接口。Docker将应用程序与该程序的依赖，打包在一个文件里面。运行这个文件，就会生成一个虚拟容器。 docker的用途 一次性环境：本地测试时用可以快速进入到测试的环境中。 提供弹性的云服务：Docker容器可以随开随关，适合动态扩容和缩容（还不是很懂这点）。 组建微服务架构：如果你的系统需要不同的环境的构建联合起来运行，那么使用几个不同的容器分别运行起来可以模拟微服务。 镜像(image)和容器镜像就像是面向对象中的对象，而容器像是实例。通常我们的应用程序都是基于一个现有的基础镜像，然后加入自己的特性化设置变为我们自己使用的容器环境，自己的这个新镜像也可以上传到docker hub，如果是公开的化，别人也就可以使用你的镜像啦。 docker的安全问题，命名空间 应用程序如何使用docker 写Dockerfile：用来配置image从而生成自己的image。 创建image文件：docker image build 生成容器：docker container run 与虚拟机的区别与通过Hypervisor把底层设备虚拟化的虚拟机不同，Docker直接移植于Linux内核之上，通过运行Linux进程将底层设备虚拟隔离，这样系统性能的损耗也要比虚拟机低的多，几乎可以忽略。同时，Docker应用容器的启停非常高效，可以支持大规模的分布系统的水平扩展，真正给企业开发带来福音。 docker-compose我们项目使用了这个命令，但是我现在还不是很清楚这个 docker容器的使用是很方便与集群部署的，下面主要介绍以一个集群部署工具 k8sKubernetes是一个可移植的，可扩展的开源平台，用于管理容器化的工作负载和服务。k8s集群由代表控制平面的组件和一组称为节点的机器组成。 节点k8s通过将容器放入在节点上运行的Pod中来执行你的工作负载。节点可以是一个虚拟机或者物理机器，每个节点都包含用于运行Pod所需要的服务，这些服务由控制平面管理。节点上的组件包括kubelet、容器运行时、kube-proxy。 云控制管理器之前项目在腾讯云使用k8s应当就是使用了这个概念的服务。 其中云控制器管理器中的控制器包括： 节点控制器：为服务器初始化一个Node对象；设置Node注解和标签；获取节点网络地址和主机名；检查节点状态 路由器控制器：方便集群中不同节点上的容器之间可以相互通信（可能也会为Pod网络分配IP地址） 服务控制器：基于云服务平台上，方便用户操作 Pod形象的比喻，如果说容器是豌豆的话，那pod就是豌豆荚，它包含了一个或多个容器，且这些处于一个pod中的容器共享存储，网络，以及怎样运行这些容器的声明。Pod的共享上下文包括一组Linux名字空间、控制组和可能一些其他的隔离方面，即用来隔离Docker容器的技术。 通常我们不需要自己来建Pod，而是使用如Deployment这种工作负载资源来创建Pod。 Deployment管理Pods，合理地调配工作负载，动态创建和销毁Pod。 服务将运行在一组Pods上的应用程序公开为网络服务的抽象方法。k8s为Pods提供自己的IP地址，并为一组Pod提供相同的DNS名，并且可以在它们之间进行负载均衡。 其他的一些概念sandboxHyper-Vk8s实践因为这次是本地实践，没有tke提供地控制环境，所以需要安装一些别的东西。 安装工具：https://kubernetes.io/zh/docs/tasks/tools/ 包括kubectl、minikube 其中，我没有看到具体minikube应该怎么下载，参考下面这个链接： https://developer.aliyun.com/article/221687 问题 k8s集群部署上的节点ip变化，那访问时的地址如何统一（见服务处的回答，会有相同的DNS域名） 参考链接：https://www.ruanyifeng.com/blog/2018/02/docker-tutorial.html https://kubernetes.io","link":"/2020/11/03/docker-k8s-%E8%99%9A%E6%8B%9F%E6%9C%BA/"},{"title":"fabric sdk","text":"之前确实有想要好好做这块，但是基础知识的学习有些跟不上，所以可能等有时间去关注的时候补充，目前的都很基础 关于fabric sdk的文中介绍网站：https://hyperledgercn.github.io/hyperledgerDocs/sdk-design_zh/ peer：锚节点是通道中能被所有对等节点探测、并能与之进行通信的一种对等节点。通道中的每个成员都有一个（或多个，以防单点故障）锚节点，允许属于不同成员身份的节点来发现通道中存在的其它节点。 block：在一个通道上，（区块是）一组有序交易的集合。区块往往通过密码学手段（Hash 值）连接到前导区块。 chain：chain就是block之间以hash连接为结构的交易日志。peer从order service接收交易block，并根据背书策略和并发冲突标记block上的交易是否有效，然后将该block追加到peer文件系统中的hash chain上。 chaincode：链码是一个运行在账本上的软件，它可以对资产进行编码，其中的交易指令（或者叫业务逻辑）也可以用来修改资产。 channel：通道是构建在“Fabric”网络上的私有区块链，实现了数据的隔离和保密。通道特定的账本在通道中是与所有对等节点共享的，并且交易方必须通过该通道的正确验证才能与账本进行交互。通道是由一个“配置块”来定义的。 commitment：一个通道中的每个对等节点都会验证交易的有序区块，然后将区块提交（写或追加）至该通道上账本的各个副本。对等节点也会标记每个区块中的每笔交易的状态是有效或者无效。 Concurrency Control Version Check： CCVC是保持通道中各对等节点间状态同步的一种方法。对等节点并行的执行交易，在交易提交至账本之前，对等节点会检查交易在执行期间读到的数据是否被修改。如果读取的数据在执行和提交之间被改变，就会引发CCVC冲突，该交易就会在账本中被标记为无效，而且值不会更新到状态数据库中。 configuration block：包含为系统链（排序服务）或通道定义成员和策略的配置数据。对某个通道或整个网络的配置修改（比如，成员离开或加入）都将导致生成一个新的配置区块并追加到适当的链上。这个配置区块会包含创始区块的内容加上增量。 consensus：共识是贯穿整个交易流程的广义术语，其用于产生一个对于排序的同意书和确认构成区块的交易集的正确性。 current state：ledger的current state表示其chain交易log中所有key的最新值。peer会将处理过的block中的每个交易对应的修改value提交到ledger的current state，由于current state表示channel所知的所有最新的k-v，所以current state也被称为World State。Chaincode执行交易proposal就是针对的current state。","link":"/2020/07/06/fabric-sdk/"},{"title":"git常用操作","text":"版本管理我基本都是用git，仓库github，原理部分这里不说，但给了一个廖雪峰的链接，那个很详细。这篇主要对付我这种有时候忘指令懒得查的这种人，哈哈哈，比较方便。 链接就是下面这个： https://www.liaoxuefeng.com/wiki/896043488029600/898732864121440 将本地项目挂到github去本地文件夹内依次运行: 123456git initgit add .git commit -m &quot;first commit&quot;git remote add orgin 你建立的github仓库的ssh链接(如果你仓库里已经有了文件，即便是readme.md，需要运行：git pull --rebase origin master)git push -u origin master 一般项目中会有gitignore，就是提交远程时忽视的内容，一定要注意！ tips1git fetch origin 得到所有的远程分支","link":"/2020/06/07/git%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"},{"title":"lq决赛题练习","text":"11.14就是决赛了，还是抽时间来准备一下。 三角形面积已知三角形三个顶点在直角坐标系下的坐标分别为：(2.3, 2.5)(6.4, 3.1)(5.1, 7.2) 求该三角形的面积。 注意，要提交的是一个小数形式表示的浮点数。要求精确到小数后3位，如不足3位，需要补零。 海伦公式：$$A=\\sqrt{s(s-a)(s-b)(s-c)}$$其中$s=a+b+c$ 浮点数输出格式问题&quot;%3.0f&quot; ：输出的数整数部分需要占3个字符 &quot;%6.2f&quot; ：输出的小数部分至少占2位，不足补零，整个数需要占6位，其中包括小数2位和小数点1位，也就是整数部分占3位 阅兵方阵x国要参加同盟阅兵活动。主办方要求每个加盟国派出的士兵恰好能组成 2 个方阵。x国发现弱小的 y国派出了130人的队伍，他们的士兵在行进中可以变换2种队形： 130 = 81 + 49 = 9^2 + 7^2 130 = 121 + 9 = 11^2 + 3^2 x国君很受刺激，觉得x国面积是y国的6倍，理应变出更多队形。于是他发号施令：我们要派出一支队伍，在行进中要变出 12 种队形！！！ 手下人可惨了，要忙着计算至少多少人才能组成 12 种不同的双方阵。请你利用计算机的优势来计算一下，至少需要多少士兵。 （ps: 不要失去信心，1105人就能组成4种队形了） 注意，需要提交的是一个整数，表示至少需要士兵数目，不要填写任何多余的内容。 没有什么算法技巧，要么提前处理出平方数的表，要么整一个和的数组来看多久到12。总之相对来说都比较暴力。 找假币在8枚硬币中，有1枚假币，假币外观与真币一模一样，只是重量略轻或略重一点。给你一架天平，要求最多称3次，就找出假币，并且知道它是重一些还是轻一些。下面的代码给出一个解决方案，仔细分析逻辑，填写划线位置缺少的代码。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273#include &lt;stdio.h&gt;int balance(int a, int b){ if(a&lt;b) return -1; if(a&gt;b) return 1; return 0;}void judge(char* data, int a, int b, int std){ switch(balance(data[a],data[std])){ case -1: printf(&quot;%d light\\n&quot;, a); break; case 0: printf(&quot;%d heavy\\n&quot;, b); break; case 1: printf(&quot;err!\\n&quot;, b); }}// data 中8个元素，有一个假币，或轻或重void f(char* data){ switch( ____________________________________ ){ // 填空 case -1: switch(balance(data[0]+data[4],data[3]+data[1])){ case -1: judge(data,0,3,1); break; case 0: judge(data,2,5,0); break; case 1: judge(data,1,4,0); } break; case 0: judge(data,6,7,0); break; case 1: switch(balance(data[0]+data[4],data[3]+data[1])){ case -1: judge(data,4,1,0); break; case 0: judge(data,5,2,0); break; case 1: judge(data,3,0,1); } break; } }int main(){ int n; char buf[100]; scanf(&quot;%d&quot;, &amp;n); gets(buf); int i; for(i=0; i&lt;n; i++){ gets(buf); f(buf); } return 0;} 请注意：只需要填写划线部分缺少的内容，不要抄写已有的代码或符号。 这个代码有些个问题。解题思路就是不断比较，相等的结果就认为上称的都是对的，然后在剩下的里面找不等个数来替换，是一个人算的题目。 约瑟夫环n 个人的编号是 1~n，如果他们依编号按顺时针排成一个圆圈，从编号是1的人开始顺时针报数。（报数是从1报起）当报到 k 的时候，这个人就退出游戏圈。下一个人重新从1开始报数。求最后剩下的人的编号。这就是著名的约瑟夫环问题。 本题目就是已知 n，k 的情况下，求最后剩下的人的编号。 题目的输入是一行，2个空格分开的整数n, k要求输出一个整数，表示最后剩下的人的编号。 约定：0 &lt; n,k &lt; 1百万 例如输入：10 3 程序应该输出：4 推导公式：$$f(N, M)=(f(N-1,M)+M)%N$$其中N是指有N个人，M指第M个人退出，F返回的是退出的人的编号。代码如下： 1234567891011121314151617181920#include &lt;iostream&gt;using namespace std;const int N = 1000010;int f[N];int main(){ int n, k; cin &gt;&gt; n &gt;&gt; k; f[1] = 0; for (int i = 2; i &lt;= n; i ++ ) f[i] = (f[i - 1] + k) % i; cout &lt;&lt; f[n] + 1 &lt;&lt; endl; return 0;} 自描述序列小明在研究一个序列，叫Golomb自描述序列，不妨将其记作{G(n)}。这个序列有2个很有趣的性质: 对于任意正整数n，n在整个序列中恰好出现G(n)次。 这个序列是不下降的。 以下是{G(n)}的前几项： n 1 2 3 4 5 6 7 8 9 10 11 12 13G(n) 1 2 2 3 3 4 4 4 5 5 5 6 6 给定一个整数n，你能帮小明算出G(n)的值吗？ 主要是找规律，在list中记录，但是有个问题就是100%的数据中很大，int大概10位数，那个超过了，首先存储量是个问题。但是可以弄反函数，这样G(n)是没有超过那个开销的。 123456789101112131415161718192021222324252627282930313233#include &lt;iostream&gt;using namespace std;typedef long long LL;const int N = 1000010;int g[N]; //足够大的表来记录一些东西int main(){ LL n; cin&gt;&gt;n; g[1] = 1, g[2] = 2; //初始的一些值 //这里完全在模拟打表 for(int i=2, j=2; j&lt;N; i++) { for(int k=0; k&lt;g[i] &amp;&amp; j&lt;N; k++) g[j++] = i; } LL s=0, t=0; for(int i=1; i&lt;N; i++){ s+=i*(LL)g[i]; //这里乘起来不知道要干什么 if(s&gt;=n){ s-=i*(LL)g[i]; cout &lt;&lt; t+(n-s+i-1)/i &lt;&lt;endl; break; } t += g[i]; } return 0;}","link":"/2020/11/03/lq%E5%86%B3%E8%B5%9B%E9%A2%98%E7%BB%83%E4%B9%A0/"},{"title":"leecode做题笔记","text":"这一部分没什么条理地放我的leecode算法心得 1 两数之和原题链接：https://leetcode-cn.com/problems/two-sum/ 题解链接：https://github.com/Garlicisnotmyfavor/leetcode-practice/blob/master/1.cpp（输入方式有修改） 方法一使用简单的全部遍历，复杂度是$O(n^2)$，我最开始用的就是这个办法，运行速度是384ms（C++确实比python还是快很多😂） 方法二在二层循环中，找另外一个数其实不用全部遍历，而是遍历第一个数后面的即可（这类型的简化方法在当初素数求解算法中有一点点类似） 方法三使用字典来模拟哈希求解，字典是python里的语法，在C++中，可以用数组其实也能达到相同的目的。就是类似把索引和数值的关系反一下，下标来装数值，下标对应的值装的是index。初始化的时候可以所有都放-1，用来判断是否存在这个数值。不过这个方法会空间换时间，出现浪费的空间（对于C++的话是这样，对python的字典倒不存在这个顾虑） 834 树中距离之和原题链接：https://leetcode-cn.com/problems/sum-of-distances-in-tree/ 题解链接：https://github.com/Garlicisnotmyfavor/leetcode-practice/blob/master/834.cpp 拿到这题我感觉会用一点深度/广度优先搜索的思想，感觉是有技巧的一道题，但是我确实….把这些忘完了，然后开始用数组装，暴力求解（用数组是因为我vector用的不熟呀）。暴力结果就是运行一些例子可以，但是总容易出错，不严谨，因为暴力的遍历是会忽略他的树形结构的。下面就主要介绍比较标准的算法和vector使用的一些技巧。 主要方法：树形动态规划 补充代码中的细节： 基于范围的for循环(auto是自动匹配变量类型) 123456789101112int my_array[5] = {1, 2, 3, 4, 5};// 每个数组元素乘于 2for (int &amp;x : my_array){ x *= 2; cout &lt;&lt; x &lt;&lt; endl; }// auto 类型也是 C++11 新标准中的，用来自动获取变量的类型for (auto &amp;x : my_array) { x *= 2; cout &lt;&lt; x &lt;&lt; endl; } 容器的resize()函数：用来划定容器的大小，如 12dp.resize(N, 0);graph.resize(N, {}); 2 两数相加原题链接：https://leetcode-cn.com/problems/add-two-numbers/ 题解链接：https://github.com/Garlicisnotmyfavor/leetcode-practice/blob/master/2.cpp 注意几点坑（以后我做之前一定要想清楚这题到底可以用什么办法，别再暴力了😂）。顺序的问题，按照方便的顺序是无法解读出他本来的值的，我这样弄错了，然后再逆序但是0也会出问题。第二就是有两个0相加的用例，要考虑边界情况。第三就是树的使用，这个我真的生疏了，语法的东西甚至都有点点忘记。（这道题不用将两个数分别给求出来再相加，应该直接相加） 方法一将长度较短的链表末尾补0，让两个长度相等后再一个一个元素对其相加。 获取两个链表的长度 在较短的链表末尾补零 对齐相加考虑进位 方法二不对齐补零，若链表不为空则用 sum(代表每个位的和的结果)加上，考虑进位。 141 环形链表题目链接：https://leetcode-cn.com/problems/linked-list-cycle/ 题解链接：https://github.com/Garlicisnotmyfavor/leetcode-practice/blob/master/141.cpp 解答摘取一个leecode上的作者，他的总结很到位链接：https://leetcode-cn.com/problems/linked-list-cycle/solution/yi-wen-gao-ding-chang-jian-de-lian-biao-wen-ti-h-2/ 无法高效获取长度，无法根据偏移快速访问元素，是链表的两个劣势。然而面试的时候经常碰见诸如获取倒数第k个元素，获取中间位置的元素，判断链表是否存在环，判断环的长度等和长度与位置有关的问题。这些问题都可以通过灵活运用双指针来解决。 Tips：双指针并不是固定的公式，而是一种思维方式~ 先来看”倒数第k个元素的问题”。设有两个指针 p 和 q，初始时均指向头结点。首先，先让 p 沿着 next 移动 k 次。此时，p 指向第 k+1个结点，q 指向头节点，两个指针的距离为 k 。然后，同时移动 p 和 q，直到 p 指向空，此时 q 即指向倒数第 k 个结点。 获取中间元素的问题。设有两个指针 fast 和 slow，初始时指向头节点。每次移动时，fast向后走两次，slow向后走一次，直到 fast 无法向后走两次。这使得在每轮移动之后。fast 和 slow 的距离就会增加一。设链表有 n 个元素，那么最多移动 n/2 轮。当 n 为奇数时，slow 恰好指向中间结点，当 n 为 偶数时，slow 恰好指向中间两个结点的靠前一个(可以考虑下如何使其指向后一个结点呢？)。 是否存在环的问题。如果将尾结点的 next 指针指向其他任意一个结点，那么链表就存在了一个环。 上一部分中，总结快慢指针的特性 —— 每轮移动之后两者的距离会加一。下面会继续用该特性解决环的问题。当一个链表有环时，快慢指针都会陷入环中进行无限次移动，然后变成了追及问题。想象一下在操场跑步的场景，只要一直跑下去，快的总会追上慢的。当两个指针都进入环后，每轮移动使得慢指针到快指针的距离增加一，同时快指针到慢指针的距离也减少一，只要一直移动下去，快指针总会追上慢指针。 根据上述表述得出，如果一个链表存在环，那么快慢指针必然会相遇。实现代码如下： 123456789101112131415161718class Solution {public: bool hasCycle(ListNode *head) { ListNode *slow = head; ListNode *fast = head; while(fast != nullptr) { fast = fast-&gt;next; if(fast != nullptr) { fast = fast-&gt;next; } if(fast == slow) { return true; } slow = slow-&gt;next; } return nullptr; }}; 最后一个问题，如果存在环，如何判断环的长度呢？方法是，快慢指针相遇后继续移动，直到第二次相遇。两次相遇间的移动次数即为环的长度。 3 无重复字符的最长字串字串问题感觉是个典型类问题。相关标签是：哈希表、滑动窗口、双指针。 最暴力的算法是以每个字符为开头去找一个最长的无重复字串，但时间复杂度高了。这里考虑使用滑动窗口思想，设置两个int指向窗口的头和尾。 题目链接：https://leetcode-cn.com/problems/longest-substring-without-repeating-characters/ 题解链接：https://github.com/Garlicisnotmyfavor/leetcode-practice/blob/master/3.cpp 1108 IP地址无效化题目链接：https://leetcode-cn.com/problems/defanging-an-ip-address/ 题解链接：https://github.com/Garlicisnotmyfavor/leetcode-practice/blob/master/1108.cpp 没什么难度，熟悉一下字符串的一些函数即可 16 最接近的三数之和题目链接：https://leetcode-cn.com/problems/3sum-closest/ 题解链接：https://github.com/Garlicisnotmyfavor/leetcode-practice/blob/master/16.cpp 最暴力的就是$O(n^3)$，想要优化时间复杂度，先对数组进行排序，之后固定一个值，对另外两个值使用双指针，有针对性地调节一端的值，能将时间复杂度降到$O(n^2)$ 910 最小差值题目链接：https://leetcode-cn.com/problems/smallest-range-ii/ 题解链接：https://github.com/Garlicisnotmyfavor/leetcode-practice/blob/master/910.cpp 贪心，主要靠数学推理和直觉，重点在于想到要以某个点，大的全减，小的全加 104 二叉树的最大深度题目链接：https://leetcode-cn.com/problems/maximum-depth-of-binary-tree/ 题解链接：https://github.com/Garlicisnotmyfavor/leetcode-practice/blob/master/104.cpp 二叉树的基础问题注意分左右去递归处理 142 环形列表2题目链接：https://leetcode-cn.com/problems/linked-list-cycle-ii/ 题解链接：https://github.com/Garlicisnotmyfavor/leetcode-practice/blob/master/142.cpp 沿袭141的基础做法，计算环的长度，再移动得到切入节点地址，综合应用了双指针的知识 795 区间子数组个数题目链接：https://leetcode-cn.com/problems/number-of-subarrays-with-bounded-maximum/ 题解链接：https://github.com/Garlicisnotmyfavor/leetcode-practice/blob/master/795.cpp 我的方法有做出来，但是相对比较复杂，相当于按照其测试用例改出来的。但看来官方解答，这题确实比较数学。 144 二叉树的前序遍历题目链接：https://leetcode-cn.com/problems/binary-tree-preorder-traversal/题解链接：https://github.com/Garlicisnotmyfavor/leetcode-practice/blob/master/144.cpp 简单的递归，我这里没有考虑使用迭代 612 任务调度器题目链接：https://leetcode-cn.com/problems/task-scheduler/ 解题链接：https://github.com/Garlicisnotmyfavor/leetcode-practice/blob/master/621.cpp 主要靠数学思维 416 分割等和子集题目链接：https://leetcode-cn.com/problems/partition-equal-subset-sum/ 解题链接：https://github.com/Garlicisnotmyfavor/leetcode-practice/blob/master/416.cpp 0-1背包问题 1365 有多少小于当前数字的数字题目链接：https://leetcode-cn.com/problems/how-many-numbers-are-smaller-than-the-current-number/题解链接：https://github.com/Garlicisnotmyfavor/leetcode-practice/blob/master/1365.cpp 计数排序 530 二叉搜索树的最小绝对差题目链接：https://leetcode-cn.com/problems/minimum-absolute-difference-in-bst/ 一个知识点（但我当时做的时候还没有掌握），就是二叉搜索树的中序遍历数值是排好序了的。 546 移动盒子题目链接：https://leetcode-cn.com/problems/remove-boxes/ 动态规划，深度优先搜索，我还是没有掌握解这题的诀窍。 24 两两交换链表中的节点题目链接：https://leetcode-cn.com/problems/swap-nodes-in-pairs/ 使用递归的方法，比较简单好想 840 矩阵中的幻方https://leetcode-cn.com/problems/magic-squares-in-grid/ 暴力算法，加一点数学推导的规律 快慢指针/反转列表1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950class Solution {public: bool isPalindrome(ListNode* head) { if (head == nullptr) { return true; } // 找到前半部分链表的尾节点并反转后半部分链表 ListNode* firstHalfEnd = endOfFirstHalf(head); ListNode* secondHalfStart = reverseList(firstHalfEnd-&gt;next); // 判断是否回文 ListNode* p1 = head; ListNode* p2 = secondHalfStart; bool result = true; while (result &amp;&amp; p2 != nullptr) { if (p1-&gt;val != p2-&gt;val) { result = false; } p1 = p1-&gt;next; p2 = p2-&gt;next; } // 还原链表并返回结果 firstHalfEnd-&gt;next = reverseList(secondHalfStart); return result; } ListNode* reverseList(ListNode* head) { ListNode* prev = nullptr; ListNode* curr = head; while (curr != nullptr) { ListNode* nextTemp = curr-&gt;next; curr-&gt;next = prev; prev = curr; curr = nextTemp; } return prev; } ListNode* endOfFirstHalf(ListNode* head) { ListNode* fast = head; ListNode* slow = head; while (fast-&gt;next != nullptr &amp;&amp; fast-&gt;next-&gt;next != nullptr) { fast = fast-&gt;next-&gt;next; slow = slow-&gt;next; } return slow; }};","link":"/2020/10/06/leecode%E5%81%9A%E9%A2%98%E7%AC%94%E8%AE%B0/"},{"title":"一篇博客的诞生之路","text":"——一位总是懒得更新博客的同学 ​ 其实创建博客以来，我真的很难得更新内容，因为总觉得这个过程繁琐，似乎也没什么人看。但昨天晚上突然看到几个朋友的blog，从头看到尾，打了鸡血一样，忍不住想要开始开辟我的博客之路。今天拿起，发现因为许久不写东西，连命令都忘了…….于是这一篇诞生啦！！ blog文件介绍{:height=”100px” width=”100p 我的整个文件目录如上，点进去打开git命令行，就可以执行一些基础的命令。其中博客的markdown文件在source/_posts目录下，在用了hexo new &quot;博客名&quot;后可以直接找到这个目录进行编辑。 hexo常用命令 hexo new &quot;我的第一篇博客&quot; 创建一篇新的博文 hexo clean 清除之前的缓存内容，一般在发布之前使用，会将public文件删除 hexo g 和上一条指令相反，这个是生成html内容，public文件夹也会生成 hexo s 在本地显示，运行后会给你一个地址，比如我是：localhost:4000，浏览器打开就可以看到，当然你可以改这个地址，具体可以去查查 hexo d 推到远程服务器，对我来说就是github，通常我不需要本地预览时，直接用hexo g -d 按照上面的步骤来就可以成功发一篇blog 下面这张图是命令界面显示的指令，内容比较全，细节上的使用也可以参照这个，里面大多数命令都可以使用首字母缩写，但是hexo clean不可以，因为可以看到这里有两个c开头的 左侧导航栏逻辑在开通了导航栏的设置后，需要hexo new page &quot;导航栏名称&quot;，创建后可以在source里找到对应md文件。之后每次创建新的blog时，md文件顶部有相应的需要填写的内容，注意目录栏填写的规则就好，之后会自动生成。 一些问题图片的插入 markdown插入图片时由于图片位置的原因在网络上无法显示。这里需要几个步骤：修改博客根目录中_config.yml文件的配置项post_asset_folder为true，此时new一个blog，伴随md文件生成的还有同名字的文件夹，把文中使用的图片放入这个文件夹中。 安装插件：npm install https://github.com/CodeFalling/hexo-asset-image --save这里有版本问题，这个是0.0.5版本，如果用npm install hexo-asset-image –save则是1.0.0版本，这个判断版本我是试着来的，最后我适用第一个版本 md中插入图片，但记得把绝对路径换为相对的。 图片的大小设置这件事我目前没有找到很好的解决办法，欢迎解惑！","link":"/2020/06/02/%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2%E7%9A%84%E8%AF%9E%E7%94%9F%E4%B9%8B%E8%B7%AF/"},{"title":"基于对称密码的加密流量异常检测系统","text":"综设3的选题。 网络中间设备想要完成流量异常检测通常需要获取明文，我们希望设计出一个在加密状态、保护用户隐私状态下依旧可以进行分布式数据库入侵检测的系统。 涉及的密码学技术： 对称可搜索加密算法 高安全、高效哈希函数 随机数生成器 可搜索加密算法 用户隐私等数据在网络上传播时要求是密文形式，但是如果对存储的密文数据查找时，会由于密文已改变了原索引条件从而造成一定的检索困难。可搜索加密算法就是设计出一个加密算法，使得在不解密为明文的条件下，能够在密文域实现较好的关键词搜索功能。 第一篇阅读的文献：PrivDPI: Privacy-Preserving Encrypted Traffic Inspection with Reusable Obfuscated Rules 论文笔记链接：原论文地址： 第二篇阅读文献：目前老师有一定进展的一篇","link":"/2020/09/22/%E5%9F%BA%E4%BA%8E%E5%AF%B9%E7%A7%B0%E5%AF%86%E7%A0%81%E7%9A%84%E5%8A%A0%E5%AF%86%E6%B5%81%E9%87%8F%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E7%B3%BB%E7%BB%9F/"},{"title":"动态规划","text":"动态规划，我的难点在于不知道什么时候是dp，二是转移方程我还不熟练，自己不太能写出来，最后就是代码阶段了，不过多见些题，经典的题目搞懂的话，问题应该不是很大。 514 自由之路视频游戏“辐射4”中，任务“通向自由”要求玩家到达名为“Freedom Trail Ring”的金属表盘，并使用表盘拼写特定关键词才能开门。 给定一个字符串 ring，表示刻在外环上的编码；给定另一个字符串 key，表示需要拼写的关键词。您需要算出能够拼写关键词中所有字符的最少步数。 最初，ring 的第一个字符与12:00方向对齐。您需要顺时针或逆时针旋转 ring 以使 key 的一个字符在 12:00 方向对齐，然后按下中心按钮，以此逐个拼写完 key 中的所有字符。 旋转 ring 拼出 key 字符 key[i] 的阶段中： 您可以将 ring 顺时针或逆时针旋转一个位置，计为1步。旋转的最终目的是将字符串 ring 的一个字符与 12:00 方向对齐，并且这个字符必须等于字符 key[i] 。 如果字符 key[i] 已经对齐到12:00方向，您需要按下中心按钮进行拼写，这也将算作 1 步。按完之后，您可以开始拼写 key 的下一个字符（下一阶段）, 直至完成所有拼写。 示例： 1234567输入: ring = &quot;godding&quot;, key = &quot;gd&quot;输出: 4解释:对于 key 的第一个字符 'g'，已经在正确的位置, 我们只需要1步来拼写这个字符。 对于 key 的第二个字符 'd'，我们需要逆时针旋转 ring &quot;godding&quot; 2步使它变成 &quot;ddinggo&quot;。当然, 我们还需要1步进行拼写。因此最终的输出是 4。 提示： ring 和 key 的字符串长度取值范围均为 1 至 100； 两个字符串中都只有小写字符，并且均可能存在重复字符； 字符串 key 一定可以由字符串 ring 旋转拼出。","link":"/2020/11/11/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"},{"title":"密钥交换协议实现","text":"在基础的DH密钥交换协议中，为了防止重放和中间人攻击加入了签名认证，在加密和整体算法设计上使用了SM2和SM3 库的安装： 12pip3 install -i https://pypi.douban.com/simple pycryptodome(pip3 install pycryptodome我会报错) pip3 install gmssl 服务端代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980import sysfrom socket import *from gmssl import sm2, funcfrom Crypto.Util.number import *from hashlib import sha256# A B 公私钥和IDIDA = '777'IDB = '321'p = 94313901681443578942367588303266881874224725225732200536290302381507159900682469308699917405398797416164103517997923683453556485646066908743873506178671593391576338559435459952848528080908486150955455121162744500566000141128127091521308011640679378126882461641894837342623287738615768137692674805041029879683private_key_A = '0' #fake_key true_key_is #'00edf68bdc69e6441770027c8867072dd4089bbb00b833e35636d0909ccf545545'public_key_A = 'e27ccfa5d1392615b5545159288b20a513dc188661fa5d31e2a5d9bba0094dbffb3f6945f605be0ee1f4207efb861ec9d63f8e3a24ade7c11d29d0bcc7d7e042'sm2_crypt_A = sm2.CryptSM2( public_key=public_key_A, private_key=private_key_A)private_key_B = '00B9AB0B828FF68872F21A837FC303668428DEA11DCD1B24429D0C99E24EED83D5'public_key_B = 'B9C9A6E04E9C91F7BA880429273747D7EF5DDEB0BB2FF6317EB00BEF331A83081A6994B8993F3F5D6EADDDB81872266C87C018FB4162F5AF347B483E24620207'sm2_crypt_B = sm2.CryptSM2( public_key=public_key_B, private_key=private_key_B) host = sys.argv[1]port = int(sys.argv[2]) #创建SockettcpSocket = socket(AF_INET, SOCK_STREAM) #绑定tcpSocket.bind((host, port)) #设置最大连接数，超过后排队tcpSocket.listen(5) while True: #建立连接 connect, addr = tcpSocket.accept() while True: #接收客户端发来的数据并且小于1024字节的数据 A_2 = connect.recv(1024) #如果客户端退出，则执行以下语句 if not A_2: break #转换 A_2 = str(bytes_to_long(A_2)) print(&quot;received g^a is&quot; + A_2) B = int(input(&quot;input B that you want: &quot;)) B_2 = str(pow(2,B,p)) #签名后消息发送数据给客户端 data = A_2 + B_2 + IDB data = data.encode() random_hex_str = func.random_hex(sm2_crypt_B.para_len) sign = sm2_crypt_B.sign(data, random_hex_str) B_2_sign = (B_2 + '!!!' + sign).encode() #bytes #print(&quot;A_2: &quot;+A_2+'\\n'+&quot;B_2: &quot;+B_2+'\\n'+&quot;sign: &quot;+sign+'\\n'+'!!!'+IDB) connect.send(B_2_sign) #接收用于验证为篡改的签名 B_2_sign = B_2_sign.decode() total = connect.recv(8192).decode() A_2_new = total[:total.find(&quot;###&quot;)] sign_data = total[total.find('###') + 3:] if sm2_crypt_A.verify(sign_data, (A_2 + B_2_sign + A_2_new + IDA).encode()) == False: print(&quot;sign error connection break&quot;) break #ACK 说明收到并通过验证 skey = sha256(long_to_bytes(pow(int(A_2),B,p))).hexdigest() print(&quot;success and the key is: &quot; + skey) connect.send(b&quot;ACK&quot;) break #关闭连接套接字 connect.close() #关闭套接字tcpSocket.close() 客户端代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768import sysfrom socket import *from gmssl import sm2, funcfrom Crypto.Util.number import *from hashlib import sha256#16进制的公钥和私钥IDA = '777'IDB = '321'p = 94313901681443578942367588303266881874224725225732200536290302381507159900682469308699917405398797416164103517997923683453556485646066908743873506178671593391576338559435459952848528080908486150955455121162744500566000141128127091521308011640679378126882461641894837342623287738615768137692674805041029879683private_key_A = '00edf68bdc69e6441770027c8867072dd4089bbb00b833e35636d0909ccf545545'public_key_A = 'e27ccfa5d1392615b5545159288b20a513dc188661fa5d31e2a5d9bba0094dbffb3f6945f605be0ee1f4207efb861ec9d63f8e3a24ade7c11d29d0bcc7d7e042'sm2_crypt_A = sm2.CryptSM2( public_key=public_key_A, private_key=private_key_A)private_key_B = '0' #fake_key true_key is '00B9AB0B828FF68872F21A837FC303668428DEA11DCD1B24429D0C99E24EED83D5'public_key_B = 'B9C9A6E04E9C91F7BA880429273747D7EF5DDEB0BB2FF6317EB00BEF331A83081A6994B8993F3F5D6EADDDB81872266C87C018FB4162F5AF347B483E24620207'sm2_crypt_B = sm2.CryptSM2( public_key=public_key_B, private_key=private_key_B) host = sys.argv[1]port = int(sys.argv[2])#创建SockettcpSocket = socket(AF_INET, SOCK_STREAM)#与服务端建立连接tcpSocket.connect((host, port))while True: A = int(input(&quot;input A that you want: &quot;)) A_2 = pow(2,A,p) #如果输入exit，则执行以下语句 if A == &quot;exit&quot;: break #发送数据给服务端发起请求 tcpSocket.send(long_to_bytes(A_2)) #接收服务端的签名数据并验签 B_2_sign = tcpSocket.recv(4096).decode() B_2 = B_2_sign[ : B_2_sign.find(&quot;!!!&quot;)] sign = B_2_sign[B_2_sign.find(&quot;!!!&quot;) + 3: ] #print(&quot;A_2: &quot;+str(A_2)+'\\n'+&quot;B_2: &quot;+B_2+'\\n'+&quot;sign: &quot;+sign+'\\n'+'!!!'+IDB) if sm2_crypt_B.verify(sign, (str(A_2) + B_2 + IDB).encode()) == False: print(&quot;sign error connection break&quot;) break print(&quot;received g^b is&quot; + B_2) #确认未篡改的签名 data = str(A_2) + B_2_sign + str(A_2) + IDA random_hex_str = func.random_hex(sm2_crypt_A.para_len) sign_data = sm2_crypt_A.sign(data.encode(), random_hex_str) total = (str(A_2)+ &quot;###&quot; + sign_data).encode() tcpSocket.send(total) #收到ACK ack = tcpSocket.recv(1024) if ack == b'ACK': skey = sha256(long_to_bytes(pow(int(B_2),A,p))).hexdigest() print(&quot;success and the key is: &quot; + skey) break#关闭套接字tcpSocket.close()","link":"/2020/06/28/%E5%AF%86%E9%92%A5%E4%BA%A4%E6%8D%A2%E5%8D%8F%E8%AE%AE%E5%AE%9E%E7%8E%B0/"},{"title":"怎么优化博客","text":"​ 在基础的一些功能能熟练使用后，可以添加一些有趣的东西，自定义出自己的特色。 ​ 未完待续….. 官方链接：https://github.com/iissnan/hexo-theme-next 修改字体 打开上面这个文件，enable:true，size部分填写数字即可 头像设置修改avatar的相关内容 logo设置赞赏功能 修改如图目录的reward_setting部分即可，enable:true，再在此目录的source/images里放入相关的二维码，要注意命名和你代码里的要相同 coding加快访问速度https://www.jianshu.com/p/547c2c3ff79e 这里提一个点，就是因为我是腾讯域名，在腾讯里添加coding的地址时，因为那个类型的负载超了（实际上我只有一次绑github的机会），本来不想给钱另寻它路的，结果直接在coding中添加域名解析，好像也可以，至少访问速度是快了很多呀！再多说一句，我有一个服务器的话，其实部署到服务器上也是可以的，以后可以试试，就是不知道一不一样方便。 公式问题修改公式渲染首先是基础的如何渲染公式问题，这里我没有使用latex的公式渲染 参考链接：https://www.jianshu.com/p/7ab21c7f0674 HEXO不兼容双大括号的问题这个是我有两篇论文里使用了公式后发现hexo g报错，找了一下是出现了不兼容公式中的双大括号，推荐下面这个链接： 解决办法但是它的第二种方法尝试未果，治标不治本。我目前使用的比较方便的方法是遇到双大括号中间加一个空格。 公式中的’显示问题目前我还没有找办法休整，之后更新 评论功能访问量显示文章加密访问侧边栏推荐阅读DaoVoice 在线联系被搜索引擎收录https://www.cnblogs.com/php-linux/p/8493346.html参考博客这篇，还不错，但是我的文件验证是临时的，后期需要改变一下，再就是我目前还没验证是否被收录，google的之后再弄。 设置我的站标文章归类展示","link":"/2020/06/02/%E6%80%8E%E4%B9%88%E7%BE%8E%E8%A7%82%E5%8D%9A%E5%AE%A2/"},{"title":"图","text":"之前关于算法的文章都是比较随意，这次想按照专题的方式来记录做算法题的一些体会和学习到的知识点。 这篇是图论相关。 127 单词接龙给定两个单词（beginWord 和 endWord）和一个字典，找到从 beginWord 到 endWord 的最短转换序列的长度。转换需遵循如下规则： 每次转换只能改变一个字母。 转换过程中的中间单词必须是字典中的单词。 说明: 如果不存在这样的转换序列，返回 0。 所有单词具有相同的长度。 所有单词只由小写字母组成。 字典中不存在重复的单词。 你可以假设 beginWord 和 endWord 是非空的，且二者不相同。 示例 1: 12345678输入:beginWord = &quot;hit&quot;,endWord = &quot;cog&quot;,wordList = [&quot;hot&quot;,&quot;dot&quot;,&quot;dog&quot;,&quot;lot&quot;,&quot;log&quot;,&quot;cog&quot;]输出: 5解释: 一个最短转换序列是 &quot;hit&quot; -&gt; &quot;hot&quot; -&gt; &quot;dot&quot; -&gt; &quot;dog&quot; -&gt; &quot;cog&quot;, 返回它的长度 5。 示例 2: 12345678输入:beginWord = &quot;hit&quot;endWord = &quot;cog&quot;wordList = [&quot;hot&quot;,&quot;dot&quot;,&quot;dog&quot;,&quot;lot&quot;,&quot;log&quot;]输出: 0解释: endWord &quot;cog&quot; 不在字典中，所以无法进行转换。 思路首先要意识到这道题本质上是一道广度优先搜索找最短路径的题。难点有以下几个： 如何建图 最容易的方式是建立一个邻接矩阵，然后单词两两比对，看是否能连接（无向边） 建立矩阵表示图关系，需要一个id和word的映射，使用哈希表 两两搜索比较时间耗费比较大，这里在官方答案中有比较新颖的做法，建立虚拟节点，之后细说 如何搜索 最基础的广度优先搜索 双向搜索，从beginword，endword一起搜索，直到两者重合 id和word的映射使用C++的map容器，但这里因为对顺序没什么要求，因此使用的是unordered_map，常用的map底层使用的红黑树来达到顺序存储的功能。 12345678910unordered_map&lt;string, int&gt; wordId;vector&lt;vector&lt;int&gt;&gt; edge;int nodeNum = 0;void addWord(string&amp; word) { if (!wordId.count(word)) { wordId[word] = nodeNum++; edge.emplace_back(); }} 这里用nodeNum来分配word的id，每次增加一个word时，对应它的wordid增加1。wordId.count 返回的是这个key在其中出现的次数（这里有待确认，因为次数不应该只有01么），在代码中就是判断这个word是否有出现过，如果有的话，则为这个word分配一个id，且建立这个点的可到达edge，即对应代码中的emplace_back()。 这里补充说明一下push_back() 和 emplace_back() 的区别，前者在使用时会创建一个对象且使用构造函数创建一个空间，后者仅声明，但不会有创建空间的开销。 虚拟节点建图这里虚拟节点指的是，图内节点不仅是给出的那些单词，而是也包含了它可以转换的各种形式。如”hit”，可以连接的点就是”*it”，“h*t”，“hi*”这三个，如果另外的节点可以和它相连的话，如”hot”，那必然是可以通过”h*t”这个虚拟节点间接相连的。这一个虚拟节点的思想使我们省去了判断节点是否相通的步骤，但是需要注意的就是在最后计算长度的时候需要除以二以排除虚拟节点的计算量。 12345678910111213void addEdge(string&amp; word) { addWord(word); int id1 = wordId[word]; for (char&amp; it : word) { char tmp = it; it = '*'; addWord(word); int id2 = wordId[word]; edge[id1].push_back(id2); edge[id2].push_back(id1); it = tmp; } } 代码中需要关注的是for循环的使用，这里for(char&amp; it:word) 通常来讲C++ String的遍历有三种方式： operator[]遍历 1for(int i=0; i&lt;s.size(); i++){} 迭代器遍历 正向（可读可写） 12string::iterator p = s.begin();while(p != s.end()){} 这里p是地址，因此可以修改 反向（可度不可写） 12string::reserse_iterator p = s.ebegin();while(p != s.rend()){} 新式（即这里使用的） 123for(auto e:s){}for(char e:s){}for(char&amp; e:s){} 前两种是一样的都是遍历s中的char字符，但是最后一个指定得到的是字符的地址，也就是这道题代码中使用的。 三种遍历方式参考链接 基础广度优先搜索1234567891011121314151617181920212223242526272829int ladderLength(string beginWord, string endWord, vector&lt;string&gt;&amp; wordList) { for (string&amp; word : wordList) { addEdge(word); } addEdge(beginWord); if (!wordId.count(endWord)) { return 0; } vector&lt;int&gt; dis(nodeNum, INT_MAX); int beginId = wordId[beginWord], endId = wordId[endWord]; dis[beginId] = 0; queue&lt;int&gt; que; que.push(beginId); while (!que.empty()) { int x = que.front(); que.pop(); if (x == endId) { return dis[endId] / 2 + 1; } for (int&amp; it : edge[x]) { if (dis[it] == INT_MAX) { dis[it] = dis[x] + 1; que.push(it); } } } return 0; } （懒得调缩进😂） 代码中vector&lt;int&gt; dis(nodeNum, INT_MAX) 表示声明一个nodeNum大小的vector，其中每个初始化大小为INT_MAX。因为构建的是虚拟节点图，所以在最后计算长度时dis[end]/2+1 。广度优先搜索使用队列可以很容易的实现，即每次将一个点取出，然后看他可以到达哪些点，将那些加入到队尾，然后这样依次计算下去，需要注意的是我们会用一个向量dis来更新距离。 双向广度优先搜索 单向的广度优先搜索是呈指数级别增长的，但是双向会减少搜索数量。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354int ladderLength(string beginWord, string endWord, vector&lt;string&gt;&amp; wordList) { for (string&amp; word : wordList) { addEdge(word); } addEdge(beginWord); if (!wordId.count(endWord)) { return 0; } vector&lt;int&gt; disBegin(nodeNum, INT_MAX); int beginId = wordId[beginWord]; disBegin[beginId] = 0; queue&lt;int&gt; queBegin; queBegin.push(beginId); vector&lt;int&gt; disEnd(nodeNum, INT_MAX); int endId = wordId[endWord]; disEnd[endId] = 0; queue&lt;int&gt; queEnd; queEnd.push(endId); while (!queBegin.empty() &amp;&amp; !queEnd.empty()) { int queBeginSize = queBegin.size(); for (int i = 0; i &lt; queBeginSize; ++i) { int nodeBegin = queBegin.front(); queBegin.pop(); if (disEnd[nodeBegin] != INT_MAX) { return (disBegin[nodeBegin] + disEnd[nodeBegin]) / 2 + 1; } for (int&amp; it : edge[nodeBegin]) { if (disBegin[it] == INT_MAX) { disBegin[it] = disBegin[nodeBegin] + 1; queBegin.push(it); } } } int queEndSize = queEnd.size(); for (int i = 0; i &lt; queEndSize; ++i) { int nodeEnd = queEnd.front(); queEnd.pop(); if (disBegin[nodeEnd] != INT_MAX) { return (disBegin[nodeEnd] + disEnd[nodeEnd]) / 2 + 1; } for (int&amp; it : edge[nodeEnd]) { if (disEnd[it] == INT_MAX) { disEnd[it] = disEnd[nodeEnd] + 1; queEnd.push(it); } } } } return 0; } 原理明白后双向和单向的代码是产不多的，他们的轮替顺序是一个的这一层遍历完再遍历另一个。其实我的思路里当时难处理的层数现在想来也容易，忘记用size遍历完一层罢了😭 我的思路的坑用广度优先搜索我还是想到了的，但是想要偷懒不建图，直接每层去找，但是面临层数问题的bug没有解开，还有就是最后一个要超时。并且我的算法没有考虑环，因为每次使用后我就把相应的单词放到使用结束的集合中，无法再加边了，不知道这里是否会有隐藏bug。 参考链接https://leetcode-cn.com/problems/word-ladder/solution/dan-ci-jie-long-by-leetcode-solution/","link":"/2020/11/07/%E5%9B%BE/"},{"title":"西瓜书决策树","text":"第四章，决策树 基本流程决策树处理分类问题，其学习目的就是产生一个泛化能力强，即处理未见示例能力强的决策树。算法流程如下图所示： 其中在三类情况下会return，即不继续划分： D中样本都属于一个类别，直接将这个类别作为节点类别，不需要划分 A属性集为空或者D样本在属性集中无区别，也就是D的样本无法从属性数据中看出其类别区分，因此这里直接将他们中数量最多的样本的类别作为这个节点的类别，这是利用了一个后验分布 当选取的子样本集为空时，其节点类别直接使用父节点中数量最多的样本的类别，这里利用的先验分布 对于这个算法图，不是很理解其中for循环中的内容，目前的感觉是找到一个区分度比较高的属性，根据这个属性值对大样本做一个子集划分，然后将每个子集递归拿进去继续划分（此时就可以去除掉这个属性，因为每个子集中样本的这个属性值都是相等的），写到这里，感觉我又懂了。😄 划分选择划分选择就是对应上面代码的第8行，选择最优划分属性。 信息增益增益率基尼指数剪枝处理预剪枝后剪枝连续与缺失值连续值处理缺失值处理多变量决策树习题后续扩展 碎碎念 发现我的封面图很多都裂了，那就随便找些个填上，最近来不及搞这些细节了。图书馆好冷呀，心酸…💔","link":"/2020/12/11/%E8%A5%BF%E7%93%9C%E4%B9%A6%E5%86%B3%E7%AD%96%E6%A0%91/"},{"title":"缺陷owner","text":"关于一个暑期项目的一路上的一些杂谈，后面会再整理整理，分为docker，git补充，restful，项目经验的总结 项目工具和团队管理代码管理：coding 集成部署：docker镜像 git diff利用ctags工具，解释出diff文件中的方法与变量（我现在需要diff文件的样子，才知道怎么分析），然后根据变更的行，推测变更的方法，并最终把一次commit变更的方法列表、所属的owner、日期、当前build的版本号（非必须）通过另外一个目录提供的restapi服务上传到数据库中。 gitpython包的使用：https://www.osgeo.cn/gitpython/tutorial.html ctags分析任务确立使用ctags工具，分析索引文件定位源码类/方法/全局变量。 如何定位（使用ctags工具处理diff文件？目前文件处理的样子） 需要定位什么信息：方法/全局变量 输出方式 对不同语言的灵敏度 如何用到项目中 值得注意的缺点 ctags特性参考链接：https://www.cnblogs.com/coolworld/p/5602589.html ctags类似一种可以适应不同语言的语法分析器，应该可以更针对性去找里面的指定内容。 使用ctags扫描可以生成一个tags文件，并且通过参数的设定可以去指定到对应的地方。但是这种扫描的具体范围针对不同项目的区别是比较大的，到时候给接口的话，方便么？ tags文件里针对同一个方法名的区分度似乎没有那么理想，如函数声明重载使用相同的tags其实就不可以区分，到时候会给出一大串需要选择，要区分的话，可以使用ctags -R --extra=+q，这样tags里会包含全路径名（我没有实践成功）。 ctags可以分析的语言范围，可以分析的语法范围，当然可以自定义一些东西。 ctags常用操作： 12345ctags *.c --这个为后缀的全部生成tags文件ctrl+] --跳转到光标字符tag的文件具体位置中ctrl+T --返回上一个找的tagctags --list-languages/kinds/maps --提供一些数据，支持的语言/语法/语言对应的后缀:tag tagname --在打开了tags文件时跳到对应tag指示的内容处 tags文件里的内容： 1函数名/类名+tab+所在文件名+tab+命令（使vi定位的命令）+tab+对语法元素的归类 这里根据我们的需求，可以在tags文件中做一些额外的补充，如给定全路径名，给定继承的语法关系等 Q: 怎么把ctags命令应用到代码中 ctags的实践首先在我的服务器上安装ctags: sudo apt-get install ctags 然后简单地去生成当前目录下所有的c语言文件的tags目录： 以我目前的认知来说，这样是比较容易找到各个方法的入口的，但是怎么进去我还不是很清楚。 进去的时候输入vi -t,或者在文件里面用的话，可以用tag命令 看代码遇见的一些问题 在addsupportlanguage中增加了两个语言，但可能还不够，目前ctags支持的语言如下： 123456789101112131415161718Ant Asm Asp AwkBasic BETAC C++ C# CobolDosBatchEiffel ErlangFlex FortranGoHTMLJava JavaScriptLisp LuaMake MatLabObjectiveC OCamlPascal Perl PHP PythonREXX RubyScheme Sh SLang SML SQLTcl TexVera Verilog VHDL VimYACC 如果添加语言，主要是增加正则匹配，然后就是修改一些老师提到的bugs ctags目录下的文件应该是镜像依赖 数据库数据库ER图 数据库说明文档 表Tx：存放所有使用此软件的项目id 表Project：存放一个项目的基本信息 表Member：存放一个项目的成员信息，外键为project_id 表Version：存放一个项目此次版本的基本信息，外键为project_id 表Commit：存放一个项目一个版本里的每个commit（提交），version_id、member_id为外键 表Diffmethod：存放一个commit里涉及的diffmethod，commit_id、version_id为外键 关系：都是one-many，其中Tx-Project以及Commit-Diffmethod为0,1:1,n，其余都为1,1:1,n 问题1：version表是否需要last_version_id来定位上个版本 问题2：拉去一个version的commit时，选取master分支/所有分支？需要怎样设计更合理（关系到git log命令） view设计：表的层级关系较多，建议设置一个包含[project_id, project_name, version_id, commit_id, method_id, method_name, member_id, member_name]的视图 触发器：暂时无 存储过程：暂时无 接口restful ER图什么是restful：https://www.zhihu.com/question/28557115 restapi如何开始，建议使用脚手架，安规范做，https://github.com/agconti/cookiecutter-django-rest Django REST Swagger - 生成sdk restful是一种组织web服务的架构风格，需要提前设计，其大致的ER图我猜长这样： 之前我们使用的sweagger就是接口文档，框架其实就是restful的，但是不够严格和系统，且没有提前设计。 项目集成部署容器开发与调试https://www.docker.com/products/docker-desktop https://blog.csdn.net/u013272009/article/details/79148562 win10家庭版的docker安装：https://www.jianshu.com/p/0d81c9359edf 但是遇见win的系统没办法运行文件的问题，老师给的链接如下：https://www.runoob.com/docker/docker-exec-command.html 原始代码的解读 原始代码的结构和算法 值得学习的一些处理 可以优化的部分 之后代码的构建方向 重点代码解读GitParser.py这个文件主要就是解析git到的内容，之后调试的时候看看它每一步的输出就好 关于git log的参数含义：https://git-scm.com/docs/git-log#Documentation/git-log.txt---numstat 1git log --pretty=raw --numstat 运行这个命令输出的内容如下： 其中这里的106,33分别代表增加和删除的行数 re库的内容参考：https://docs.python.org/zh-cn/3/library/re.html 如代码： 123PAT_DIFF_PART = r'''(@@\\ \\-(?P&lt;org_begin_line&gt;\\d+),(?P&lt;org_end_line&gt;\\d+)\\ \\+(?P&lt;chg_begin_line&gt;\\d+),(?P&lt;chg_end_line&gt;\\d+)\\ @@\\n)'''RE_DIFF_PART = re.compile(PAT_DIFF_PART, re.MULTILINE | re.VERBOSE) 其中compile将前面的PAT_DIFF_PART样式编译为正则表达对象，方便后面的使用，具体参数设定看文档。 如代码： 1raw_commits = RE_COMMIT.finditer(data) re.finditer(*pattern*, *string*, *flags=0*)pattern 在 string 里所有的非重复匹配，返回为一个迭代器 iterator保存了匹配对象。 关于git的一些参数rebase,merge 全图： 拉去的commit需要根据实际DAG A..B：用B以前的分支减去A及以前的分支 A..B –ancestry-path：先找到B祖先，但同时要减去不是A children的 A…B：得到AB的所有祖先，但删去他们共有的祖先 使用Django链接数据库https://blog.csdn.net/buxianghejiu/article/details/79011126 https://darkcooking.gitbooks.io/django-rest-framework-cn/content/chapter1.html 代码速度优化优化前： 121359931 function calls (1359550 primitive calls) in 4.375 secondsncalls tottime percall cumtime percall filename:lineno(function) import时导入更准确的包 re匹配时用findall，封装为对象使用 减少不必要的循环 使用二分查找 字符串处理： 123456f'{s} {t}' # Fast!s + ' ' + t' '.join((s, t))'%s %s' % (s, t)'{} {}'.format(s, t)Template('$s $t').substitute(s=s, t=t) # Slow! 优化后： 123605744 function calls (605445 primitive calls) in 2.156 seconds Ordered by: standard name","link":"/2020/07/21/%E7%BC%BA%E9%99%B7owner/"},{"title":"西瓜书模型评估与选择","text":"此为西瓜书的第二章。 经验误差与过拟合 error(误差)：学习器的实际预测输出与样本的真实输出之间的差值 training error(训练误差)：在训练集上的误差 empirical error(泛化误差)：在测试集的误差👍（我们更看重的是泛化误差） overfitting(过拟合)：学习能力过强时，会将在广样本中不具备的一些特质作为训练样本训练出的东西，这些在更广的测试集中不适用，导致泛化能力下降。过拟合问题不可避免（P≠NP） underfitting(欠拟合) 评估方法通常为了在几种模型中选择出我们期待的最好的模型，我们需要测试模型的泛化能力，一般使用测试集的数据。为了能更公证地比较，测试集的数据需要独立同分布地采样，同时尽量避免出现在训练集中，有以下方法可以使用： 留出法(hold-out)将数据集D划分为两个互斥的集合，一个作为训练集S，一个作为测试集T。需要注意： 训练/测试集的划分要尽可能保持数据分布的一致性。即如果S中正样本占50%，则T中也要使正样本比例接近50% 若S中包含大多的样本，则测试集的数据过少（甚至只有一个的话）那测出来的数据极不稳定；反之若T中样本过多也是同样的道理，会导致学习的模型不够完善。目前这个问题没有解决办法，一般的方式是2/3~4/5的样本用于训练 交叉验证法(cross validation)“p次k折交叉验证”指的是对于样本集，我们使用p中不同的划分方式，每次将样本集划分为数量相等的k份，然后每次用k-1份作为训练集训练，剩下的一份作为测试集，这样下来总过求p×k次的平均值作为结果来判断。如下图所示： 注意图中只展示了一次划分。特殊的，当k和样本的数量一致时，交叉验证法退化为留一法(Leave-One-Out)，LOO方法在数据较多时计算量过大。 自助法(bootstrapping)前面的方法在训练时因为需要拿出一部分作为测试集，因此训练样本的规模和全部样本的规模不一样，这里会产生偏差。这里的“自助法”以自助采样法(bootstrap sampling)为基础。 在数据集D中，有m个样本，现在我们想要用构造一个同样为m个样本的数据集D’，方式就是每次随机地从D中抽取一个样本放入D’中，放入后将这个样本放回去以保证下次依旧有机会再抽到。最后我们使用D’来做训练，而测试集是D-D’（即D中没有在D’中出现过的）。这里估计一下这个测试集大概的大小，即样本在m次采样中始终不被采到的概率:$$\\lim_{ m\\to \\infty } (1-\\frac 1m)^{ m } = \\frac 1e \\approx 0.368$$自助法在数据集较小、难以有效划分训练/测试集时很有用，对集成学习[1]等有很大的好处，但是其产生的数据集改变了初始数据集的分布，会引入估计偏差。 调参与最终模型调参比较苦💔，这里还提到一般我们在实际结果中的测试数据称为测试集，把训练数据划分为训练集和验证集（validation set） 性能度量衡量模型泛化能力的评价标准。 回归任务中最常用的是“均方误差”：$$E(f;\\mathcal D) = \\int_{ x \\rightarrow \\mathcal D }{ (f(x)-y)^2p(x) }, { \\rm d }x$$ 错误率与精度分类问题中常用[3]：$$E(f;\\mathcal D) = \\int_{ x \\rightarrow \\mathcal D }{ \\coprod (f(x)-y)^2p(x) }, { \\rm d }x$$ 查准率、查全率与F1根据样例真实类别和预测类别的组合可以分为以下四个：TP(真正例)，FN(假反例)，FP(假正例)，TN(真反例) 预测结果 真实情况 正例 反例 正例 TP(真正例) FN(假反例) 反例 FP(假正例) TN(真反例) 其中，查准率P:$$P=\\frac {TP}{TP+FP}$$代表的含义是在我预测为正的样例中，有多少是真的为正。查全率：$$R=\\frac {TP}{TP+FN}$$代表真正的正例有多少被预测为正例。通常来讲，这两个指标是矛盾的，一个越大，另一个越小。用P-R曲线表示如下： 如果一个学习模型的P-R曲线可以“包住”另一条，则其性能更好，图中A性能比C好，但是这里无法估测AB的性能，在这种情况下可以用查准率=查全率时候的值作为比较依据，即图中红色的虚线所交点——平衡点(BEP)。但BEP还是过于简化，在实际应用中，我们对查全率和查准率的偏好可能是不一样的，用$\\beta$代表查全率对查准率的相对重要性，则有如下指标：$$F_{\\beta} = \\frac {(1+\\beta^2)\\times P \\times R}{(\\beta^2 \\times P)+R}$$特殊的，当$\\beta$=1时，为标准的$F_1$。 当我们在分类问题中，计算了多次结果，有二分类混淆矩阵时，我们希望求得一个全局的值，有两种方式： 宏查全率/查准率/$F_1$：先计算出分别的这几个指标，再求平均值 微查全率/查准率/$F_1$：先计算值的平均，再计算指标[2] ROC与AUC一般情况下，对于分类问题，我们很可能是计算出一个介于0和1之间值，然后再给一个阈值(threshold)，通过比较结果值和阈值间的大小关系来判定分类。如果对数据结果进行排序，那么选择的这个截断点的不同会导致最后分类的查全率和查准率不同。实际上对模型能力的评估可以化为对结果排序准确度的评估，这里称作ROC(受试者工作特征)[4]。它的纵轴是“真正例率”，横轴是“假正例率”，其中纵轴的表达式和查全率一致，横轴表达式如下：$$FPR = \\frac {FP}{TN+FP}$$表达的是所有反例中错预测为正例的比率。作出ROC图如下： 比较性能除了通过曲线的“包住”关系外，还可以通过计算面积得到AUC。表达式如下：$$AUC = \\frac 12 \\sum_{i=1}^{m-1}(x_{i+1}-x_i)(y_i+y_{i+1})$$AUC是评估排序质量的值，与排序的误差紧密相关，考虑排序损失(loss)：$$\\mathcal l_{rank} = \\frac {1}{m^+m^-} \\sum_{x^+ \\in D^+} \\sum_{x^- \\in D^-} (\\coprod (f(x^+) &lt; f(x^-))+\\frac 12 \\coprod(f(x^+)=f(x^-)))$$这两个值之间的关系为：$AUC = 1-l_{rank}$ 代价敏感错误率与代价曲线在之前的计算中，将正例预测为反例和将反例预测为正例的代价是一样的，但是在实际场景中，这两种错误的代价会有偏重。因此这里设立代价矩阵，$cost_{10}$就是将第一类例子预测为第0类例子的代价。在非均等代价下，ROC曲线不能直接反映出学习器的期望总体代价[5]，而“代价曲线”(cost curve)则可以达到目的。横轴为正例概率代价：$$P(+)cost = \\frac {p \\times cost_{ 01 } }{p \\times cost_{01} + (1-p) \\times cost_{01} }$$纵轴为取值为[0,1]的归一化代价[6]：$$cost_{norm} = \\frac {FNR \\times p \\times cost_{01} + FPR \\times (1-p) \\times cost_{01} }{p \\times cost_{01} +(1-p) \\times cost_{01}}$$其中$p$为样例为正的概率，$FNR = 1-TPR$为假反例率。ROC中每一个点可以对应一条代价曲线，线段下的面积代表了该条件下的期望总体代价，如果将ROC每一个点的代价曲线都画出来，他们的下界围成的面积是在所有条件下学习器的期望总体代价，如下图所示： 比较检验主要使用统计假设检验的知识（hypothesis test），基础为概率论知识（❗这里的概率论知识多起来了，需要补充），因为我们能够得到的是测试集上的结果，但想要的其实是泛化能力，即模型总的指标，这个指标无法直接得到，但是我们可以用统计的知识给出这个指标为多少值的可行度（置信度，置信区间），这里我们就先主要考虑错误率指标$\\epsilon$ 假设检验假设检验的思想是，我对实际的错误率$\\epsilon$假设一个值的范围，如$\\epsilon \\leq \\epsilon_0$，然后需要判断是否能在置信度为$1-\\alpha$的条件下相信这个假设。具体应用里可能有二项分布，t分布等。假设检验概率论基础 交叉验证t检验对比两个学习器之间的性能差异，可以通过比较他们的错误率，如果错误率十分相似，那可以认为他们的性能是差不多的，如果不能认为相似的话，平均错误率小的更优。在具体使用时，一般每个学习器都会做k折交叉验证，我们对每次交叉验证时的一对错误率做假设检验，看他们的差值是否在一定的置信度下能够是近似为0的。即求$\\Delta_i = \\epsilon_i^A- \\epsilon_i^B$，得到$\\Delta_1,\\Delta_2,…,\\Delta_k$后，计算出均值和方差，在显著度$\\alpha$下，若变量：$$\\tau_T = |\\frac {\\sqrt k \\mu}{\\sigma}|$$小于临界值$t_{\\alpha/2,k-1}$则假设不能被拒绝。 但在实际操作时，由于k折方法在选取数据时可能存在两次之间抽取到了同样的数据，因此测试错误率并不完全独立，为了缓解这一问题，可以采用$5 \\times 2$交叉验证，即5次2折交叉验证。对于两个学习器A，B，每次会产生两对错误率，计算差值得到第一折的$\\Delta_i^1$和第二折的$\\Delta_i^2$，为了缓解测试错误率的非独立性[7]，我们对每次交叉验证计算$\\mu = 0.5(\\Delta_1^1+\\Delta_1^2)$和方差$\\sigma_i^2 = (\\Delta_i^1-\\frac {\\Delta_i^1+\\Delta_i^2}{2})^2+(\\Delta_i^2-\\frac {\\Delta_i^1+\\Delta_i^2}{2})^2$，变量：$$\\tau_t = \\frac {\\mu}{\\sqrt{0.2 \\sum_{i=1}^5\\sigma_i^2} }$$服从自由度为5的$t$分布，其双边检验的临界值$t_{\\alpha/2,5}$。 McNemar检验二分类问题中，比较学习器A和学习器B之间的关系，可以得到两者都正确，两者都错误，一个正确和一个错误的样本数，若性能相同，则一个正确一个错误的样本数$e_{01} = e_{10}$，则对于变量$|e_{01}=e_{10}|$应当服从正态分布，McNemar检验考虑变量：$$\\tau_{\\chi^2} = \\frac {(|e_{01}-e_{10}|-1)^2}{e_{10}+e_{01}}$$服从自由度为1的$\\chi^2$分布。（这里分子减1是由于他们的和很小，需要连续性校正[8]） Friedman检验与Nemenyi后续检验上面的交叉验证$t$检验和McNemar检验都是对两个学习器的性能的比较，但有时候我们需要对多个数据上多个算法的性能做比较，这时可以两两比较，但不够方便。Friedman检验是整体检验几个算法是否满足假设“所有算法性能相同”，而Nemenyi后续检验是给出两个算法性能接近的阈值，这样可以分别判断哪些算法是近似的，哪些有较大差异。 在Friedman算法中，我们首先对每个数据集上算法的表现做排名（相同名次的需要平分数值），得到下面的表格： 若算法性能相同，那么平均序值应当相等，，假设我们在N个数据集上比较k个算法，$r_i$表示第i个算法的平均序值，则变量：$$\\tau_{\\chi^2} = \\frac {k-1}{k}.\\frac {12N}{k^2-1}\\sum_{i=1}^k(r_i-\\frac {k+1}{2})^2$$在k和N都较大时，服从自由度为k-1的$\\chi^2$分布，优化后一般使用变量：$$\\tau_F = \\frac {(N-1)\\tau_{\\chi^2}}{N(k-1)-\\tau_{\\chi^2}}$$服从自由度为k-1和(k-1)(N-1)的$F$分布。 在后续Nemenyi检验中，计算这个平均序值差别的临界阈值：$$CD = q_\\alpha \\sqrt{\\frac {k(k+1)}{6N}}$$可以用下图比较直观的说明其含义，A&gt;B&gt;C，但其中AB,BC差异都不大，有重叠部分，但是AC差异大认为性能不同： 偏差与方差泛化误差可以做如下分解：$$E(f;D) = bias^2(x)+var(x)+\\varepsilon^2$$其中第一项偏差代表了模型的拟合能力，第二项方差代表了模型抗扰动的能力，第三项是噪声代表了模型的训练难度。其中偏差和方差是有冲突的： 习题习题答案参考链接 2.3 无直接联系（之前我对BEP的理解出现误区，列了个公式让查全率=查准率然后去推导出FP=FN这个结论，这个方式是不可行的，因为BEP曲线对于分类问题的阈值是变化的，而错误率是在阈值一定后计算的，两者无法相比）。 2.6 接着2.3回答，ROC曲线上的每个点可以对于一个错误率。 2.8 第一个方式容易受特殊点的影响，但计算相对简单 后续扩展[1] 集成学习 [2] 在不同场景的应用有什么不同 [3] 这里$\\coprod$表示指示函数，成立是为1，不成立为0 [4] P-R图和ROC曲线的不同：一个表明我们对查全率和查准率的倾向性（希望综合的考虑），一个是对排序性能的判断（前面相当于对应截断点的选择） [5] 均等条件下，ROC曲线可以反映出期望？ [6] 归一化的定义，同时对这个公式的理解不太透 [7] 这样为什么能缓解独立性 [8] 不是很懂连续性校正 碎碎念非自然死亡，很喜欢这部剧，因为讨论的社会问题有价值，同时我对悬疑没有抗拒力！ “有工夫绝望的话，还不如吃点好吃的去睡觉呢!”🍕 ”梦想什么的，用不着那么夸张的东西吧，有个目标就行了。目标吗?比如，发了工资要买什么，或者下次休假去哪玩，又或者为了谁而工作。“ ”世道如何，是看自己如何处世吧。“ 写完这里，又开始想中午吃什么了…..🐷","link":"/2020/12/06/%E8%A5%BF%E7%93%9C%E4%B9%A6%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%B8%8E%E9%80%89%E6%8B%A9/"},{"title":"假设检验","text":"假设检验是统计推断的重要形式，分为两类问题，一类是参数的假设检验，一类是分布的假设检验。作出假设、根据样本所提供的信息，运用统计分析的方法进行判断，从而提出是接受还是拒绝$H_0$的决定，这就是假设检验问题。 假设检验的基本概念问题的提出 我们想要知道工厂生产的零件次品率是否小于4%，但是采用的是抽样检测。这里我们得到抽样检测的结果后，作出如下假设：$H_{0}: p \\leq 0.04, H_{1}: p&gt;0.04$ 公司的包装重量规定为500g，但存在随机误差，正常情况下符合正态分布$N(500,15^2)$，某日随机抽取一定的样本得到相关数据，现在作出假设：$H_0: \\mu=500, H_1: \\mu \\neq 500$ 我们通过计算机生产随机数，现在我们得到了一系列生成的[0,1]的随机数，想要知道这个随机数生成是否是[0,1]之间的均匀分布，作出假设：$H_0: X服从U(0,1) ,H_1:X不服从U(0,1)$ 以上例子中，分别为单侧假设检验、双侧假设检验和非参数的假设检验。 假设检验的接受域和拒绝域以2为例子，推导以下这个问题的解决思路。我们想要通过抽样的数据来判断整个阶段的产品是否正常，那么因为是独立同分布抽样的，抽样出来的产品本身的分布也应当是十分接近整阶段产品的分布才能基本认为$H_0$成立。这里使用样本均值$\\bar{X}$作为总体均值的一个较好估计量，那么$P{ |\\bar{X}-\\mu| &gt; k} = \\alpha$需要成立，其中$\\alpha$为一个小概率，简单来说就是$\\bar {X}$偏离$\\mu$的距离大于$k$这个事件概率足够小。通过现有数据的计算即可判断这个式子是否成立。 假设检验的两类错误 弃真：正确的被拒绝 纳伪：错误的被接受 （这里的分类很类似分类模型中的错误情况） 参数的假设检验单个正态总体均值$\\mu$的检验$H_0$的拒绝域是$|\\bar{X} - \\mu_0|$的值大于一个界限值得区域。 总体方差$\\sigma^2$已知时$$P{ \\frac {|\\bar{X} - \\mu_0|}{\\sigma/ \\sqrt{n} } &gt; u_{\\frac a2}} = \\alpha$$拒绝域为$|u| &gt; u_{\\frac a2}$ ，这里检验方使用了服从标准正态分布得统计量，则称为U检验法。 总体方差$\\sigma^2$未知时 用标准差$S$替代$\\sigma$，$T=\\frac {|\\bar{X} - \\mu_0|}{\\sigma/ \\sqrt{n}} - t(n-1)$，$$P{ \\frac {|\\bar{X} - \\mu_0|}{\\sigma/ \\sqrt{n} } &gt; t_{\\frac a2}(n-1)} = \\alpha$$这里使用了服从$t$分布的统计量，则称为$t$检验法 单侧检验问题 $H_1: \\mu &gt; \\mu_0$：拒绝域为$u &gt; u_{\\alpha}$，$t&gt; t_{\\alpha}(n-1)$ $H_1: \\mu &lt; \\mu_0$：拒绝域为$u &lt; -u_{\\alpha}$，$t&lt;-t_{\\alpha}(n-1)$ 单个正态总体方差$\\sigma^2$的检验[1] 两个正态总体均值差$\\mu_1-\\mu_2$的检验两个正态总体方差比$\\frac {\\sigma_1^2}{\\sigma_2^2}$的检验大样本检验分布的假设检验后续扩展[1] 概率论教材P187 今天时间不够就没有整理完全 碎碎念封面图是动画《借东西的小人阿莉埃蒂》，从小到大我都梦想着有一个小人家族生活在我身旁。选了这张图是因为很喜欢这个拿着武器走向外面的背影，郁郁葱葱又暗藏危机。","link":"/2020/12/09/%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C/"},{"title":"西瓜书绪论","text":"第一章主要是引入机器学习的背景，给出基础的术语。 引言机器学习是什么？在人的认识中，通常是根据先前的经验，加上这次的现象来推测结果，如西瓜书🍉中喜欢举的例子，我们以往的经验表明色泽青绿、根蒂蜷缩、敲声浊响的一般是好瓜，借这个经验我们可以来判断当前手里的瓜好不好。但如果希望计算机也能有这个能力的话，那么经验对于的就是数据，而这个判断按过程对于的就是我们的学习模型。 基本术语 data set：数据集，即一系列的样本的数据，如（色泽=浅白；根蒂=硬挺；敲声=浊响），（色泽=乌黑；根蒂=硬挺；敲声=浊响）…. sample：样本，上面数据集中一个（）内的内容即是一个样本的数据 feature：特征，如第一个样本的特征有浅白，硬挺，浊响 feature vector：特征空间，一个样本的所有特征可以组成一个特征向量，向量所在的空间可以是特征空间 label：一个样本的结果是它的标记 supervised learning(有label) classification：分类，预测的是离散值，如“好瓜”，“坏瓜” binary classification：二分类，只有两个类别，为positive class和negative class multi-class classification：多分类 regression：回归，预测的是连续值，如结果为[0,1]的值 unsupervised learning(无label) clustering：聚类，分类标准不是事前设定的，是一个训练的结果 generalization：泛化能力，模式适用于“新样本”的能力。通常来讲我们都是从所有的数据中抽取一部分来训练，我们这里的抽取是独立同分布的，一般来说，抽取的越多我们模型的泛化能力也越强 假设空间在西瓜🍉的这个例子中，我们如果只有三个特征，即色泽，根蒂和敲声，而又假设每个特征只有三个取值空间，那么如果我们期待从已有的数据中得到“好瓜”的判断逻辑表达式的话，只需要在27个中做选取，并且这27个中可能不止一个满足我们training test中的数据，之后将考虑如何从候选的表达中选取最好的一个。 归纳偏好承接上面的问题，如何选择？任何一个有效的机器学习算法必有其归纳偏好，否则它将被假设空间中看似在训练集上“等效”的假设所迷惑。这个有一个常用的判断价值观，即“奥卡姆剃刀”：“若有多个假设与观察一致，则选最简单的那个”，在图像中可能就是更平滑的曲线。但这个理论绝不是一定的，如下图所示： 在不同的情况下，他们的优劣并不明显显示，由没有免费的午餐理论（NFL，证明这里略过，见P9）[1]，即无论学习算法聪明/笨拙，他们的期望是一样的，和随机差不多，但这里的前提是“所有”问题出现的概率是相同，实际情况中，我们只用关注于特定的问题，因此这个结论并没有那么致命。它更重要的是告诉我们，针对一个具体任务，要具体的选择解决方案 习题1.2 在我前面文章的基础上，这里就是27×26×….×（27-k+1） 1.3 关注正确的百分率，偏好是能符合更多样本的更平滑的曲线 后续扩展[1] “没有免费的午餐的证明”","link":"/2020/12/06/%E8%A5%BF%E7%93%9C%E4%B9%A6%E7%BB%AA%E8%AE%BA/"},{"title":"西瓜书线性模型","text":"进入🍉的第三章啦！之前有看过李宏毅老师的课，但是这本书看起来还是比较吃紧，冲！ 基本形式linear model是通过属性的线性组合来进行预测的函数，用向量形式表达的话就是：$$f(x) = \\omega^T x+b$$ 线性回归 最小二乘法：$$\\omega = \\frac {\\sum_{i=1}^m y_i(x_i-\\bar{x})}{\\sum_{i=1}^mx_i^2-\\frac 1m (\\sum_{i=1}^mx_i)^2}$$ $$b = \\frac 1m \\sum_{i=1}^m(y_i-\\omega x_i)$$ 多元线性回归$$\\hat \\omega^* = arg min(y-X\\hat \\omega)^T(y-X\\hat \\omega)$$其中$\\hat \\omega = (\\omega;b)$,$$X = \\begin{pmatrix} x_{11} &amp; x_{12} &amp; \\cdots &amp; x_{1d} &amp; 1\\\\ x_{21} &amp; x_{22} &amp; \\cdots &amp; x_{2d} &amp;1\\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ x_{m1} &amp; x_{m2} &amp; \\cdots &amp; x_{md} &amp;1\\\\ \\end{pmatrix}$$求导可得：$2X^T(X\\hat \\omega-y)$ 如果$X^TX$为满秩矩阵（正定矩阵）[1]则可直接求唯一解，当实际情况中$X$的列数多于行数，不是满秩，则变为求解方程组，存在多组解，需要在其中选择最合适的，常见方法是使用正则化[2] 广义线性模型：$$y = g^{-1}(\\omega^Tx+b)$$其中$g(.)$为单调可微函数，如$ln$ 对数几率回归如果需要用回归来做分类问题，最粗暴的是给一个零界点来判断（单位跃阶函数），但是他不是连续的也不可导，所以我们更普遍地使用”Sigmoid函数”，表达式为：$$y= \\frac {1}{1+e^{-z}}$$将$z$代入为$\\omega ^Tx+b$再转化形式为$ln \\frac {y}{y-1} = \\omega^Tx +b$其中$\\frac {y}{y-1}$就是几率，用线性回归模型的预测结果去逼近真实标记的对数几率，因此较多”对数几率回归”，又叫”逻辑回归“，这是一个凸函数，可以用梯度下降法或者牛顿法来求其最优解[3]，关于求最优解的过程，包括将y看作后验概率估计，用极大似然法的内容这里不赘述，详见书P59页。 线性判别分析 线性判别分析(LDA)直观上来说就是我们想要把样本投影到一条直线上，根据直线上两样本的距离来判断他们是否是相似的，因此优化目标就是：同一类的样本占据的总长度尽可能近，不同类的样本他们的中心点尽可能原，翻译成数学语言就是：$$J = \\frac {||\\omega^T\\mu_0-\\omega^T\\mu_1||_2^2}{\\omega^T\\sum_0\\omega+\\omega^T\\sum_1\\omega}$$对于两个样本要足够大，其中$\\mu_i,\\sum_i$分别代表样本的均值向量和协方差矩阵[3]，分子就是中心点距离足够大，分母就是协方差足够小。 推导最优解的过程略去(书P61)，但其从贝叶斯决策理论的角度来阐述，两类数据同先验、满足高斯分布且协方差相等时，可以达到最优解[4]。应用到多分类时，将样本投影到$d’$维空间，由于其维度小于数据原有的属性数量，且投影过程中使用了类别信息，因此也被视作典型的监督降维技术[5]。 多分类学习处理多分类问题一般是需要将其拆分为多个二分类问题，然后再集成为最终结果。 拆分方法： 一对一(OvO)：每两个分类组合，最后看每个分类被选择的次数 一对其余(OvR)：如图所示，最后看每个预测结果的置信度 多对多(MvM)：选一些做正类，一些做反类，常用的方法是”纠错输出码”(ECOC)，如下图所示： 对N分类问题做M次划分，最后看每个分类的结果组成的编码，通过计算和各类编码的距离来做分类判断。这里说它是纠错码的原因就是对错误有一定的包容度。 类别不平衡问题如果样例中的正反数量非常不一致，是很难训练出不错的效果的。通常我们判断是以0.5为界限，即$\\frac {y}{y-1} &gt;1$，但如果正反例数量不同，$m^+$和$m^-$分别代表正反例数目，则观测几率为$\\frac {m^+}{m^-}$，使用”再缩放“则可以将判断式子修正为：$$\\frac {y}{y-1} \\times \\frac {m^+}{m^-} &gt;1$$但这个方法并不简单，还有另外两种方式可以修改这个比例： 欠采样：EasyEnsemble，拆分 过采样：SMOTE，不能简单重复 习题习题答案参考链接 后续扩展[1] 正定矩阵的知识补充，我记得的是$P^TMP&gt;0$，还有其可逆，但是其他的记不得了 [2] 正则化是啥也忘记了 [3] 协方差的具体含义忘记了 [4] 这个结论和贝叶斯决策的东西都不太了解 [5] 投影后维度降了，之前直观理解中的距离概念应该是怎样的呢 碎碎念喜欢女孩和梧桐树的故事，那一段的风景","link":"/2020/12/10/%E8%A5%BF%E7%93%9C%E4%B9%A6%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/"},{"title":"计网编程","text":"后面写着写着写顺了，有时间再来补充代码吧 熟悉linux环境下的编程gcc编译1gcc -Wall hello.c -o hello 然后同时运行./server &amp; ./client 注意填写的命令行参数 开发调试工具 netstat：用来确保我们使用的端口是不被占用的，如我们要使用12345端口，可以做如下操作确保其可使用性 12netstat -anp | grep 12345如果上面有进程显示，则 kill -s 16191（写PID） tcpdump https://www.cnblogs.com/ggjucheng/archive/2012/01/14/2322659.html 常用函数地址转换函数 socket地址结构 应用实例","link":"/2020/06/07/%E8%AE%A1%E7%BD%91%E7%BC%96%E7%A8%8B/"},{"title":"基础算法复习","text":"算法方面忘得很多了，也比较长时间没有使用C/C++，这学期事情不是很多，有时间可以看看。 暴力求解判断输入是否结束：while (scanf(&quot;%d, &amp;h&quot;) != EOF) 在事先不清楚有多少数据的情况下通过 scanf 的返回值，即成功赋值的个数来达到判断的功能 日期题目闰年的判断语句：(year%4 == 0 &amp;&amp; year%100 != 0)||(year%400 == 0) 排序和查找sort函数：12#include &lt;algorithm&gt;sort(first, last, comp) 默认为升序排列，若要更灵活地实现排序，则要自己编写comp函数 1234567bool Compare(Student x, Student y){ if(x.score == y.score){ return x.number &lt; y.number }else{ return x.score &lt; y.score }} 在设计排序算法时的一个tip：当比较函数的返回值是true时，表示的是比较函数的第一个参数将会排在第二个参数前面。 对于结构体或类的自定义排序，还可以用sort函数按照题面要求定义不同的排序规则。 二分查找123456789101112131415bool BinarySearch(int n, int target){ int left = 0; int right = n-1; whhile(left &lt; right){ int middle = (left+right)/2; if(arr[middle] &lt; target){ left = middle+1; }else if(target &lt; arr[middle]){ right = middle-1; }else{ return true; } } return false;} 当数据很大时，为防止溢出，可以用 int middle = left+(right-left)/2替代 int middle = (left+right)/2 字符串string的使用1234567891011121314151617181920string str = &quot;hello world&quot;;n = str.size()//迭代器访问for(string::iterator it = str.begin(); it != str.end(); ++it){ printf(&quot;%c&quot;, *it);}//在任意位置插入元素str.insert(str.size(), &quot;end world&quot;);//在任意位置删除元素str.erase(7);//将字符串清空str.clear();//可以使用加号拼接字符串str1 = str+str2;//判断字符串关系str1 &lt;= str2;//find查找特定字符串，若找到对应的字符/字符串就返回对应下标；找不到则返回string::nposint found = str.find(&quot;world&quot;);//返回字符串子串的函数substr()string str2 = str1.substr(3,5); 当输入是一行字符串时，使用：while(getline(cin, str)){} 初始化数组：memset(number, 0, sizeof(number)); 字符串匹配(KMP)12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364#include &lt;iostream&gt;#include &lt;cstdio&gt;using namespace std;const int MAXM = 10000;const int MAXN = 1000000;int nextTable[MAXM];int pattern[MAXM];int text[MAXN];void GetNextTable(int m){ int j = 0; nextTable[j] = -1; int i = nextTable[j]; while(j &lt; m){ if(i == -1 || pattern[j] == pattern[i]){ i++; j++; nextTable[j] = i; }else{ i = nextTable[i]; } } return ;}int KMP(int n, int m){ GetNextTable(m); int i = 0; int j = 0; while(i&lt;n &amp;&amp; j&lt;m){ if(j == -1 || text[i] == pattern[j]){ i++; j++; }else{ j = nextTable[j]; } } if(j == m){ return i-j+1; }else{ return -1; }}int main(){ int caseNumber; scanf(&quot;%d&quot;, &amp;caseNumber); while(caseNumber--){ int n, m; scanf(&quot;%d%d&quot;, n, m); for(int i=0; i&lt;n; i++){ scanf(&quot;%d&quot;, &amp;text[i]); } for(int j=0; j&lt;m; j++){ scanf(&quot;%d&quot;, &amp;pattern[j]); } printf(&quot;%d\\n&quot;, KMP(n, m)); } return 0;} 数据结构向量vector 头文件和声明：#include &lt;vector&gt; vector&lt;typename&gt; name vector的状态：当前是否为空的 empty(), 返回当前向量元素个数 size() vector尾部元素的添加或删除。push_back() pop_back() 元素的访问：下标访问，从0到size()-1；通过迭代器访问，类似指针 元素操作：insert() erase() clear() 迭代器操作：首元素 begin() 尾元素 end() 使用场合：在数据量不确定的情况下完成数据的处理，还可以实现图论中的邻接表 队列Queue 定义：#include &lt;queue&gt; queue&lt;typename&gt; name 判断是否为空：empty() 元素个数：size() queue元素的添加或删除：push() pop() queue元素的访问：front() back() 栈stack 定义：#include &lt;stack&gt; stack&lt;typename&gt; name 判断是否为空：empty() 元素个数：size() stack元素的添加或删除：push() pop() stack元素的访问：top() 一个字符串小技巧：string answer(str.size(), ' '); 典型题：括号匹配，简单计算器 数学问题进制转换基本代码如下，一般情况下会遇到只能以字符串形式储存，需要设计字符串计算的函数 12345678910111213141516171819202122#include &lt;iostream&gt;#include &lt;cstdio&gt;#include &lt;vector&gt;using namespace std;int main(){ unsigned int n; while(scanf(&quot;%d&quot;, &amp;n) != EOF){ vector&lt;int&gt; binary; while(n != 0){ binary.push_back(n % 2); n /= 2; } for(int i = binary.size()-1; i&gt;= 0; i--){ printf(&quot;%d&quot;, binary[i]); } printf(&quot;\\n&quot;); } return 0;} 最大公约数与最小公倍数最大公约数 12345678910111213141516171819#include &lt;iostream&gt;#include &lt;cstdio&gt;using namespace std;int GCD(int a, int b){ if(b == 0){ return a; } else{ return GCD(b, a%b); }}int main(){ int a, b; while(scanf(&quot;%d%d&quot;, &amp;a, &amp;b) != EOF){ printf(&quot;%d\\n&quot;, GCD(a, b)); } return 0;} 最小公倍数用的公式就是：a*b/GCD(a, b) 质数 判断是否为素数 123456789101112bool Judge(int x){ if(x&lt;2){ return false; } int bound = sqrt(x); for(int i=2; i &lt; bound; i++){ if(x % i == 0){ return false; } } return true;} 素数筛法 123456789101112131415void Initial(){ for(int i = 0; i &lt; MAXN; i++){ isPrime[i] = true; } isPrime[0] = false; isPrime[1] = false; for(int i = 0; i &lt; MAXN; i++){ if(!isPrime[i]) continue; prime.push_back(i); for(int j=i*i; j&lt;MAXN; j+=i){ isPrime[j] = false; } } return;} 分解质因数：在素数筛法的基础上完成 快速幂 12345678910111213int FastExponentiation(int a, int b, int mod) { int answer = 1; while(b != 0){ if(b % 2 == 1){ answer *= a; answer %= mod; } b /= 2; a *= a; a %= mod; } return answer;} 矩阵与矩阵快速幂 12345678910111213141516171819202122232425262728293031323334353637383940414243#include &lt;iostream&gt;#include &lt;cstdio&gt;using namespace std;struct Matrix { int matrix[10][10]; int row, col; Matrix(int r, int c): row(r), col(c){}};Matrix Multipy(Matrix x, Matrix y){ Matrix answer(x.row, y.col); for(int i=0; i &lt; answer.row; i++){ for(int j=0; j&lt;answer.col; j++){ answer.matrix[i][j] = 0; for(int k=0; j &lt; answer.col; k++){ answer.matrix[i][j] += x.matrix[i][k]*y.matrix[k][j]; } } } return answer;}void PrintMatrix(Matrix x){}Matrix FastExponentiation(Matrix x, int k){ Matrix answer(x.row, x.col); for(int i=0; i&lt;answer.row; i++){ for(int j=0; j&lt;answer.col; j++){ if(i == j) answer.matrix[i][j] = 1; else answer.matrix[i][j] = 0; } } while(k != 0){ if(k % 2 == 1){ answer = Multipy(answer, x); } k /= 2; x = Multipy(x, x); } return answer;} 其核心思想和前面的非矩阵快速幂一致 高精度整数（给一个模板，但只适合正整数） 1234567891011121314151617181920struct BigInteger{ int digit[MAXN]; int length; BigInteger(); BigInteger(int x); BigInteger(string str); BigInteger(const BigInteger&amp; b); BigInteger operator=(int x); BigInteger operator=(string str); BigInteger operator=(const BigInteger&amp; b); bool operator&lt;=(const BigInteger&amp; b); bool operator==(const BigInteger&amp; b); BigInteger operator+(const BigInteger&amp; b); BigInteger operator-(const BigInteger&amp; b); BigInteger operator*(const BigInteger&amp; b); BigInteger operator/(const BigInteger&amp; b); BigInteger operator%(const BigInteger&amp; b); friend istream&amp; operator&gt;&gt;(istream&amp; in, BigInteger&amp; x); friend ostream&amp; operator&lt;&lt;(ostream&amp; out, const BigInteger&amp; x);}; 其中每一个部分都有相应板块的代码，具体见书P107（太长了，最好理解了敲来背） 贪心策略 贪心策略一般用在优化问题上，其核心思想是选择当前状态下的最优解，即不以整体最优进行考虑，而只考虑当下这一步。但在某些问题中，局部最优能收敛到全局最优，使用贪心就很有效果。这类最优问题的特点是具备无后效性，即某个状态以前的过程不会影响以后的状态，而只与当前状态有关。 区间贪心指当有多个不同的区间存在，且这些区间有可能相互重叠的时候，如何选择才能从众多区间中，选取最多的两两互不相交的区间。 列题：搭桥问题 有n个岛屿，每个岛屿都可以用直线上不相交的线段表示，岛屿的坐标为$[l_i, r_i]$，对于所有$1 \\leq i \\leq n-1$都有$r_i &lt; l_{i+1}$为了能让两个临近的岛屿相连接，需要在其之间架一座桥。长度为a的桥可以架在第i和第i+1号岛屿之间，如果它们的坐标为x和y，则有$l_i \\leq x \\leq r_i$，$l_{i+1} \\leq y \\leq r_{i +1}$和$y-x=a$。 我们可以使用m座桥，每座桥最多可以使用一次。请确定他可用的桥梁是否能够连接每对相邻的岛屿。 题解： 一共n个岛屿的话，可以得到n-1个需要架的桥的区间（相邻的才架），对于每个区间设定[minimum, maxmum]，对区间按照minimum排序，对给的桥按照length排序。最后在所有能满足的区间中，选择maxmum最小的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687#include &lt;iostream&gt;#include &lt;cstdio&gt;#include &lt;cstring&gt;#include &lt;algorithm&gt;#include &lt;queue&gt;using namespace std;const int MAXN = 200001;struct Island{ long long left; long long right;};struct Bridge{ long long length; long long index;};struct Interval{ long long minimum; long long maxmum; long long index; //区间编号 bool operator&lt; (Interval x) const{ //操作符的重载 return maxmum &gt; x.maxmum; }};//自定义比较函数bool IntervalCompare(Interval x, Interval y){ if(x.minimum == y.minimum){ return x.maxmum &lt; y.maxmum; } else { return x.minimum &lt; y.minimum; }}bool BridgeCompare(Bridge x, Bridge y){ return x.length &lt; y.length;}Island island[MAXN];Bridge bridge[MAXN];Interval interval[MAXN];long long answer[MAXN];bool Solve(int n, int m){ priority_queue&lt;Interval&gt; myQueue; //优先队列的性质 int position = 0; //当前区间的下标 int number = 0; //搭建桥的数目 for(int i=0; i&lt;m; i++){ while(myQueue.top().maxmum &lt; bridge[i].length &amp;&amp; !myQueue.empty()){ myQueue.pop(); } while(position &lt; n-1 &amp;&amp; (interval[position].minimum &lt;= bridge[i].length) &amp;&amp; (interval[position].maxmum &gt;= bridge[i].length)){ myQueue.push(interval[position]); position++; } if(!myQueue.empty()){ Interval current = myQueue.top(); myQueue.pop(); answer[current.index] = bridge[i].index; number++; } } return number == (n-1);}int main(){ int n, m; while(scanf(&quot;%d%d&quot;, &amp;n, &amp;m) != EOF){ memset(island, 0, sizeof(island)); memset(bridge, 0, sizeof(bridge)); memset(interval, 0, sizeof(interval)); memset(answer, 0, sizeof(answer)); for(int i=0; i&lt;m; i++){ scanf(&quot;%lld%lld&quot;, &amp;island[i].left, &amp;island[i].right); } for(;;){ //输入桥的信息 } //计算区间，排序，选择 }} 上面代码涉及到优先队列，他的用法和概念后面说。 递归与分治构成递归需要具备两个条件： 子问题必须与原始问题相同，且规模更小，尝试列出等式 不能无限制地调用本身，必须有一个递归出口 分治法，“分而治之”，即把复杂的问题分成两个或更多个子问题，子问题间相互独立且与原问题相同或相似，持续分直到最后的子问题可以简单直接求解。分治法中也和递归有结合，它们是相互依存的。 搜索宽度优先搜索 状态。需要确定所求解问题中的状态，通过状态的扩展，遍历所有的状态，从中寻找需要的答案 状态的扩展方式。 有效状态。有一些状态不需要再次扩展可以直接舍弃 队列。为了使得状态能够先扩展，使用队列，将得到的状态依次放入队尾，每次取对头元素进行扩展 标记。区分有效和无效的状态（比如下面代码要区分已经访问过了还是没有访问） 有效状态数。估计是否在时间范围内能完成整个搜索 最优。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#include &lt;iostream&gt;#include &lt;cstdio&gt;#include &lt;cstring&gt;#include &lt;queue&gt;using namespace std;const int MAXN = 100001;//储存位置和时间struct Status{ int n, t; Status(int n, int t): n(n), t(t){}};bool visit[MAXN];int BFS(int n, int k){ queue&lt;Status&gt; myQueue; myQueue.push(Status(n, 0)); visit[n] = true; while(!myQueue.empty()){ Status current = myQueue.front(); myQueue.pop(); if(current.n == k){ return current.t; } for(int i=0; i&lt;3; i++){ Status next(current.n, current.t+1); if(i == 0){ next.n += 1; } else if(i == 1){ next.n -= 1; } else{ next.n *= 2; } if(next.n &lt; 0 || next.n &gt;= MAXN || visit[next.n]){ continue; } myQueue.push(next); visit[next.n] = true; } }}int main(){ int n, k; scanf(&quot;%d%d&quot;, &amp;n, &amp;k); memset(visit, false, sizeof(visit)); printf(&quot;%d\\n&quot;, BFS(n, k)); return 0;} 深度优先搜索通常使用递归函数，一般不能来求最优解，而是使用来判断有无解，是存在性问题。注意不能递归层数太深，可能会出现“爆栈”的问题 数据结构二二叉树前序遍历先根节点-左-右 中序遍历左-根-右 后序遍历左-右-根 层次遍历需要设置队列来装 二叉排序树二叉排序树的特点： 左子树非空的话，左子树上所有结点关键字的值小于根结点关键字的值 右子树非空的话，右子树上所有结点关键字的值大于根结点关键字的值 左右子树本身也是一棵二叉排序树 优先队列能够将数据按事先规定的优先级进行动态组织的数据结构称为优先队列，访问元素时，只能访问当前队列中优先级最高的元素。 在头文件queue中，定义为priority_queue&lt;typename&gt; name 元素个数size()，是否为空empty()，push()，pop()，访问top() 默认为大顶堆，即优先级高的先输出。要改为小顶堆：priority_queue&lt;typename, vector&lt;typename&gt;, greater&lt;typename&gt;&gt; name 哈夫曼树：带权路径长度和最小的二叉树。求解时每次找最小的两个结点组合起来。 散列表一般的搜索方式，无论是向量还是树，结构中元素存放位置与元素的关键字之间并不存在确定的关系，因此在查找时需要对关键字进行比较，最好也就是$O(log_n)$，但是使用散列表直接对关键字进行访问的话，可以在$O(1)$下完成。 先介绍标准库中的map，map是将关键字和映射值形成一一映射绑定存储的容器，底层是用红黑树实现的，内部依然有序，所以查找效率为$O(log_n)$。标准库中还有一个无序映射unordered_map，底层是散列表，期望查找效率为$O(1)$。在数据量不大时，map可以完成几乎所有工作了，如果实在需要使用unordered_map，直接改一下名称就好，用法基本一样。 定义：在 &lt;map&gt;中，需要 map&lt;typename1, typename2&gt; name 状态有两个，empty()和size() 添加和删除：insert() erase() 访问用[key]或者at()或者迭代器 查找特定元素find()，找到时返回的是该元素的迭代器，没找到就返回迭代器end() 映射清空的操作clear() map迭代器操作：begin() end() 图论图的结构可以用邻接矩阵或邻接表表示，分类上可以分为有向/无向图，是否带权。 并查集并查集用于处理一些不交集的合并和查询问题。有以下两个功能： 判断任意两个元素是否属于同一个集合； 按照要求合并不同的集合； 首先将集合在逻辑上表示为树结构，每个结点都指向其父节点，而树中的元素无顺序之分，在同一棵树上的就是一个集合中的。并查集有两个操作，查找和合并 查找：确定元素属于哪个集合。不断向上查找，直到找到他的根结点，之后根据根节点是否相同来判断两个元素是否属于一个集合。 合并：将一棵树作为另一颗树的子树，从而使得两棵树变为一棵更大的树。 为了避免不好的树的形态（最差的就是退化为单链表），需要对合并做一定的约束和优化，具体下来就是路径压缩。在查找到某个结点的根结点时，将其与根节点之间的所有结点都直接指向根结点。且还有个小技巧，就是在合并时，总是将高度较低的树，作为高度较高的树的子树进行合并。 应用：在图论中，用来判断是否为连通图，或用来求图的连通分量。 连通图的定义：在一个无向图G中，若顶点u到顶点v有路径相连，则两点是相连的。若图中任意两点都是连通的，则为连通图。而G中的一个极大连通子图为G的一个连通分量。连通图只有自己为唯一的连通分量 最小生成树如果存在一个连通子图，包含原图中所有顶点和部分边，且这个子图不存在回路，则 为原图的一棵生成树。在带权无向连通图中，所有生成树中边权的和最小的那一颗被称为该无向图的最小生成树。常见算法：Kruskal和Prim 最短路径Dijkstra算法 拓扑排序针对的有向无环图。按照方向排一个序。 关键路径动态规划动态规划通常用于求解最优解的问题，与分治法类似，基本思想都是将待求问题分解成若干个子问题，先求解子问题，然后从这些子问题中得到原问题的解。但与分治法不同的是，适合用于动态规划求解的问题，经分解得到的子问题往往不是相互独立的。若用分治法来解这类问题，则分解得到的子问题太多，有些子问题会被重复计算很多次。而动态规划的做法是将已解决子问题的答案保存下来，在需要子问题答案的时候便可直接获得，而不需要重复计算，这样可以避免大量的重复计算，提高效率。 递推求解最大连续子序列和最长递增子序列最长公共子序列背包问题","link":"/2020/09/21/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95%E5%A4%8D%E4%B9%A0/"}],"tags":[{"name":"git","slug":"git","link":"/tags/git/"},{"name":"密码学","slug":"密码学","link":"/tags/%E5%AF%86%E7%A0%81%E5%AD%A6/"},{"name":"网络安全","slug":"网络安全","link":"/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"},{"name":"动态规划","slug":"动态规划","link":"/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"},{"name":"blog","slug":"blog","link":"/tags/blog/"},{"name":"图","slug":"图","link":"/tags/%E5%9B%BE/"},{"name":"算法","slug":"算法","link":"/tags/%E7%AE%97%E6%B3%95/"},{"name":"ML","slug":"ML","link":"/tags/ML/"},{"name":"决策树","slug":"决策树","link":"/tags/%E5%86%B3%E7%AD%96%E6%A0%91/"},{"name":"git，语法分析","slug":"git，语法分析","link":"/tags/git%EF%BC%8C%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90/"},{"name":"假设检验","slug":"假设检验","link":"/tags/%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C/"},{"name":"概率论","slug":"概率论","link":"/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/"},{"name":"线性模型","slug":"线性模型","link":"/tags/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/"}],"categories":[{"name":"论文","slug":"论文","link":"/categories/%E8%AE%BA%E6%96%87/"},{"name":"开发","slug":"开发","link":"/categories/%E5%BC%80%E5%8F%91/"},{"name":"网络安全","slug":"论文/网络安全","link":"/categories/%E8%AE%BA%E6%96%87/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"},{"name":"算法","slug":"算法","link":"/categories/%E7%AE%97%E6%B3%95/"},{"name":"Spring boot框架","slug":"开发/Spring-boot框架","link":"/categories/%E5%BC%80%E5%8F%91/Spring-boot%E6%A1%86%E6%9E%B6/"},{"name":"我的博客发展","slug":"我的博客发展","link":"/categories/%E6%88%91%E7%9A%84%E5%8D%9A%E5%AE%A2%E5%8F%91%E5%B1%95/"},{"name":"网络安全","slug":"网络安全","link":"/categories/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"},{"name":"区块链","slug":"开发/区块链","link":"/categories/%E5%BC%80%E5%8F%91/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"版本管理","slug":"开发/版本管理","link":"/categories/%E5%BC%80%E5%8F%91/%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86/"},{"name":"机器学习","slug":"机器学习","link":"/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"项目","slug":"开发/项目","link":"/categories/%E5%BC%80%E5%8F%91/%E9%A1%B9%E7%9B%AE/"},{"name":"基础学科","slug":"基础学科","link":"/categories/%E5%9F%BA%E7%A1%80%E5%AD%A6%E7%A7%91/"},{"name":"西瓜书","slug":"机器学习/西瓜书","link":"/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E8%A5%BF%E7%93%9C%E4%B9%A6/"},{"name":"概率论","slug":"基础学科/概率论","link":"/categories/%E5%9F%BA%E7%A1%80%E5%AD%A6%E7%A7%91/%E6%A6%82%E7%8E%87%E8%AE%BA/"},{"name":"计算机网络","slug":"基础学科/计算机网络","link":"/categories/%E5%9F%BA%E7%A1%80%E5%AD%A6%E7%A7%91/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}]}